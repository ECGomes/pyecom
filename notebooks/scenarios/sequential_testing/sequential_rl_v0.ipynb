{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-24T03:16:27.576746Z",
     "start_time": "2024-08-24T03:16:23.494670Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 04:16:27,303\tWARNING deprecation.py:50 -- DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import ray\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib import Policy\n",
    "\n",
    "import IPython.core.display_functions\n",
    "\n",
    "from src.parsers import HMParser, CotevParser\n",
    "from src.resources import Aggregator, Generator, Load, Storage\n",
    "from src.algorithms.rl import EnergyCommunitySequentialV0, EnergyCommunitySequentialV1\n",
    "from src.algorithms.rl import EnergyCommunitySequentialV2, EnergyCommunitySequentialV3\n",
    "from src.algorithms.rl import EnergyCommunitySequentialV7\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data parsing\n",
    "\n",
    "# EC data for non-renewable generators and batteries\n",
    "data_ec = HMParser(file_path='/Users/ecgomes/DataspellProjects/pyecom/data/EC_V4.xlsx', ec_id=1)\n",
    "data_ec.parse()\n",
    "\n",
    "# EV data from the EV4EU simulator\n",
    "data_ev = CotevParser(population_path=\n",
    "                      '/Users/ecgomes/DataspellProjects/pyecom/data/simulation_dataframes_2years/population_731.csv',\n",
    "                      driving_history_path=\n",
    "                      '/Users/ecgomes/DataspellProjects/pyecom/data/simulation_dataframes_2years/ev_driving_history_731.csv',\n",
    "                      assigned_segments_path='/Users/ecgomes/DataspellProjects/pyecom/data/simulation_dataframes_2years/assigned_segments_731.csv',\n",
    "                      parse_date_start='2019',\n",
    "                      parse_date_end='2020')\n",
    "data_ev.parse()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T03:16:29.744222Z",
     "start_time": "2024-08-24T03:16:28.398786Z"
    }
   },
   "id": "e43835ff69a5fd2a",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# UPAC Data load\n",
    "\n",
    "data_upacs = {}\n",
    "for i in glob.glob('/Users/ecgomes/Documents/PhD/UPAC data/upac*_pv.csv'):\n",
    "    temp = pd.read_csv(i, index_col=0, parse_dates=True)\n",
    "    temp = temp.resample('H').mean()\n",
    "    \n",
    "    # Need to divide by 1000 to convert from W to kW\n",
    "    temp['pv'] = temp['pv'] / 1000\n",
    "    temp['load'] = temp['load'] / 1000\n",
    "    \n",
    "    # Set any negative values to zero\n",
    "    temp.loc[temp['pv'] < 0, 'pv'] = 0\n",
    "    temp.loc[temp['load'] < 0, 'load'] = 0\n",
    "    \n",
    "    # We only want 2019 and 2020 data\n",
    "    temp = temp.loc['2019':'2020']\n",
    "    \n",
    "    # Fill potential NaN values with interpolation\n",
    "    # temp = temp.interpolate()\n",
    "    \n",
    "    # Fill NaN values with zeros\n",
    "    temp = temp.fillna(0)\n",
    "    \n",
    "    name = i.split('/')[-1].split('_')[0].split('upac')[1]\n",
    "    \n",
    "    data_upacs[name] = temp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T03:16:32.786992Z",
     "start_time": "2024-08-24T03:16:30.256215Z"
    }
   },
   "id": "d8097bd3d6272b3d",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train resource creation\n",
    "\n",
    "def create_resources(upacs, ec, ev):\n",
    "    \"\"\"\n",
    "    Create the resources for the training environment.\n",
    "    return a list of resources.\n",
    "    :param upacs: dict with the UPAC data\n",
    "    :param ec: dict with the EC data\n",
    "    :param ev: dict with the EV data\n",
    "    \"\"\"\n",
    "\n",
    "    resources = []\n",
    "    # Add generators (from pv column from the UPAC data)\n",
    "    for i in range(len(upacs)):\n",
    "        current_name = list(upacs.keys())[i]\n",
    "        resources.append(Generator(\n",
    "            name='ren_generator_' + current_name,\n",
    "            value=np.zeros(upacs[current_name]['pv'].shape),\n",
    "            lower_bound=np.zeros(upacs[current_name]['pv'].shape),\n",
    "            upper_bound=upacs[current_name]['pv'].values,\n",
    "            cost=ec.generator['cost_parameter_b'][0, 0] * np.ones(upacs[current_name].shape[0]),\n",
    "            cost_nde=np.tile(ec.generator['cost_nde'][0], (int(upacs[current_name].shape[0] / 24))),\n",
    "            is_renewable=True))\n",
    "\n",
    "    '''\n",
    "    resources.append(Generator(\n",
    "        name='generator_14',\n",
    "        value=np.zeros(upacs['02']['pv'].shape),\n",
    "        lower_bound=np.zeros(upacs['02']['pv'].shape),\n",
    "        upper_bound=np.ones(upacs['02']['pv'].shape) * 15,\n",
    "        cost=ec.generator['cost_parameter_b'][0, 0] * np.ones(upacs['02'].shape[0]),\n",
    "        cost_nde=ec.generator['cost_nde'][0],\n",
    "        is_renewable=False))\n",
    "    \n",
    "    resources.append(Generator(\n",
    "        name='generator_15',\n",
    "        value=np.zeros(upacs['02']['pv'].shape),\n",
    "        lower_bound=np.zeros(upacs['02']['pv'].shape),\n",
    "        upper_bound=np.ones(upacs['02']['pv'].shape) * 15,\n",
    "        cost=ec.generator['cost_parameter_b'][0, 0] * np.ones(upacs['02'].shape[0]),\n",
    "        cost_nde=ec.generator['cost_nde'][0],\n",
    "        is_renewable=False))\n",
    "    '''\n",
    "\n",
    "    # Add loads (from load column from the UPAC data)\n",
    "    for i in range(len(upacs)):\n",
    "        current_name = list(upacs.keys())[i]\n",
    "        resources.append(Load(\n",
    "            name='load_' + current_name,\n",
    "            value=upacs[current_name]['load'],\n",
    "            lower_bound=np.zeros(upacs[current_name].shape),\n",
    "            upper_bound=upacs[current_name]['load'].values,\n",
    "            cost=np.ones(upacs[current_name].shape[0]),\n",
    "            cost_cut=np.tile(ec.load['cost_cut'][0], (int(upacs[current_name].shape[0] / 24))),\n",
    "            cost_reduce=np.tile(ec.load['cost_reduce'][0], (int(upacs[current_name].shape[0] / 24))),\n",
    "            cost_ens=np.tile(ec.load['cost_ens'][0], (int(upacs[current_name].shape[0] / 24)))))\n",
    "\n",
    "    # Add storage (from the EC data)\n",
    "    for i in range(ec.storage['p_charge_limit'].shape[0]):\n",
    "        resources.append(Storage(\n",
    "            name='storage_{:02d}'.format(i+1),\n",
    "            value=ec.storage['initial_state'][i] * np.ones(upacs['02'].shape[0]),\n",
    "            lower_bound=np.ones(upacs['02'].shape[0]) * ec.storage['energy_min_percentage'][i],\n",
    "            upper_bound=(ec.storage['energy_capacity'][i] * np.ones(upacs['02'].shape[0])),\n",
    "            cost=np.ones(upacs['02'].shape[0]) * 0,\n",
    "            cost_discharge=np.tile(ec.storage['discharge_price'][i], (int(upacs['02'].shape[0] / 24))),\n",
    "            cost_charge=np.tile(ec.storage['charge_price'][i], (int(upacs['02'].shape[0] / 24))),\n",
    "            capacity_max=ec.storage['energy_capacity'][i],\n",
    "            capacity_min=ec.storage['energy_min_percentage'][i],\n",
    "            initial_charge=ec.storage['initial_state'][i],\n",
    "            discharge_efficiency=ec.storage['discharge_efficiency'][i],\n",
    "            discharge_max=np.tile(ec.storage['p_discharge_limit'][i], (int(upacs['02'].shape[0] / 24))),\n",
    "            charge_efficiency=ec.storage['charge_efficiency'][i],\n",
    "            charge_max=np.tile(ec.storage['p_charge_limit'][i], (int(upacs['02'].shape[0] / 24))),\n",
    "            capital_cost=np.array([0.05250, 0.10500, 0.01575])))\n",
    "\n",
    "    # Add vehicles (from the EV data)\n",
    "    for i in np.arange(len(ev)):\n",
    "        # Append to the list of resources\n",
    "        # ev[i].cost_charge *= 0\n",
    "        # ev[i].cost_discharge *= 0\n",
    "        resources.append(ev[i])\n",
    "\n",
    "    # Append Aggregator\n",
    "    resources.append(Aggregator(\n",
    "        name='aggregator',\n",
    "        value=np.zeros(upacs['02'].shape[0]),\n",
    "        lower_bound=np.zeros(upacs['02'].shape[0]),\n",
    "        upper_bound=np.tile(ec.peers['import_contracted_p_max'][0, 0], (upacs['02'].shape[0])),\n",
    "        cost=np.tile(ec.peers['buy_price'][0, 0], (upacs['02'].shape[0])),\n",
    "        imports=np.zeros(upacs['02'].shape[0]),\n",
    "        exports=np.zeros(upacs['02'].shape[0]),\n",
    "        import_cost=np.tile(ec.peers['buy_price'][0], (int(upacs['02'].shape[0] / 24))), # * 100,\n",
    "        export_cost=np.tile(ec.peers['sell_price'][0], (int(upacs['02'].shape[0] / 24))),\n",
    "        import_max=np.tile(ec.peers['import_contracted_p_max'][0, 0], (int(upacs['02'].shape[0]))),\n",
    "        export_max=np.tile(ec.peers['export_contracted_p_max'][0, 0], (int(upacs['02'].shape[0])))))\n",
    "\n",
    "    return resources"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T03:16:33.297491Z",
     "start_time": "2024-08-24T03:16:33.287609Z"
    }
   },
   "id": "bf9b045471522328",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create resources for the training environment\n",
    "\n",
    "def iterate_resources(u, c, e, mode='daily'):\n",
    "    \n",
    "    temp = {}\n",
    "    \n",
    "    # Save first key of upac data\n",
    "    first_key = list(u.keys())[0]\n",
    "    \n",
    "    if mode is 'daily':\n",
    "\n",
    "        # Loop to iterate over days in the datasets\n",
    "        for i in np.unique(u[first_key].index.date):\n",
    "            # Create the resources for the training environment\n",
    "            \n",
    "            date = i.strftime('%Y-%m-%d')\n",
    "            \n",
    "            temp_u = {k: v.loc[date] for k, v in u.items()}\n",
    "            temp_e = e.create_resources(e.population, e.trips_grid, e.assigned_segments, date)\n",
    "            \n",
    "            temp[date] = create_resources(upacs=temp_u,\n",
    "                                          ec=c,\n",
    "                                          ev=temp_e)\n",
    "            \n",
    "    elif mode is 'monthly':\n",
    "        \n",
    "        # Loop to iterate over months in the datasets\n",
    "        # Need to be careful with different years\n",
    "        unique_months = np.unique(data_upacs['02'].index.strftime('%Y-%m'))\n",
    "        \n",
    "        for i in unique_months:\n",
    "            # Create the resources for the training environment\n",
    "            date = i\n",
    "            \n",
    "            temp_u = {k: v.loc[date] for k, v in u.items()}\n",
    "            temp_e = e.create_resources(e.population, e.trips_grid, e.assigned_segments, date)\n",
    "            \n",
    "            temp[date] = create_resources(upacs=temp_u,\n",
    "                                          ec=c,\n",
    "                                          ev=temp_e)\n",
    "            \n",
    "    elif mode is 'yearly':\n",
    "        \n",
    "        # Loop to iterate over years in the datasets\n",
    "        unique_years = np.unique(data_upacs['02'].index.strftime('%Y'))\n",
    "        \n",
    "        for i in unique_years:\n",
    "            # Create the resources for the training environment\n",
    "            date = i\n",
    "            \n",
    "            temp_u = {k: v.loc[date] for k, v in u.items()}\n",
    "            temp_e = e.create_resources(e.population, e.trips_grid, e.assigned_segments, date)\n",
    "            \n",
    "            temp[date] = create_resources(upacs=temp_u,\n",
    "                                          ec=c,\n",
    "                                          ev=temp_e)\n",
    "        \n",
    "    return temp\n",
    "\n",
    "dataset_resources = iterate_resources(u=data_upacs, c=data_ec, e=data_ev, mode='monthly')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T03:16:34.059610Z",
     "start_time": "2024-08-24T03:16:33.968039Z"
    }
   },
   "id": "82526219bdef7d23",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['ren_generator_08',\n 'ren_generator_06',\n 'ren_generator_02',\n 'ren_generator_09',\n 'ren_generator_13',\n 'storage_01',\n 'storage_02',\n 'storage_03',\n 'aggregator']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the execution order\n",
    "\n",
    "execution_order = [res.name for res in dataset_resources[list(dataset_resources.keys())[0]][:5]] + \\\n",
    "                  [res.name for res in dataset_resources[list(dataset_resources.keys())[0]][10:13]] + \\\n",
    "                  [dataset_resources[list(dataset_resources.keys())[0]][-1].name]\n",
    "                  #[res.name for res in dataset_resources[list(dataset_resources.keys())[0]][13:-1]]# + \\\n",
    "                  #[res.name for res in dataset_resources[list(dataset_resources.keys())[0]][5:7]]# + \\\n",
    "                  #[dataset_resources[list(dataset_resources.keys())[0]][-1].name]\n",
    "execution_order"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T03:16:34.531698Z",
     "start_time": "2024-08-24T03:16:34.527264Z"
    }
   },
   "id": "9905c07df9d0e24c",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated: True\n"
     ]
    }
   ],
   "source": [
    "# Create the environment and check if everything is ok\n",
    "\n",
    "temp_env = EnergyCommunitySequentialV7(ren_generators=dataset_resources[list(dataset_resources.keys())[0]][:5],\n",
    "                                       generators=[],#dataset_resources[list(dataset_resources.keys())[0]][5:7],\n",
    "                                       loads=dataset_resources[list(dataset_resources.keys())[0]][5:10],\n",
    "                                       storages=dataset_resources[list(dataset_resources.keys())[0]][10:13],\n",
    "                                       evs=[], #dataset_resources[list(dataset_resources.keys())[0]][13:-1],\n",
    "                                       aggregator=dataset_resources[list(dataset_resources.keys())[0]][-1],\n",
    "                                       storage_penalty=1,\n",
    "                                       ev_penalty=1,\n",
    "                                       balance_penalty=1,\n",
    "                                       execution_order=execution_order)\n",
    "temp_env.reset()\n",
    "terminations = truncations = {a: False for a in temp_env.agents}\n",
    "terminations['__all__'] = False\n",
    "truncations['__all__'] = False\n",
    "while not terminations['__all__'] and not truncations['__all__']:\n",
    "\n",
    "    actions = temp_env.action_space_sample()\n",
    "    next_obs, rewards, terminations, truncations, infos = temp_env.step(actions)\n",
    "\n",
    "print('Terminated: {}'.format(terminations['__all__']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T03:16:35.187044Z",
     "start_time": "2024-08-24T03:16:35.004602Z"
    }
   },
   "id": "f732630cb55ab585",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create the policies dictionary\n",
    "\n",
    "def assign_group_policies(env):\n",
    "\n",
    "    policies = {'generator_renewable': (None,\n",
    "                              env.observation_space['ren_generator_08'],\n",
    "                              env.action_space['ren_generator_08'],\n",
    "                              {}),\n",
    "                'storage': (None,\n",
    "                            env.observation_space['storage_01'],\n",
    "                            env.action_space['storage_01'],\n",
    "                            {}),\n",
    "                'ev': (None,\n",
    "                       env.observation_space['ev_01'],\n",
    "                       env.action_space['ev_01'],\n",
    "                       {}),\n",
    "                #'generator_non_renewable': (None,\n",
    "                #              env.observation_space['generator_14'],\n",
    "                #              env.action_space['generator_14'],\n",
    "                #              {}),\n",
    "                }\n",
    "\n",
    "    return policies\n",
    "\n",
    "def assign_group_policies_v2(env):\n",
    "\n",
    "    policies = {'ren_08': (None,\n",
    "                           env.observation_space['ren_generator_08'],\n",
    "                           env.action_space['ren_generator_08'],\n",
    "                           {}),\n",
    "                'ren_09': (None,\n",
    "                            env.observation_space['ren_generator_09'],\n",
    "                            env.action_space['ren_generator_09'],\n",
    "                            {}),\n",
    "                'ren_02': (None,\n",
    "                            env.observation_space['ren_generator_02'],\n",
    "                            env.action_space['ren_generator_02'],\n",
    "                            {}),\n",
    "                'ren_06': (None,\n",
    "                            env.observation_space['ren_generator_06'],\n",
    "                            env.action_space['ren_generator_06'],\n",
    "                            {}),\n",
    "                'ren_13': (None,\n",
    "                            env.observation_space['ren_generator_13'],\n",
    "                            env.action_space['ren_generator_13'],\n",
    "                            {}),\n",
    "                'storage_01': (None,\n",
    "                               env.observation_space['storage_01'],\n",
    "                               env.action_space['storage_01'],\n",
    "                               {}),\n",
    "                'storage_02': (None,\n",
    "                               env.observation_space['storage_02'],\n",
    "                               env.action_space['storage_02'],\n",
    "                               {}),\n",
    "                'storage_03': (None,\n",
    "                               env.observation_space['storage_03'],\n",
    "                               env.action_space['storage_03'],\n",
    "                               {}),\n",
    "                'ev_01': (None,\n",
    "                          env.observation_space['ev_01'],\n",
    "                          env.action_space['ev_01'],\n",
    "                          {}),\n",
    "                'ev_02': (None,\n",
    "                          env.observation_space['ev_02'],\n",
    "                          env.action_space['ev_02'],\n",
    "                          {}),\n",
    "                'ev_03': (None,\n",
    "                          env.observation_space['ev_03'],\n",
    "                          env.action_space['ev_03'],\n",
    "                          {}),\n",
    "                'ev_04': (None,\n",
    "                          env.observation_space['ev_04'],\n",
    "                          env.action_space['ev_04'],\n",
    "                          {}),\n",
    "                'ev_05': (None,\n",
    "                          env.observation_space['ev_05'],\n",
    "                          env.action_space['ev_05'],\n",
    "                          {}),\n",
    "                }\n",
    "\n",
    "    return policies\n",
    "\n",
    "def assign_group_policies_v3(env):\n",
    "\n",
    "    policies = {'ren_08': (None,\n",
    "                           env.observation_space['ren_generator_08'],\n",
    "                           env.action_space['ren_generator_08'],\n",
    "                           {}),\n",
    "                'ren_09': (None,\n",
    "                           env.observation_space['ren_generator_09'],\n",
    "                           env.action_space['ren_generator_09'],\n",
    "                           {}),\n",
    "                'ren_02': (None,\n",
    "                           env.observation_space['ren_generator_02'],\n",
    "                           env.action_space['ren_generator_02'],\n",
    "                           {}),\n",
    "                'ren_06': (None,\n",
    "                           env.observation_space['ren_generator_06'],\n",
    "                           env.action_space['ren_generator_06'],\n",
    "                           {}),\n",
    "                'ren_13': (None,\n",
    "                           env.observation_space['ren_generator_13'],\n",
    "                           env.action_space['ren_generator_13'],\n",
    "                           {}),\n",
    "                'storage_01': (None,\n",
    "                               env.observation_space['storage_01'],\n",
    "                               env.action_space['storage_01'],\n",
    "                               {}),\n",
    "                'storage_02': (None,\n",
    "                               env.observation_space['storage_02'],\n",
    "                               env.action_space['storage_02'],\n",
    "                               {}),\n",
    "                'storage_03': (None,\n",
    "                               env.observation_space['storage_03'],\n",
    "                               env.action_space['storage_03'],\n",
    "                               {}),\n",
    "                }\n",
    "    \n",
    "    return policies\n",
    "\n",
    "def assign_group_policies_v4(env):\n",
    "\n",
    "    policies = {'generator_renewable': (None,\n",
    "                                        env.observation_space['ren_generator_08'],\n",
    "                                        env.action_space['ren_generator_08'],\n",
    "                                        {}),\n",
    "                'storage_01': (None,\n",
    "                               env.observation_space['storage_01'],\n",
    "                               env.action_space['storage_01'],\n",
    "                               {}),\n",
    "                'storage_02': (None,\n",
    "                               env.observation_space['storage_02'],\n",
    "                               env.action_space['storage_02'],\n",
    "                               {}),\n",
    "                'storage_03': (None,\n",
    "                               env.observation_space['storage_03'],\n",
    "                               env.action_space['storage_03'],\n",
    "                               {}),\n",
    "                }\n",
    "\n",
    "    return policies\n",
    "\n",
    "policies = assign_group_policies_v3(env=temp_env)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T03:16:35.636135Z",
     "start_time": "2024-08-24T03:16:35.630019Z"
    }
   },
   "id": "665c1352bde7814a",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datapoint 2019-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(RolloutWorker pid=38781)\u001B[0m 2024-08-24 04:16:45,046\tWARNING env_runner_v2.py:155 -- More than 6696 observations in 6696 env steps for episode 459653279789532117 are buffered in the sampler. If this is more than you expected, check that that you set a horizon on your environment correctly and that it terminates at some point. Note: In multi-agent environments, `rollout_fragment_length` sets the batch size based on (across-agents) environment steps, not the steps of individual agents, which can result in unexpectedly large batches.Also, you may be waiting for your Env to terminate (batch_mode=`complete_episodes`). Make sure it does at some point.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0; avg. reward=-37532.54730000007\n",
      "Iter: 1; avg. reward=-23602.133000000023\n",
      "Iter: 2; avg. reward=-17757.321133333346\n",
      "Iter: 3; avg. reward=-13586.62085000001\n",
      "Iter: 4; avg. reward=-11288.289599999995\n",
      "Iter: 5; avg. reward=-9488.124333333331\n",
      "Iter: 6; avg. reward=-8084.3909\n",
      "Iter: 7; avg. reward=-6873.9564375\n",
      "Iter: 8; avg. reward=-6157.167522222226\n",
      "Iter: 9; avg. reward=-5399.711669999995\n",
      "Iter: 10; avg. reward=-4752.928599999989\n",
      "Iter: 11; avg. reward=-4183.2311916666495\n",
      "Iter: 12; avg. reward=-3737.404776923055\n",
      "Iter: 13; avg. reward=-3318.4821999999717\n",
      "Iter: 14; avg. reward=-2963.2609599999646\n",
      "Iter: 15; avg. reward=-2628.0275249999563\n",
      "Iter: 16; avg. reward=-2327.3668235293608\n",
      "Iter: 17; avg. reward=-2087.315527777723\n",
      "Iter: 18; avg. reward=-1883.60173157889\n",
      "Iter: 19; avg. reward=-1707.3059199999436\n",
      "Iter: 20; avg. reward=-1517.3649952380329\n",
      "Iter: 21; avg. reward=-1404.5028318181214\n",
      "Iter: 22; avg. reward=-1256.1769695651537\n",
      "Iter: 23; avg. reward=-1089.6715541665978\n",
      "Iter: 24; avg. reward=-975.5021479999272\n",
      "Iter: 25; avg. reward=-834.6488538460761\n",
      "Iter: 26; avg. reward=-781.3794703702938\n",
      "Iter: 27; avg. reward=-680.7562321427762\n",
      "Iter: 28; avg. reward=-559.9674965516397\n",
      "Iter: 29; avg. reward=-464.94547666658013\n",
      "Iter: 30; avg. reward=-390.9620741934584\n",
      "Iter: 31; avg. reward=-289.89662499990663\n",
      "Iter: 32; avg. reward=-260.4254787877893\n",
      "Iter: 33; avg. reward=-268.781308823444\n",
      "Iter: 34; avg. reward=-228.8824885713443\n",
      "Iter: 35; avg. reward=-148.51166388880225\n",
      "Iter: 36; avg. reward=-81.60136216207476\n",
      "Iter: 37; avg. reward=-60.94753421044192\n",
      "Iter: 38; avg. reward=-16.060623076838212\n",
      "Iter: 39; avg. reward=50.71665000008752\n",
      "Iter: 40; avg. reward=115.16639756106585\n",
      "Iter: 41; avg. reward=176.09303095247287\n",
      "Iter: 42; avg. reward=193.38423255822792\n",
      "Iter: 43; avg. reward=241.986959090998\n",
      "Iter: 44; avg. reward=292.2269311112014\n",
      "Iter: 45; avg. reward=335.7126000000921\n",
      "Iter: 46; avg. reward=382.8929489362646\n",
      "Iter: 47; avg. reward=369.3579062500914\n",
      "Iter: 48; avg. reward=397.8194877551932\n",
      "Iter: 49; avg. reward=428.78528200009174\n",
      "Iter: 50; avg. reward=466.0696725491126\n",
      "Iter: 51; avg. reward=488.69451538470935\n",
      "Iter: 52; avg. reward=509.0442000000955\n",
      "Iter: 53; avg. reward=554.4267481482456\n",
      "Iter: 54; avg. reward=543.9106400000968\n",
      "Iter: 55; avg. reward=565.5244857143838\n",
      "Iter: 56; avg. reward=579.8570543860644\n",
      "Iter: 57; avg. reward=609.4530310345825\n",
      "Iter: 58; avg. reward=649.2577508475591\n",
      "Iter: 59; avg. reward=660.8758383334346\n",
      "Iter: 60; avg. reward=675.2705836066599\n",
      "Iter: 61; avg. reward=696.1469774194582\n",
      "Iter: 62; avg. reward=699.6893269842284\n",
      "Iter: 63; avg. reward=700.694017187601\n",
      "Iter: 64; avg. reward=729.0641861539486\n",
      "Iter: 65; avg. reward=762.7088287879828\n",
      "Iter: 66; avg. reward=793.2156089553289\n",
      "Iter: 67; avg. reward=798.4185455883401\n",
      "Iter: 68; avg. reward=821.4122971015541\n",
      "Iter: 69; avg. reward=843.3475657143917\n",
      "Iter: 70; avg. reward=872.7902887325017\n",
      "Iter: 71; avg. reward=898.6523152778859\n",
      "Iter: 72; avg. reward=908.4585191781903\n",
      "Iter: 73; avg. reward=917.1246243244321\n",
      "Iter: 74; avg. reward=939.9044520001084\n",
      "Iter: 75; avg. reward=940.6426000001081\n",
      "Iter: 76; avg. reward=944.3413155845228\n",
      "Iter: 77; avg. reward=960.4279474360054\n",
      "Iter: 78; avg. reward=981.2988202532736\n",
      "Iter: 79; avg. reward=991.5442612501095\n",
      "Iter: 80; avg. reward=1011.4831395062829\n",
      "Iter: 81; avg. reward=1024.788079268403\n",
      "Iter: 82; avg. reward=1041.4528927711951\n",
      "Iter: 83; avg. reward=1005.3835976191568\n",
      "Iter: 84; avg. reward=997.6892023530486\n",
      "Iter: 85; avg. reward=1011.6135534884795\n",
      "Iter: 86; avg. reward=1022.9261574713719\n",
      "Iter: 87; avg. reward=1018.3070590910157\n",
      "Iter: 88; avg. reward=1028.927676404601\n",
      "Iter: 89; avg. reward=1041.8939133334402\n",
      "Iter: 90; avg. reward=1054.6151043957116\n",
      "Iter: 91; avg. reward=1067.2877250001077\n",
      "Iter: 92; avg. reward=1043.1258591398907\n",
      "Iter: 93; avg. reward=1047.194237234148\n",
      "Iter: 94; avg. reward=1038.5250473685257\n",
      "Iter: 95; avg. reward=1050.7199885417713\n",
      "Iter: 96; avg. reward=1064.9758536083525\n",
      "Iter: 97; avg. reward=1061.7669489796958\n",
      "Iter: 98; avg. reward=1067.440935353639\n",
      "Iter: 99; avg. reward=1058.6459220001022\n",
      "Iter: 100; avg. reward=1437.4610190001026\n",
      "Iter: 101; avg. reward=1548.1549590001048\n",
      "Iter: 102; avg. reward=1631.014308000106\n",
      "Iter: 103; avg. reward=1662.2123820001073\n",
      "Iter: 104; avg. reward=1709.812650000108\n",
      "Iter: 105; avg. reward=1739.1722100001105\n",
      "Iter: 106; avg. reward=1758.153698000112\n",
      "Iter: 107; avg. reward=1768.0091990001138\n",
      "Iter: 108; avg. reward=1791.820356000115\n",
      "Iter: 109; avg. reward=1801.5490130001158\n",
      "Iter: 110; avg. reward=1796.5341640001147\n",
      "Iter: 111; avg. reward=1793.5456810001142\n",
      "Iter: 112; avg. reward=1789.9013570001134\n",
      "Iter: 113; avg. reward=1773.2798620001115\n",
      "Iter: 114; avg. reward=1761.6996570001108\n",
      "Iter: 115; avg. reward=1756.4022510001105\n",
      "Iter: 116; avg. reward=1750.2298270001097\n",
      "Iter: 117; avg. reward=1738.9398750001078\n",
      "Iter: 118; avg. reward=1741.7989350001083\n",
      "Iter: 119; avg. reward=1734.030319000107\n",
      "Iter: 120; avg. reward=1727.8507890001065\n",
      "Iter: 121; avg. reward=1734.7822880001074\n",
      "Iter: 122; avg. reward=1737.3130120001072\n",
      "Iter: 123; avg. reward=1736.4380260001074\n",
      "Iter: 124; avg. reward=1744.2018990001077\n",
      "Iter: 125; avg. reward=1729.7346600001065\n",
      "Iter: 126; avg. reward=1736.2943770001082\n",
      "Iter: 127; avg. reward=1742.358163000108\n",
      "Iter: 128; avg. reward=1734.8503640001084\n",
      "Iter: 129; avg. reward=1736.6370990001085\n",
      "Iter: 130; avg. reward=1743.0614400001086\n",
      "Iter: 131; avg. reward=1741.2777050001084\n",
      "Iter: 132; avg. reward=1755.2349490001097\n",
      "Iter: 133; avg. reward=1773.444672000112\n",
      "Iter: 134; avg. reward=1778.0838040001129\n",
      "Iter: 135; avg. reward=1782.090823000113\n",
      "Iter: 136; avg. reward=1749.6143190001112\n",
      "Iter: 137; avg. reward=1759.400028000113\n",
      "Iter: 138; avg. reward=1751.2000130001115\n",
      "Iter: 139; avg. reward=1745.2986360001116\n",
      "Iter: 140; avg. reward=1741.2177240001108\n",
      "Iter: 141; avg. reward=1735.1990390001113\n",
      "Iter: 142; avg. reward=1726.6658460001113\n",
      "Iter: 143; avg. reward=1723.9358500001115\n",
      "Iter: 144; avg. reward=1719.6091540001112\n",
      "Iter: 145; avg. reward=1723.2183380001113\n",
      "Iter: 146; avg. reward=1722.1717420001116\n",
      "Iter: 147; avg. reward=1743.4435940001129\n",
      "Iter: 148; avg. reward=1740.5095760001122\n",
      "Iter: 149; avg. reward=1727.7667660001107\n",
      "Iter: 150; avg. reward=1719.0381030001092\n",
      "Iter: 151; avg. reward=1715.384465000108\n",
      "Iter: 152; avg. reward=1710.418607000106\n",
      "Iter: 153; avg. reward=1702.9400790001057\n",
      "Iter: 154; avg. reward=1717.8711330001063\n",
      "Iter: 155; avg. reward=1716.9859070001057\n",
      "Iter: 156; avg. reward=1715.931458000105\n",
      "Iter: 157; avg. reward=1707.7429050001049\n",
      "Iter: 158; avg. reward=1694.8526870001047\n",
      "Iter: 159; avg. reward=1685.892608000103\n",
      "Iter: 160; avg. reward=1691.0963790001033\n",
      "Iter: 161; avg. reward=1689.731332000102\n",
      "Iter: 162; avg. reward=1702.9000900001038\n",
      "Iter: 163; avg. reward=1709.8794760001028\n",
      "Iter: 164; avg. reward=1703.031388000101\n",
      "Iter: 165; avg. reward=1692.2874030000999\n",
      "Iter: 166; avg. reward=1672.8821780000978\n",
      "Iter: 167; avg. reward=1679.7483670000988\n",
      "Iter: 168; avg. reward=1660.3656410000974\n",
      "Iter: 169; avg. reward=1651.3096600000968\n",
      "Iter: 170; avg. reward=1648.4827830000968\n",
      "Iter: 171; avg. reward=1645.7842980000971\n",
      "Iter: 172; avg. reward=1653.8855230000981\n",
      "Iter: 173; avg. reward=1655.082635000099\n",
      "Iter: 174; avg. reward=1651.3672260000985\n",
      "Iter: 175; avg. reward=1664.1755070000995\n",
      "Iter: 176; avg. reward=1662.5028420001001\n",
      "Iter: 177; avg. reward=1663.0804930001\n",
      "Iter: 178; avg. reward=1647.6836040000978\n",
      "Iter: 179; avg. reward=1648.3516380000979\n",
      "Iter: 180; avg. reward=1643.0088540000984\n",
      "Iter: 181; avg. reward=1644.5713390000985\n",
      "Iter: 182; avg. reward=1639.3359180000987\n",
      "Iter: 183; avg. reward=1686.0217830001004\n",
      "Iter: 184; avg. reward=1699.203479000102\n",
      "Iter: 185; avg. reward=1701.3672780001025\n",
      "Iter: 186; avg. reward=1700.2377530001022\n",
      "Iter: 187; avg. reward=1720.8625100001038\n",
      "Iter: 188; avg. reward=1717.934381000104\n",
      "Iter: 189; avg. reward=1716.7321390001043\n",
      "Iter: 190; avg. reward=1713.2083390001044\n",
      "Iter: 191; avg. reward=1709.7522790001035\n",
      "Iter: 192; avg. reward=1740.3201280001051\n",
      "Iter: 193; avg. reward=1730.9271420001041\n",
      "Iter: 194; avg. reward=1745.6933450001043\n",
      "Iter: 195; avg. reward=1744.441783000105\n",
      "Iter: 196; avg. reward=1730.1193420001032\n",
      "Iter: 197; avg. reward=1733.6126950001035\n",
      "Iter: 198; avg. reward=1732.2623560001034\n",
      "Iter: 199; avg. reward=1751.6857360001052\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "# Create an RLlib Algorithm instance from a PPOConfig to learn how to\n",
    "# act in the above environment.\n",
    "\n",
    "from ray.tune import register_env\n",
    "from ray.train import Checkpoint\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "IMPORT_PENALTY = 1 #100\n",
    "EXPORT_PENALTY = 1 #10\n",
    "STORAGE_ACTION_PENALTY = 5 #100\n",
    "STORAGE_ACTION_REWARD = 5 #10\n",
    "EV_ACTION_PENALTY = 1 #1000\n",
    "EV_ACTION_REWARD = 5 #10\n",
    "EV_REQUIREMENT_PENALTY = 100 #3000\n",
    "BALANCE_PENALTY = 5000 #20000\n",
    "\n",
    "checkpoint = None\n",
    "checkpoint_path = None\n",
    "algo = None\n",
    "current_best = None\n",
    "\n",
    "# Months per day:\n",
    "# January: 0:31 -> DONE\n",
    "# February: 31:59 -> DONE\n",
    "# March: 59:90 -> DONE\n",
    "# April: 90:120 -> DONE\n",
    "# May: 120:151 -> DONE\n",
    "# June: 151:181 -> DONE\n",
    "# July: 181:212 -> DONE\n",
    "# August: 212:243 -> DONE\n",
    "# September: 243:273 -> DONE\n",
    "# October: 273:304 -> DONE\n",
    "# November: 304:334 -> DONE\n",
    "# December: 334:365 -> DONE\n",
    "\n",
    "# Build a loop for using separate resources on a daily basis\n",
    "for datapoint in list(dataset_resources.keys())[:1]:\n",
    "    \n",
    "    temp_resources = dataset_resources[datapoint]\n",
    "    \n",
    "    env = EnergyCommunitySequentialV7(ren_generators=temp_resources[:5],\n",
    "                                      generators=[],#temp_resources[5:7],\n",
    "                                      loads=temp_resources[5:10],\n",
    "                                      storages=temp_resources[10:13],\n",
    "                                      evs=[], #temp_resources[13:-1],\n",
    "                                      aggregator=temp_resources[-1],\n",
    "                                      storage_penalty=STORAGE_ACTION_PENALTY,\n",
    "                                      ev_penalty=EV_REQUIREMENT_PENALTY,\n",
    "                                      balance_penalty=BALANCE_PENALTY,\n",
    "                                      execution_order=execution_order)\n",
    "\n",
    "    register_env(\"EC_Multi\", lambda config: env)\n",
    "\n",
    "    # Define the PPOConfig\n",
    "    config = PPOConfig() \\\n",
    "        .environment(env=\"EC_Multi\", disable_env_checking=False)\\\n",
    "        .training(train_batch_size=128,\n",
    "                  lr=2e-4, #tune.grid_search([0.001, 0.0001]),\n",
    "                  gamma=0.99,\n",
    "                  use_gae=True,\n",
    "                  use_critic=True,\n",
    "                  #model={#'fcnet_activation': 'linear',\n",
    "                         #'post_fcnet_activation': 'linear',\n",
    "                         #'use_lstm': True,\n",
    "                         #'fcnet_hiddens': [64, 64],\n",
    "                         #'lstm_cell_size': 256,\n",
    "                         #'max_seq_len': 2,\n",
    "                         #'lstm_use_prev_action': True,\n",
    "                         #'lstm_use_prev_reward': True,\n",
    "                         #'vf_share_layers': True\n",
    "                  #      }\n",
    "                )\\\n",
    "        .framework('torch') \\\n",
    "        .rollouts(batch_mode='complete_episodes', #'complete_episodes',\n",
    "                  num_rollout_workers=1,\n",
    "                  rollout_fragment_length='auto')\\\n",
    "        .multi_agent(policies={'ren_08': (None,\n",
    "                                          env.observation_space['ren_generator_08'],\n",
    "                                          env.action_space['ren_generator_08'],\n",
    "                                          PPOConfig.overrides(gamma=0.0)),\n",
    "                               'ren_09': (None,\n",
    "                                          env.observation_space['ren_generator_09'],\n",
    "                                          env.action_space['ren_generator_09'],\n",
    "                                          PPOConfig.overrides(gamma=0.0)),\n",
    "                               'ren_02': (None,\n",
    "                                          env.observation_space['ren_generator_02'],\n",
    "                                          env.action_space['ren_generator_02'],\n",
    "                                          PPOConfig.overrides(gamma=0.0)),\n",
    "                               'ren_06': (None,\n",
    "                                          env.observation_space['ren_generator_06'],\n",
    "                                          env.action_space['ren_generator_06'],\n",
    "                                          PPOConfig.overrides(gamma=0.0)),\n",
    "                               'ren_13': (None,\n",
    "                                          env.observation_space['ren_generator_13'],\n",
    "                                          env.action_space['ren_generator_13'],\n",
    "                                          PPOConfig.overrides(gamma=0.0)),\n",
    "                               'storage_01': (None,\n",
    "                                              env.observation_space['storage_01'],\n",
    "                                              env.action_space['storage_01'],\n",
    "                                              PPOConfig.overrides(gamma=0.9)),\n",
    "                               'storage_02': (None,\n",
    "                                              env.observation_space['storage_02'],\n",
    "                                              env.action_space['storage_02'],\n",
    "                                              PPOConfig.overrides(gamma=0.9)),\n",
    "                               'storage_03': (None,\n",
    "                                              env.observation_space['storage_03'],\n",
    "                                              env.action_space['storage_03'],\n",
    "                                              PPOConfig.overrides(gamma=0.9)),\n",
    "                               'aggregator': (None,\n",
    "                                              env.observation_space['aggregator'],\n",
    "                                              env.action_space['aggregator'],\n",
    "                                              PPOConfig.overrides(gamma=0.9))},\n",
    "                     policy_mapping_fn=(lambda agent_id, episode, worker, **kwargs:\n",
    "                                        #'generator_renewable' if agent_id.startswith('ren_generator') else\n",
    "                                        'ren_08' if agent_id.startswith('ren_generator_08') else\n",
    "                                        'ren_09' if agent_id.startswith('ren_generator_09') else\n",
    "                                        'ren_02' if agent_id.startswith('ren_generator_02') else\n",
    "                                        'ren_06' if agent_id.startswith('ren_generator_06') else\n",
    "                                        'ren_13' if agent_id.startswith('ren_generator_13') else\n",
    "                                        'storage_01' if agent_id.startswith('storage_01') else\n",
    "                                        'storage_02' if agent_id.startswith('storage_02') else\n",
    "                                        'storage_03' if agent_id.startswith('storage_03') else\n",
    "                                        'aggregator'\n",
    "                                        #'ev_01' if agent_id.startswith('ev_01') else\n",
    "                                        #'ev_02' if agent_id.startswith('ev_02') else\n",
    "                                        #'ev_03' if agent_id.startswith('ev_03') else\n",
    "                                        #'ev_04' if agent_id.startswith('ev_04') else\n",
    "                                        #'ev_05'\n",
    "                                        ))\n",
    "    \n",
    "    # if agent_id.startswith('ev') else\n",
    "                                        #'generator_non_renewable'))\n",
    "\n",
    "    #results = tune.run(\n",
    "    #    \"PPO\",\n",
    "    #    stop={\"training_iteration\": 100},\n",
    "    #    config=config.to_dict(),\n",
    "    #    checkpoint_at_end=True,\n",
    "    #    verbose=0,\n",
    "    #)\n",
    "    algo = config.build()\n",
    "    \n",
    "    '''\n",
    "    # Load the checkpoint if it exists\n",
    "    if checkpoint is not None:\n",
    "        policy = Policy.from_checkpoint(checkpoint.checkpoint.path)\n",
    "    \n",
    "        for p in policies.keys():\n",
    "            if p in policy.keys():\n",
    "                algo.get_policy(p).set_weights(policy[p].get_weights())\n",
    "    elif checkpoint_path is not None:\n",
    "        checkpoint = Checkpoint.from_directory(checkpoint_path)\n",
    "        policy = Policy.from_checkpoint(checkpoint)\n",
    "    \n",
    "        for p in policies.keys():\n",
    "            if p in policy.keys():\n",
    "                algo.get_policy(p).set_weights(policy[p].get_weights())\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Clear the Jupyter cell output\n",
    "    IPython.core.display_functions.clear_output()\n",
    "    \n",
    "    # Train for n iterations and report results (mean episode rewards)\n",
    "    print(f\"Datapoint {datapoint}\\n\")\n",
    "    for i in range(200):\n",
    "        results = algo.train()\n",
    "        print(f\"Iter: {i}; avg. reward={results['episode_reward_mean']}\")\n",
    "        # print(f\"Policy rewards: {results['policy_reward_mean']}\")\n",
    "        # if results['episode_reward_mean'] > 500:\n",
    "        #     break\n",
    "        # if results['episode_reward_mean'] > current_best_results['episode_reward_mean']:\n",
    "        #     current_best = algo.save()\n",
    "        #     current_best_results = results\n",
    "\n",
    "\n",
    "\n",
    "# if results['episode_reward_mean'] < 500:\n",
    "        # Save the checkpoint to disk.\n",
    "        # checkpoint = algo.save()\n",
    "        # algo.save('/Users/ecgomes/DataspellProjects/pyecom/models/sequential_v6_nogen_fullpenalty_{}'.format(datapoint))\n",
    "        \n",
    "    # else:\n",
    "    #    break\n",
    "    # print(\"checkpoints saved at\", checkpoint)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "204b37883758a647",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/ecgomes/DataspellProjects/pyecom/models/no_costs/sequential_monthly_noev_v1), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'__all__': {'num_agent_steps_trained': 1152.0, 'num_env_steps_trained': 744.0, 'total_loss': 3.2134428586278645}, 'ren_08': {'total_loss': 3.2134428586278645, 'policy_loss': 0.0003935329509632928, 'vf_loss': 3.8432056348775796e-08, 'vf_loss_unclipped': 3.8432056348775796e-08, 'vf_explained_var': -1.0, 'entropy': 0.00032196849027449, 'mean_kl_loss': -1.635482569543432e-08, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 0.0}, 'ren_06': {'total_loss': -0.00019010848232678005, 'policy_loss': -0.00019013179200036185, 'vf_loss': 2.6834569862696105e-08, 'vf_loss_unclipped': 2.6834569862696105e-08, 'vf_explained_var': -1.0, 'entropy': 0.00014740432080413614, 'mean_kl_loss': 2.3265230955043277e-09, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 0.0}, 'ren_02': {'total_loss': -0.010277627514941351, 'policy_loss': -0.010291964784264564, 'vf_loss': 1.4335616684125593e-05, 'vf_loss_unclipped': 1.4335616684125593e-05, 'vf_explained_var': -0.6884876448767526, 'entropy': 0.0006800597541899022, 'mean_kl_loss': 0.0006992797296973171, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 0.0}, 'ren_09': {'total_loss': -0.10248820932848113, 'policy_loss': -0.12792882872479303, 'vf_loss': 0.025440620593726634, 'vf_loss_unclipped': 0.025440620593726634, 'vf_explained_var': 0.8299821131569999, 'entropy': 0.0835696718948228, 'mean_kl_loss': 1.271115377986272, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 0.0}, 'ren_13': {'total_loss': -0.0005029196478426456, 'policy_loss': -0.0005041627532669476, 'vf_loss': 1.2438268782131801e-06, 'vf_loss_unclipped': 1.2438268782131801e-06, 'vf_explained_var': -1.0, 'entropy': 0.0013217346503266267, 'mean_kl_loss': 1.1069286522780163e-07, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 0.0}, 'storage_01': {'total_loss': 1.2456038270837495, 'policy_loss': -0.05603752492793969, 'vf_loss': 1.2910262685694864, 'vf_loss_unclipped': 563.3486728874807, 'vf_explained_var': 0.41947635275976997, 'entropy': 1.9764909539903914, 'mean_kl_loss': 0.008283691611750205, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 1.2814453840255737}, 'storage_02': {'total_loss': 1.30446329266099, 'policy_loss': -0.04599755363804953, 'vf_loss': 1.33340530029365, 'vf_loss_unclipped': 562.6250947540998, 'vf_explained_var': 0.43948335783822196, 'entropy': 1.627935265132359, 'mean_kl_loss': 0.011229987557927847, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 1.5187500715255737}, 'storage_03': {'total_loss': -0.040849734864064624, 'policy_loss': -0.09265714193295155, 'vf_loss': 0.03770021908783487, 'vf_loss_unclipped': 0.03770021908783487, 'vf_explained_var': 0.5531820620809282, 'entropy': 1.933479997089931, 'mean_kl_loss': 0.018577366666145307, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 0.7593750357627869}, 'aggregator': {'total_loss': 0.8172907768828528, 'policy_loss': -0.0013235826577459064, 'vf_loss': 0.8186143669060298, 'vf_loss_unclipped': 0.8220456220422472, 'vf_explained_var': 0.1946834019252232, 'entropy': 0.0, 'mean_kl_loss': 0.0, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 0.0}}, 'num_env_steps_sampled': 1339200, 'num_env_steps_trained': 0, 'num_agent_steps_sampled': 1339200, 'num_agent_steps_trained': 0}, 'sampler_results': {'episode_reward_max': 3065.1691000002006, 'episode_reward_min': -920.4809000000391, 'episode_reward_mean': 1751.6857360001052, 'episode_len_mean': 6696.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {'ren_08': 593.5999999999937, 'ren_06': 636.899999999994, 'ren_02': 587.199999999994, 'ren_09': 516.5999999999946, 'ren_13': 399.49999999999886, 'storage_01': -1993.7887000000003, 'storage_02': -2008.0776999999994, 'storage_03': -1810.0985000000003, 'aggregator': -276.71850000000006}, 'policy_reward_max': {'ren_08': 669.5999999999907, 'ren_06': 669.5999999999907, 'ren_02': 669.5999999999907, 'ren_09': 669.5999999999907, 'ren_13': 669.5999999999907, 'storage_01': 9.541000000000013, 'storage_02': -5.230999999999995, 'storage_03': -5.2746000000000075, 'aggregator': -253.3029000000001}, 'policy_reward_mean': {'ren_08': 668.2779999999907, 'ren_06': 669.0949999999907, 'ren_02': 667.8779999999907, 'ren_09': 666.2359999999908, 'ren_13': 663.202999999991, 'storage_01': -467.316385, 'storage_02': -485.2398869999999, 'storage_03': -365.7283990000001, 'aggregator': -264.71959300000003}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [348.96239999997806, 1397.675300000198, 2218.23750000013, 2045.2874000001134, 2665.062200000156, 2448.658000000203, 2236.158500000154, 2584.6349000001665, 1958.2595000001277, 2390.2567000001172, 1213.4171999999865, 1784.5920000000735, 1248.0797999999793, 465.3617999999571, 851.8159000000488, 1870.7334000001288, 1865.9620000000687, 864.5612999999388, 2069.1526000001577, 865.4528999999454, 1663.5005000000856, 1658.7525000001558, 2260.0644000001307, 2652.4544000002024, 2540.9509000001726, 1239.9596000000781, 1259.596200000182, 2642.4498000002095, 2071.337200000176, 2469.3666000001786, 2470.974100000188, 2664.7588000001733, 2078.3756000000767, 1276.4486000002037, 1591.5906000001103, 3065.1691000002006, -920.4809000000391, 1681.8150000001829, 869.6404999999392, 2064.892600000181, 2285.0651000001208, 2072.2165000001824, 66.29539999996727, 2058.9046000001267, 2070.116100000127, 2653.486100000213, 2448.529400000207, 1860.3961000000754, 1470.57360000002, 671.8281999999339, 1457.4229000000241, 1277.197700000036, 1070.6419999999773, 2211.84900000013, 1469.1462000001732, 1665.7634000001267, 1277.036000000099, 1477.5684000000638, 1668.9097000001534, 450.33509999995084, 2059.332400000205, 1833.102300000039, 2236.190800000152, 1461.9281000000035, 1859.9462000000453, 1875.2121000000693, 866.1406000000168, 1833.6342000001378, 446.7147999999337, 1451.2830000001243, 2651.0932000002003, 2465.0077000002066, 2424.6277000001987, 1669.4615000001845, 2254.070800000097, 2276.8318000001764, 1058.1772000000935, 2256.8637000001563, 1069.5379999999816, 1867.7375000001537, 2072.3150000001833, 2258.7367000001937, 1884.4255000001267, 2680.2186000002043, 1669.5296000000992, 2411.5633000001576, 1882.8576000000764, 2678.921200000181, 1670.7291000001226, 2075.6648000001555, 1847.1423000001428, 1874.890200000075, 1877.0191000000714, 486.2547999999602, 1700.241500000059, 2084.083200000208, 1001.2947999999667, 1099.8385000000435, 1488.4577000000695, 2130.277600000108], 'episode_lengths': [6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696], 'policy_ren_08_reward': [669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 668.8999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 593.5999999999937, 669.1999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.1999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 615.3999999999955, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.2999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_ren_06_reward': [669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 636.899999999994, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 652.5999999999927, 669.4999999999907, 669.4999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_ren_02_reward': [669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 587.199999999994, 668.4999999999908, 669.2999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 621.4999999999925, 667.3999999999908, 668.9999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 639.2999999999931, 666.1999999999907, 668.3999999999907, 668.9999999999907, 668.9999999999907, 669.3999999999908, 669.3999999999908, 669.3999999999908, 668.9999999999907, 669.3999999999908], 'policy_ren_09_reward': [583.4999999999977, 641.2999999999936, 654.8999999999922, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 664.6999999999921, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 667.1999999999915, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 622.7999999999919, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 516.5999999999946], 'policy_ren_13_reward': [669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 399.49999999999886, 585.0999999999984, 601.7999999999967, 628.0999999999952, 630.599999999995, 661.0999999999916, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 665.199999999991, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 633.7999999999947, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 581.5999999999942, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_storage_01_reward': [-1006.4506999999998, -202.98979999999992, -402.03049999999985, -605.8495, -201.11620000000045, -2.7475999999999994, -397.66909999999973, -5.3797999999999995, -198.8077000000002, 6.105399999999991, -1397.0602000000006, 4.5447999999999915, -1394.0956999999985, -1993.7887000000003, -1793.7385000000017, -794.9615000000001, -996.7295999999998, -396.89820000000014, -791.5785999999998, -596.1867999999996, -996.2135000000004, -595.6337999999993, -399.3549999999998, -2.3665000000000083, 1.7788999999999962, -201.11320000000023, -597.7572000000001, 0.577299999999994, -194.4763000000002, -394.52570000000054, 4.259699999999998, -192.19750000000005, -991.586999999998, -394.6551000000001, -594.9619000000004, 6.7901000000000185, -992.1008999999988, -592.5021999999998, -989.9481999999995, -196.03070000000008, 9.319199999999997, -793.3395999999993, -989.9742999999994, -393.3673000000002, 5.715800000000004, 9.541000000000013, 7.369800000000001, -790.1016999999987, -390.0882000000002, -586.2825000000003, -789.8082999999997, -1190.438799999999, -1192.3809, 3.229000000000002, -593.747, -393.4967, -392.4028000000002, -395.6061000000001, -193.70590000000007, -593.4776999999999, -592.8317999999996, -592.5695999999999, -196.67590000000075, -594.6371000000004, -799.2502000000001, -988.4271999999999, -194.4662000000003, -594.4870000000006, -800.8152999999995, -399.4466000000001, 1.949499999999994, -392.97549999999984, -194.69300000000038, -193.77180000000013, -396.88370000000054, -393.31280000000004, 4.272699999999995, -396.1665000000006, -599.7582000000012, -395.2248000000003, -796.5739000000003, 3.9808999999999926, -393.9896000000006, -195.30909999999997, -596.2101999999995, -196.72660000000047, -193.38960000000046, 5.870899999999997, -1192.6132999999998, -194.7643000000004, -389.17580000000044, -193.97920000000053, -397.26810000000063, -395.56440000000015, 6.842100000000005, -594.2189999999999, -194.9166000000004, -394.8030000000006, -196.81260000000012, -399.35590000000025], 'policy_storage_02_reward': [-1212.9982, -1431.3855999999994, -226.76120000000014, -215.35240000000002, -202.8936000000003, -211.41560000000007, -35.51649999999996, -204.87219999999996, -27.872199999999985, -617.3622999999994, -218.1965000000001, -1031.333099999998, -18.92439999999998, -410.58379999999994, -420.75429999999983, -5.494800000000008, -209.02659999999995, -1009.1445999999993, -11.132800000000007, -1408.1210999999994, -213.4625999999999, -414.51170000000076, -411.27020000000005, -209.67019999999997, -414.0278000000003, -28.344699999999996, -216.8167999999998, -28.317199999999985, -213.09809999999993, -11.730399999999996, -609.5429999999994, -12.580500000000008, -7.015800000000004, -602.4785000000003, -611.6209, -7.493199999999993, -2008.0776999999994, -403.49140000000017, -1214.3899000000006, -414.72170000000006, -405.60790000000014, -207.9697999999995, -613.4705999999995, -215.28759999999994, -408.75480000000005, -222.5259, -422.78470000000016, -420.6098, -820.7674000000004, -1419.4309999999998, -18.297399999999993, -611.1457000000005, -614.6279999999997, -418.28230000000025, -1013.0440000000001, -1014.0216000000004, -810.7033000000002, -810.3680000000021, -210.6818999999998, -222.3855999999999, -219.14969999999994, -235.91729999999993, -627.5208999999996, -18.3029, -13.54990000000001, -214.8413, -815.4585000000003, -609.5310000000001, -626.5567999999997, -426.87160000000017, -216.89880000000002, -17.824700000000018, -8.652100000000004, -813.2090999999998, -217.00029999999944, -406.4339000000003, -1818.039100000001, -17.756899999999995, -207.53809999999984, -608.7065000000006, -207.4836, -405.2048999999994, -200.2466, -204.22939999999994, -408.6447000000001, -11.762900000000004, -806.2386999999992, -5.230999999999995, -212.92059999999992, -206.65179999999995, -813.5809999999999, -409.3639999999998, -5.479999999999997, -2001.7279999999992, -1395.1811999999975, -406.9794999999999, -1603.3916999999976, -1194.0131999999987, -1402.4381999999994, -400.8869000000005], 'policy_storage_03_reward': [-420.4889999999998, -13.670199999999994, -213.05929999999972, -210.6703, -12.162699999999997, -416.9860000000003, -411.6240999999999, -10.591800000000001, -812.5396999999998, -9.7929, -210.29649999999998, -228.45549999999997, -410.2322999999999, -214.3302, -17.6821, -414.57380000000023, -11.284100000000004, -813.1189999999992, -212.9962000000003, -214.38500000000008, -208.90870000000027, -415.06120000000016, -13.18950000000001, -218.55399999999986, -8.987499999999994, -1606.2759999999998, -1009.9257, -408.4399, -606.6940999999998, -209.72939999999994, -8.878700000000002, -213.56239999999985, -9.69730000000001, -810.0827, -205.07579999999965, -20.714399999999976, -1009.1645999999995, -412.0290000000001, -8.997000000000007, -405.53929999999997, -405.7919999999995, -8.989800000000002, -1416.1431000000014, -411.38789999999983, -609.7133999999996, -210.5644, -216.4451, -11.273000000000005, -406.90279999999973, -406.77379999999977, -816.8166000000002, -8.697700000000001, -204.92199999999966, -407.7310000000005, -9.268700000000008, -7.767399999999999, -604.2455000000007, -405.1727000000006, -1006.2488999999999, -1810.0985000000003, -206.97679999999994, -409.29230000000035, -14.328899999999999, -1006.8329000000017, -406.44030000000043, -5.2746000000000075, -1206.0991999999994, -8.388200000000003, -1205.9088999999983, -802.7146000000004, -211.6228, -207.89549999999966, -409.0846999999997, -405.9963000000001, -211.8948999999998, -8.312000000000003, -209.24199999999973, -406.89119999999957, -1208.7428999999988, -210.71030000000005, -10.202200000000005, -410.2239000000002, -607.4267000000002, -10.21180000000001, -408.72989999999993, -407.97959999999995, -205.8924, -406.57630000000006, -8.420200000000008, -608.3398999999998, -6.393400000000002, -605.2077999999999, -807.2498999999996, -204.60219999999964, -5.3165, -5.572899999999997, -202.3132999999995, -404.7688999999997, -5.433100000000004, -5.927500000000002], 'policy_aggregator_reward': [-272.9997, -273.97909999999985, -273.2114999999995, -270.8403999999999, -266.76530000000025, -268.19280000000026, -267.03180000000003, -272.42130000000014, -266.0208999999999, -268.89349999999996, -267.52959999999996, -268.46419999999995, -268.16779999999983, -263.9354999999998, -264.00919999999996, -262.2364999999997, -264.99770000000007, -264.27690000000024, -263.13980000000015, -263.8541999999999, -265.9146999999998, -264.0408, -264.12089999999984, -264.95490000000024, -270.7127000000002, -271.00649999999996, -263.60409999999996, -269.3704, -262.39429999999993, -262.6478999999998, -262.86389999999983, -264.90079999999983, -261.3243, -259.4351, -268.7507999999999, -261.0133999999998, -259.13770000000005, -258.16240000000005, -264.8243999999999, -266.8157000000002, -260.8542000000001, -265.4843, -262.1166, -269.05259999999976, -265.1315000000003, -266.5646000000001, -267.6106000000002, -265.6193999999998, -259.668, -263.68449999999973, -265.65480000000025, -260.5200999999999, -265.42710000000005, -265.2667000000001, -260.59409999999997, -266.35090000000014, -263.61239999999987, -259.2848000000002, -266.0536000000002, -271.7031000000002, -269.7093, -276.71850000000006, -273.2835000000002, -266.2989999999998, -268.81339999999983, -264.24480000000017, -265.8355, -266.15960000000047, -268.00420000000025, -267.68419999999975, -270.3347000000004, -264.29660000000024, -264.1425000000003, -265.46129999999994, -268.1503000000002, -263.10949999999997, -266.8143999999999, -270.12170000000003, -262.4228000000003, -265.6208999999997, -261.4253, -260.81539999999995, -261.81159999999977, -257.93109999999984, -264.88560000000007, -265.7676000000002, -259.4216999999999, -263.1424000000002, -263.31680000000017, -262.5792000000002, -261.40750000000025, -261.15880000000027, -259.7829000000002, -258.9506000000001, -253.3029000000001, -256.9454000000001, -257.8835999999999, -254.3764000000002, -254.2584000000004, -258.35210000000023]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.13279813368121676, 'mean_inference_ms': 0.3558898719369273, 'mean_action_processing_ms': 0.034635503898619156, 'mean_env_wait_ms': 0.021758446383673594, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.006468454996744792, 'StateBufferConnector_ms': 0.0010921955108642578, 'ViewRequirementAgentConnector_ms': 0.06842184066772461}}, 'episode_reward_max': 3065.1691000002006, 'episode_reward_min': -920.4809000000391, 'episode_reward_mean': 1751.6857360001052, 'episode_len_mean': 6696.0, 'episodes_this_iter': 1, 'policy_reward_min': {'ren_08': 593.5999999999937, 'ren_06': 636.899999999994, 'ren_02': 587.199999999994, 'ren_09': 516.5999999999946, 'ren_13': 399.49999999999886, 'storage_01': -1993.7887000000003, 'storage_02': -2008.0776999999994, 'storage_03': -1810.0985000000003, 'aggregator': -276.71850000000006}, 'policy_reward_max': {'ren_08': 669.5999999999907, 'ren_06': 669.5999999999907, 'ren_02': 669.5999999999907, 'ren_09': 669.5999999999907, 'ren_13': 669.5999999999907, 'storage_01': 9.541000000000013, 'storage_02': -5.230999999999995, 'storage_03': -5.2746000000000075, 'aggregator': -253.3029000000001}, 'policy_reward_mean': {'ren_08': 668.2779999999907, 'ren_06': 669.0949999999907, 'ren_02': 667.8779999999907, 'ren_09': 666.2359999999908, 'ren_13': 663.202999999991, 'storage_01': -467.316385, 'storage_02': -485.2398869999999, 'storage_03': -365.7283990000001, 'aggregator': -264.71959300000003}, 'hist_stats': {'episode_reward': [348.96239999997806, 1397.675300000198, 2218.23750000013, 2045.2874000001134, 2665.062200000156, 2448.658000000203, 2236.158500000154, 2584.6349000001665, 1958.2595000001277, 2390.2567000001172, 1213.4171999999865, 1784.5920000000735, 1248.0797999999793, 465.3617999999571, 851.8159000000488, 1870.7334000001288, 1865.9620000000687, 864.5612999999388, 2069.1526000001577, 865.4528999999454, 1663.5005000000856, 1658.7525000001558, 2260.0644000001307, 2652.4544000002024, 2540.9509000001726, 1239.9596000000781, 1259.596200000182, 2642.4498000002095, 2071.337200000176, 2469.3666000001786, 2470.974100000188, 2664.7588000001733, 2078.3756000000767, 1276.4486000002037, 1591.5906000001103, 3065.1691000002006, -920.4809000000391, 1681.8150000001829, 869.6404999999392, 2064.892600000181, 2285.0651000001208, 2072.2165000001824, 66.29539999996727, 2058.9046000001267, 2070.116100000127, 2653.486100000213, 2448.529400000207, 1860.3961000000754, 1470.57360000002, 671.8281999999339, 1457.4229000000241, 1277.197700000036, 1070.6419999999773, 2211.84900000013, 1469.1462000001732, 1665.7634000001267, 1277.036000000099, 1477.5684000000638, 1668.9097000001534, 450.33509999995084, 2059.332400000205, 1833.102300000039, 2236.190800000152, 1461.9281000000035, 1859.9462000000453, 1875.2121000000693, 866.1406000000168, 1833.6342000001378, 446.7147999999337, 1451.2830000001243, 2651.0932000002003, 2465.0077000002066, 2424.6277000001987, 1669.4615000001845, 2254.070800000097, 2276.8318000001764, 1058.1772000000935, 2256.8637000001563, 1069.5379999999816, 1867.7375000001537, 2072.3150000001833, 2258.7367000001937, 1884.4255000001267, 2680.2186000002043, 1669.5296000000992, 2411.5633000001576, 1882.8576000000764, 2678.921200000181, 1670.7291000001226, 2075.6648000001555, 1847.1423000001428, 1874.890200000075, 1877.0191000000714, 486.2547999999602, 1700.241500000059, 2084.083200000208, 1001.2947999999667, 1099.8385000000435, 1488.4577000000695, 2130.277600000108], 'episode_lengths': [6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696, 6696], 'policy_ren_08_reward': [669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 668.8999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 593.5999999999937, 669.1999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.1999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 615.3999999999955, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.2999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_ren_06_reward': [669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 636.899999999994, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 652.5999999999927, 669.4999999999907, 669.4999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_ren_02_reward': [669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 587.199999999994, 668.4999999999908, 669.2999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 621.4999999999925, 667.3999999999908, 668.9999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 639.2999999999931, 666.1999999999907, 668.3999999999907, 668.9999999999907, 668.9999999999907, 669.3999999999908, 669.3999999999908, 669.3999999999908, 668.9999999999907, 669.3999999999908], 'policy_ren_09_reward': [583.4999999999977, 641.2999999999936, 654.8999999999922, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 664.6999999999921, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 667.1999999999915, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 622.7999999999919, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 516.5999999999946], 'policy_ren_13_reward': [669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 399.49999999999886, 585.0999999999984, 601.7999999999967, 628.0999999999952, 630.599999999995, 661.0999999999916, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 665.199999999991, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 633.7999999999947, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 581.5999999999942, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_storage_01_reward': [-1006.4506999999998, -202.98979999999992, -402.03049999999985, -605.8495, -201.11620000000045, -2.7475999999999994, -397.66909999999973, -5.3797999999999995, -198.8077000000002, 6.105399999999991, -1397.0602000000006, 4.5447999999999915, -1394.0956999999985, -1993.7887000000003, -1793.7385000000017, -794.9615000000001, -996.7295999999998, -396.89820000000014, -791.5785999999998, -596.1867999999996, -996.2135000000004, -595.6337999999993, -399.3549999999998, -2.3665000000000083, 1.7788999999999962, -201.11320000000023, -597.7572000000001, 0.577299999999994, -194.4763000000002, -394.52570000000054, 4.259699999999998, -192.19750000000005, -991.586999999998, -394.6551000000001, -594.9619000000004, 6.7901000000000185, -992.1008999999988, -592.5021999999998, -989.9481999999995, -196.03070000000008, 9.319199999999997, -793.3395999999993, -989.9742999999994, -393.3673000000002, 5.715800000000004, 9.541000000000013, 7.369800000000001, -790.1016999999987, -390.0882000000002, -586.2825000000003, -789.8082999999997, -1190.438799999999, -1192.3809, 3.229000000000002, -593.747, -393.4967, -392.4028000000002, -395.6061000000001, -193.70590000000007, -593.4776999999999, -592.8317999999996, -592.5695999999999, -196.67590000000075, -594.6371000000004, -799.2502000000001, -988.4271999999999, -194.4662000000003, -594.4870000000006, -800.8152999999995, -399.4466000000001, 1.949499999999994, -392.97549999999984, -194.69300000000038, -193.77180000000013, -396.88370000000054, -393.31280000000004, 4.272699999999995, -396.1665000000006, -599.7582000000012, -395.2248000000003, -796.5739000000003, 3.9808999999999926, -393.9896000000006, -195.30909999999997, -596.2101999999995, -196.72660000000047, -193.38960000000046, 5.870899999999997, -1192.6132999999998, -194.7643000000004, -389.17580000000044, -193.97920000000053, -397.26810000000063, -395.56440000000015, 6.842100000000005, -594.2189999999999, -194.9166000000004, -394.8030000000006, -196.81260000000012, -399.35590000000025], 'policy_storage_02_reward': [-1212.9982, -1431.3855999999994, -226.76120000000014, -215.35240000000002, -202.8936000000003, -211.41560000000007, -35.51649999999996, -204.87219999999996, -27.872199999999985, -617.3622999999994, -218.1965000000001, -1031.333099999998, -18.92439999999998, -410.58379999999994, -420.75429999999983, -5.494800000000008, -209.02659999999995, -1009.1445999999993, -11.132800000000007, -1408.1210999999994, -213.4625999999999, -414.51170000000076, -411.27020000000005, -209.67019999999997, -414.0278000000003, -28.344699999999996, -216.8167999999998, -28.317199999999985, -213.09809999999993, -11.730399999999996, -609.5429999999994, -12.580500000000008, -7.015800000000004, -602.4785000000003, -611.6209, -7.493199999999993, -2008.0776999999994, -403.49140000000017, -1214.3899000000006, -414.72170000000006, -405.60790000000014, -207.9697999999995, -613.4705999999995, -215.28759999999994, -408.75480000000005, -222.5259, -422.78470000000016, -420.6098, -820.7674000000004, -1419.4309999999998, -18.297399999999993, -611.1457000000005, -614.6279999999997, -418.28230000000025, -1013.0440000000001, -1014.0216000000004, -810.7033000000002, -810.3680000000021, -210.6818999999998, -222.3855999999999, -219.14969999999994, -235.91729999999993, -627.5208999999996, -18.3029, -13.54990000000001, -214.8413, -815.4585000000003, -609.5310000000001, -626.5567999999997, -426.87160000000017, -216.89880000000002, -17.824700000000018, -8.652100000000004, -813.2090999999998, -217.00029999999944, -406.4339000000003, -1818.039100000001, -17.756899999999995, -207.53809999999984, -608.7065000000006, -207.4836, -405.2048999999994, -200.2466, -204.22939999999994, -408.6447000000001, -11.762900000000004, -806.2386999999992, -5.230999999999995, -212.92059999999992, -206.65179999999995, -813.5809999999999, -409.3639999999998, -5.479999999999997, -2001.7279999999992, -1395.1811999999975, -406.9794999999999, -1603.3916999999976, -1194.0131999999987, -1402.4381999999994, -400.8869000000005], 'policy_storage_03_reward': [-420.4889999999998, -13.670199999999994, -213.05929999999972, -210.6703, -12.162699999999997, -416.9860000000003, -411.6240999999999, -10.591800000000001, -812.5396999999998, -9.7929, -210.29649999999998, -228.45549999999997, -410.2322999999999, -214.3302, -17.6821, -414.57380000000023, -11.284100000000004, -813.1189999999992, -212.9962000000003, -214.38500000000008, -208.90870000000027, -415.06120000000016, -13.18950000000001, -218.55399999999986, -8.987499999999994, -1606.2759999999998, -1009.9257, -408.4399, -606.6940999999998, -209.72939999999994, -8.878700000000002, -213.56239999999985, -9.69730000000001, -810.0827, -205.07579999999965, -20.714399999999976, -1009.1645999999995, -412.0290000000001, -8.997000000000007, -405.53929999999997, -405.7919999999995, -8.989800000000002, -1416.1431000000014, -411.38789999999983, -609.7133999999996, -210.5644, -216.4451, -11.273000000000005, -406.90279999999973, -406.77379999999977, -816.8166000000002, -8.697700000000001, -204.92199999999966, -407.7310000000005, -9.268700000000008, -7.767399999999999, -604.2455000000007, -405.1727000000006, -1006.2488999999999, -1810.0985000000003, -206.97679999999994, -409.29230000000035, -14.328899999999999, -1006.8329000000017, -406.44030000000043, -5.2746000000000075, -1206.0991999999994, -8.388200000000003, -1205.9088999999983, -802.7146000000004, -211.6228, -207.89549999999966, -409.0846999999997, -405.9963000000001, -211.8948999999998, -8.312000000000003, -209.24199999999973, -406.89119999999957, -1208.7428999999988, -210.71030000000005, -10.202200000000005, -410.2239000000002, -607.4267000000002, -10.21180000000001, -408.72989999999993, -407.97959999999995, -205.8924, -406.57630000000006, -8.420200000000008, -608.3398999999998, -6.393400000000002, -605.2077999999999, -807.2498999999996, -204.60219999999964, -5.3165, -5.572899999999997, -202.3132999999995, -404.7688999999997, -5.433100000000004, -5.927500000000002], 'policy_aggregator_reward': [-272.9997, -273.97909999999985, -273.2114999999995, -270.8403999999999, -266.76530000000025, -268.19280000000026, -267.03180000000003, -272.42130000000014, -266.0208999999999, -268.89349999999996, -267.52959999999996, -268.46419999999995, -268.16779999999983, -263.9354999999998, -264.00919999999996, -262.2364999999997, -264.99770000000007, -264.27690000000024, -263.13980000000015, -263.8541999999999, -265.9146999999998, -264.0408, -264.12089999999984, -264.95490000000024, -270.7127000000002, -271.00649999999996, -263.60409999999996, -269.3704, -262.39429999999993, -262.6478999999998, -262.86389999999983, -264.90079999999983, -261.3243, -259.4351, -268.7507999999999, -261.0133999999998, -259.13770000000005, -258.16240000000005, -264.8243999999999, -266.8157000000002, -260.8542000000001, -265.4843, -262.1166, -269.05259999999976, -265.1315000000003, -266.5646000000001, -267.6106000000002, -265.6193999999998, -259.668, -263.68449999999973, -265.65480000000025, -260.5200999999999, -265.42710000000005, -265.2667000000001, -260.59409999999997, -266.35090000000014, -263.61239999999987, -259.2848000000002, -266.0536000000002, -271.7031000000002, -269.7093, -276.71850000000006, -273.2835000000002, -266.2989999999998, -268.81339999999983, -264.24480000000017, -265.8355, -266.15960000000047, -268.00420000000025, -267.68419999999975, -270.3347000000004, -264.29660000000024, -264.1425000000003, -265.46129999999994, -268.1503000000002, -263.10949999999997, -266.8143999999999, -270.12170000000003, -262.4228000000003, -265.6208999999997, -261.4253, -260.81539999999995, -261.81159999999977, -257.93109999999984, -264.88560000000007, -265.7676000000002, -259.4216999999999, -263.1424000000002, -263.31680000000017, -262.5792000000002, -261.40750000000025, -261.15880000000027, -259.7829000000002, -258.9506000000001, -253.3029000000001, -256.9454000000001, -257.8835999999999, -254.3764000000002, -254.2584000000004, -258.35210000000023]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.13279813368121676, 'mean_inference_ms': 0.3558898719369273, 'mean_action_processing_ms': 0.034635503898619156, 'mean_env_wait_ms': 0.021758446383673594, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.006468454996744792, 'StateBufferConnector_ms': 0.0010921955108642578, 'ViewRequirementAgentConnector_ms': 0.06842184066772461}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 1339200, 'num_agent_steps_trained': 0, 'num_env_steps_sampled': 1339200, 'num_env_steps_trained': 0, 'num_env_steps_sampled_this_iter': 6696, 'num_env_steps_trained_this_iter': 0, 'num_env_steps_sampled_throughput_per_sec': 908.6058813802899, 'num_env_steps_trained_throughput_per_sec': 0.0, 'timesteps_total': 1339200, 'num_steps_trained_this_iter': 0, 'agent_timesteps_total': 1339200, 'timers': {'training_iteration_time_ms': 7387.714, 'sample_time_ms': 3683.803, 'synch_weights_time_ms': 5.869}, 'counters': {'num_env_steps_sampled': 1339200, 'num_env_steps_trained': 0, 'num_agent_steps_sampled': 1339200, 'num_agent_steps_trained': 0}, 'done': False, 'episodes_total': 200, 'training_iteration': 200, 'trial_id': 'default', 'date': '2024-08-24_04-42-33', 'timestamp': 1724470953, 'time_this_iter_s': 7.3717358112335205, 'time_total_s': 1548.1934320926666, 'pid': 38726, 'hostname': 'Eduardos-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'env': 'EC_Multi', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0002, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 128, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x2ee3827a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None), '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'ren_08': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'expected_production': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('production': Discrete(10)), {'gamma': 0.0}), 'ren_09': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'expected_production': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('production': Discrete(10)), {'gamma': 0.0}), 'ren_02': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'expected_production': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('production': Discrete(10)), {'gamma': 0.0}), 'ren_06': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'expected_production': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('production': Discrete(10)), {'gamma': 0.0}), 'ren_13': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'expected_production': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('production': Discrete(10)), {'gamma': 0.0}), 'storage_01': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'available_renewable_energy': Box(0.0, 99999.0, (1,), float32), 'available_storage_energy': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'maximum_charge': Box(0.0, 99999.0, (1,), float32), 'maximum_discharge': Box(0.0, 99999.0, (1,), float32), 'soc': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('ctl': Discrete(20)), {'gamma': 0.9}), 'storage_02': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'available_renewable_energy': Box(0.0, 99999.0, (1,), float32), 'available_storage_energy': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'maximum_charge': Box(0.0, 99999.0, (1,), float32), 'maximum_discharge': Box(0.0, 99999.0, (1,), float32), 'soc': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('ctl': Discrete(20)), {'gamma': 0.9}), 'storage_03': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'available_renewable_energy': Box(0.0, 99999.0, (1,), float32), 'available_storage_energy': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'maximum_charge': Box(0.0, 99999.0, (1,), float32), 'maximum_discharge': Box(0.0, 99999.0, (1,), float32), 'soc': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('ctl': Discrete(20)), {'gamma': 0.9}), 'aggregator': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32)), Dict('placeholder': Discrete(1)), {'gamma': 0.9})}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 1}, 'time_since_restore': 1548.1934320926666, 'iterations_since_restore': 200, 'perf': {'cpu_util_percent': 25.619999999999997, 'ram_util_percent': 64.97}})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.save('/Users/ecgomes/DataspellProjects/pyecom/models/no_costs/sequential_monthly_noev_v1')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T03:42:44.995496Z",
     "start_time": "2024-08-24T03:42:44.912279Z"
    }
   },
   "id": "e87b4cd68c23375b",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check the results\n",
    "# Create a new env\n",
    "\n",
    "test_resources = dataset_resources[list(dataset_resources.keys())[0]]\n",
    "\n",
    "test_env = EnergyCommunitySequentialV0(ren_generators=test_resources[:5],\n",
    "                                       generators=test_resources[5:7],\n",
    "                                       loads=test_resources[7:12],\n",
    "                                       storages=test_resources[12:15],\n",
    "                                       evs=test_resources[15:-1],\n",
    "                                       aggregator=test_resources[-1],\n",
    "                                       ev_penalty=1,\n",
    "                                       balance_penalty=BALANCE_PENALTY,\n",
    "                                       execution_order=execution_order)\n",
    "\n",
    "obs, info = test_env.reset()\n",
    "\n",
    "# Set up the terminations and truncations\n",
    "terminations = truncations = {a: False for a in test_env.agents}\n",
    "terminations['__all__'] = False\n",
    "truncations['__all__'] = False\n",
    "\n",
    "while not terminations['__all__'] and not truncations['__all__']:\n",
    "\n",
    "    current_agent = test_env.execution_order[test_env._current_agent_idx]\n",
    "\n",
    "    current_policy = 'generator_renewable' if current_agent.startswith('ren_gen') else \\\n",
    "        'storage' if current_agent.startswith('storage') else \\\n",
    "            'ev' if current_agent.startswith('ev') else \\\n",
    "                'generator_non_renewable'\n",
    "\n",
    "    action_dict = {current_agent: algo.compute_single_action(observation=obs[current_agent],\n",
    "                                                             policy_id=current_policy)}\n",
    "\n",
    "    obs, rewards, terminations, truncations, info = test_env.step(action_dict)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad683417379e3b8d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the generator power output\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(5):\n",
    "    plt.plot(test_env.ren_generators[i].value)\n",
    "\n",
    "plt.legend(['generator_{:02d}'.format(i+1) for i in range(data_ec.generator['p_forecast'].shape[0])])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c3feab2574a47b6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create subplots with the generator values and the forecast\n",
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(10, 10))\n",
    "\n",
    "for i in np.arange(5):\n",
    "    axs[i].plot(test_env.ren_generators[i].value, label='rl_{:02d}'.format(i+1))\n",
    "    axs[i].plot(data_upacs[list(data_upacs.keys())[i]]['pv'].loc['2019-01-01'].values, label='forecast_{:02d}'.format(i+1),\n",
    "                linestyle='--')\n",
    "    \n",
    "    axs[i].legend()\n",
    "    \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd2094b014b68100",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the storage state of charge\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(data_ec.storage['p_charge_limit'].shape[0]):\n",
    "    plt.plot(test_env.storages[i].value * test_env.storages[i].capacity_max)\n",
    "    \n",
    "plt.yticks(np.arange(0, 120, 10))\n",
    "\n",
    "plt.legend(['storage_{:02d}'.format(i+1) for i in range(data_ec.storage['p_charge_limit'].shape[0])])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dff30e2397d292e6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the load values\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(5):\n",
    "    plt.plot(test_env.loads[i].value)\n",
    "    \n",
    "plt.legend(['load_{:02d}'.format(i+1) for i in range(5)])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5410febfe280c103",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check imports and exports\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(test_env.aggregator.imports, label='imports')\n",
    "plt.plot(test_env.aggregator.exports, label='exports')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5ae9575aeeaf40c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check EVs\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for ev in test_env.evs:\n",
    "    plt.plot(ev.value * ev.capacity_max, label=ev.name)\n",
    "\n",
    "plt.yticks(np.arange(0, 80, 5))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74c6a4ca8fa3f912",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for ev in test_env.evs:\n",
    "    print(ev.name)\n",
    "    print(ev.charge)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f60d9ebd62fbe091",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i in range(len(test_env.evs)):\n",
    "    plt.plot(test_env.evs[i].schedule_requirement_soc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d58254a0e27239b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check the sum of values\n",
    "\n",
    "test_prod = pd.DataFrame({'ren_gen': np.sum([test_env.ren_generators[i].value for i in range(5)], axis=0),\n",
    "                          'sdischarge': np.sum([test_env.storages[i].discharge for i in range(3)], axis=0),\n",
    "                          'evdischarge': np.sum([test_env.evs[i].discharge for i in range(5)], axis=0),\n",
    "                          'non_ren_gen': np.sum([test_env.generators[i].value for i in range(2)], axis=0),\n",
    "                          'imports': test_env.aggregator.imports})\n",
    "\n",
    "test_cons = pd.DataFrame({'loads': np.sum([test_env.loads[i].value for i in range(5)], axis=0),\n",
    "                          'scharge': np.sum([test_env.storages[i].charge / test_env.storages[i].charge_efficiency \n",
    "                                             for i in range(3)], axis=0),\n",
    "                          'evcharge': np.sum([test_env.evs[i].charge / test_env.evs[i].charge_efficiency \n",
    "                                              for i in range(5)], axis=0),\n",
    "                          'exports': test_env.aggregator.exports})\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10))\n",
    "\n",
    "test_prod.plot(kind='area', ax=axs[0])\n",
    "test_cons.plot(kind='area', ax=axs[1])\n",
    "\n",
    "axs[2].plot(test_prod.sum(axis=1)[0:], label='prod')\n",
    "axs[2].plot(test_cons.sum(axis=1)[0:], label='cons')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "116e0f9e09d53659",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_prod"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78f7d845fda12af0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_cons"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6867593193aead80",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_env.aggregator.imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56349d9b222d4cf8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "32178670952f7c66"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
