{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from src.parsers import HMParser\n",
    "from src.resources import Aggregator, Generator, Load, Storage, Vehicle\n",
    "from src.algorithms.rl import EnergyCommunitySequentialV0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data parsing\n",
    "\n",
    "data = HMParser(file_path='/Users/ecgomes/DataspellProjects/pyecom/data/EC_V4.xlsx', ec_id=1)\n",
    "data.parse()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define resources\n",
    "\n",
    "resources = []\n",
    "\n",
    "# Add the generators\n",
    "for i in range(data.generator['p_forecast'].shape[0]):\n",
    "    resources.append(Generator(name='generator_{:02d}'.format(i+1),\n",
    "                               value=np.zeros(data.generator['p_forecast'][i].shape),\n",
    "                               lower_bound=np.zeros(data.generator['p_forecast'][i].shape),\n",
    "                               upper_bound=data.generator['p_forecast'][i],\n",
    "                               cost=data.generator['cost_parameter_b'][i],\n",
    "                               cost_nde=data.generator['cost_nde'][i],\n",
    "                               is_renewable=data.generator['type_generator'][i]))\n",
    "\n",
    "# Add the loads\n",
    "for i in range(data.load['p_forecast'].shape[0]):\n",
    "    resources.append(Load(name='load_{:02d}'.format(i+1),\n",
    "                          value=data.load['p_forecast'][i],\n",
    "                          lower_bound=np.zeros(data.load['p_forecast'][i].shape),\n",
    "                          upper_bound=data.load['p_forecast'][i],\n",
    "                          cost=np.ones(data.load['p_forecast'][i].shape),\n",
    "                          cost_cut=data.load['cost_cut'][i],\n",
    "                          cost_reduce=data.load['cost_reduce'][i],\n",
    "                          cost_ens=data.load['cost_ens'][i]))\n",
    "    \n",
    "# Add the storage\n",
    "for i in range(data.storage['p_charge_limit'].shape[0]):\n",
    "    resources.append(Storage(name='storage_{:02d}'.format(i+1),\n",
    "                             value=data.storage['initial_state'][i] * np.ones(data.storage['p_charge_limit'].shape[1]),\n",
    "                             lower_bound=np.ones(data.storage['p_charge_limit'].shape[0]) * data.storage['energy_min_percentage'][i],\n",
    "                             upper_bound=(data.storage['energy_capacity'] * \n",
    "                                          np.ones(data.storage['p_charge_limit'].shape[0])),\n",
    "                             cost=np.ones(data.storage['p_charge_limit'].shape[0]),\n",
    "                             cost_discharge=data.storage['discharge_price'][i],\n",
    "                             cost_charge=data.storage['charge_price'][i],\n",
    "                             capacity_max=data.storage['energy_capacity'][i],\n",
    "                             capacity_min=data.storage['energy_min_percentage'][i],\n",
    "                             initial_charge=data.storage['initial_state'][i],\n",
    "                             discharge_efficiency=data.storage['discharge_efficiency'][i],\n",
    "                             discharge_max=data.storage['p_discharge_limit'][i],\n",
    "                             charge_efficiency=data.storage['charge_efficiency'][i],\n",
    "                             charge_max=data.storage['p_charge_limit'][i],\n",
    "                             capital_cost=np.array([0.05250, 0.10500, 0.01575])))\n",
    "    \n",
    "# Define the Electric Vehicles\n",
    "for i in np.arange(data.vehicle['e_capacity_max'].shape[0]):\n",
    "    new_ev = Vehicle(name='ev_{:02d}'.format(i + 1),\n",
    "                     value=data.vehicle['min_technical_soc'][i] * np.ones(data.vehicle['schedule_charge'][i, :].shape),\n",
    "                     lower_bound=np.ones(data.vehicle['schedule_charge'][i].shape) * \\\n",
    "                                 data.vehicle['min_technical_soc'][i] * data.vehicle['e_capacity_max'][i],\n",
    "                     upper_bound=np.ones(data.vehicle['schedule_charge'][i].shape) * \\\n",
    "                                 data.vehicle['e_capacity_max'][i],\n",
    "                     cost = np.zeros(data.vehicle['schedule_charge'][i].shape),\n",
    "                     cost_discharge=np.ones(data.vehicle['schedule_charge'][i].shape) * \\\n",
    "                                    data.vehicle['discharge_price'][i, 0],\n",
    "                     cost_charge=np.ones(data.vehicle['schedule_charge'][i].shape) * \\\n",
    "                                 data.vehicle['charge_price'][i, 0],\n",
    "                     capacity_max=data.vehicle['e_capacity_max'][i],\n",
    "                     initial_charge=data.vehicle['min_technical_soc'][i],\n",
    "                     min_charge=data.vehicle['min_technical_soc'][i] * data.vehicle['e_capacity_max'][i],\n",
    "                     discharge_efficiency=data.vehicle['charge_efficiency'][i],\n",
    "                     charge_efficiency=data.vehicle['charge_efficiency'][i],\n",
    "                     schedule_connected=data.vehicle['schedule'][i],\n",
    "                     schedule_discharge=data.vehicle['schedule_discharge'][i],\n",
    "                     schedule_charge=data.vehicle['schedule_charge'][i],\n",
    "                     schedule_requirement_soc=data.vehicle['schedule_departure_soc'][i],\n",
    "                     schedule_arrival_soc=data.vehicle['schedule_arrival_soc'][i]\n",
    "                     )\n",
    "    resources.append(new_ev)\n",
    "    \n",
    "# Append Aggregator\n",
    "resources.append(Aggregator(name='aggregator',\n",
    "                            value=np.zeros(data.load['p_forecast'][0, :].shape),\n",
    "                            lower_bound=np.zeros(data.load['p_forecast'][0, :].shape),\n",
    "                            upper_bound=data.peers['import_contracted_p_max'][0, :],\n",
    "                            cost=data.peers['buy_price'][0, :],\n",
    "                            imports=np.zeros(data.load['p_forecast'][0, :].shape),\n",
    "                            exports=np.zeros(data.load['p_forecast'][0, :].shape),\n",
    "                            import_cost=data.peers['buy_price'][0, :],\n",
    "                            export_cost=data.peers['sell_price'][0, :],\n",
    "                            import_max=data.peers['import_contracted_p_max'][0, :],\n",
    "                            export_max=data.peers['export_contracted_p_max'][0, :]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the environment and check if everything is ok\n",
    "\n",
    "temp_env = EnergyCommunitySequentialV0(resources=resources,\n",
    "                                       import_penalty=1000,\n",
    "                                       export_penalty=1000,\n",
    "                                       storage_action_penalty=500,\n",
    "                                       ev_action_penalty=500,\n",
    "                                       ev_requirement_penalty=700,\n",
    "                                       balance_penalty=1000)\n",
    "temp_env.reset()\n",
    "terminations = truncations = {a: False for a in temp_env.agents}\n",
    "terminations['__all__'] = False\n",
    "truncations['__all__'] = False\n",
    "while not terminations['__all__'] and not truncations['__all__']:\n",
    "    actions = temp_env.action_space.sample()\n",
    "    observations, rewards, terminations, truncations, infos = temp_env.step(actions)\n",
    "    # print('Observation: {}'.format(observations))\n",
    "    # print('Observation keys: {}'.format(observations.keys()))\n",
    "    # print('Reward: {}'.format(rewards))\n",
    "    # print('Infos: {}\\n'.format(infos))\n",
    "print('Terminated: {}'.format(terminations['__all__']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check for environment errors\n",
    "\n",
    "ray.rllib.utils.check_env(env=temp_env)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Aux function to assign policies\n",
    "\n",
    "def assign_policies(env):\n",
    "\n",
    "    policies = {}\n",
    "    for agent in env.agents:\n",
    "        policies[agent] = (None,\n",
    "                           env.observation_space[agent],\n",
    "                           env.action_space[agent],\n",
    "                           {})\n",
    "    return policies\n",
    "\n",
    "# policies = assign_policies(env=temp_env)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create the policies dictionary\n",
    "\n",
    "def assign_group_policies(env):\n",
    "    \n",
    "    policies = {'generator': (None,\n",
    "                              env.observation_space['generator_01'],\n",
    "                                env.action_space['generator_01'],\n",
    "                                {}),\n",
    "                'storage': (None,\n",
    "                            env.observation_space['storage_01'],\n",
    "                            env.action_space['storage_01'],\n",
    "                            {}),\n",
    "                'ev': (None,\n",
    "                       env.observation_space['ev_01'],\n",
    "                       env.action_space['ev_01'],\n",
    "                       {}),\n",
    "                'aggregator': (None,\n",
    "                               env.observation_space['aggregator'],\n",
    "                               env.action_space['aggregator'],\n",
    "                               {})           \n",
    "                }\n",
    "    \n",
    "    return policies\n",
    "\n",
    "policies = assign_group_policies(env=temp_env)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create an RLlib Algorithm instance from a PPOConfig to learn how to\n",
    "# act in the above environment.\n",
    "\n",
    "from ray.tune import register_env\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "register_env(\"EC_Multi\", lambda config: EnergyCommunitySequentialV0(resources=resources,\n",
    "                                                                    import_penalty=100,\n",
    "                                                                    export_penalty=100,\n",
    "                                                                    storage_action_penalty=50,\n",
    "                                                                    ev_action_penalty=50,\n",
    "                                                                    ev_requirement_penalty=70,\n",
    "                                                                    balance_penalty=100),\n",
    "             )\n",
    "\n",
    "# Define the PPOConfig\n",
    "config = PPOConfig()\n",
    "config = config.environment(env=\"EC_Multi\")\n",
    "config = config.training(train_batch_size=240,\n",
    "                         lr=2e-4,\n",
    "                         gamma=0.99,\n",
    "                         use_gae=True,\n",
    "                         use_critic=True)\n",
    "config = config.framework('torch')\n",
    "config = config.rollouts(batch_mode='complete_episodes',\n",
    "                        num_rollout_workers=2,\n",
    "                        rollout_fragment_length='auto')\n",
    "config = config.multi_agent(policies=policies,\n",
    "                            policy_mapping_fn=(lambda agent_id, episode, worker, **kwargs: \n",
    "                            'generator' if agent_id.startswith('generator') else\n",
    "                            'storage' if agent_id.startswith('storage') else\n",
    "                            'ev' if agent_id.startswith('ev') else\n",
    "                            'aggregator'))\n",
    "config = config.exploration(exploration_config={})\n",
    "\n",
    "# Use the config's `build()` method to construct a PPO object.\n",
    "algo = config.build()\n",
    "\n",
    "# Train for n iterations and report results (mean episode rewards).\n",
    "checkpoint = None\n",
    "for i in range(200):\n",
    "    results = algo.train()\n",
    "    print(f\"Iter: {i}; avg. reward={results['episode_reward_mean']}\")\n",
    "    if results['episode_reward_mean'] > -50.0:\n",
    "        break\n",
    "\n",
    "    # Save the checkpoint to disk.\n",
    "    # checkpoint = algo.save()\n",
    "    # print(\"checkpoints saved at\", checkpoint)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check the results\n",
    "# Create a new env\n",
    "test_env = EnergyCommunitySequentialV0(resources=resources,\n",
    "                                       import_penalty=10,\n",
    "                                       export_penalty=10,\n",
    "                                       storage_action_penalty=5,\n",
    "                                       ev_action_penalty=5,\n",
    "                                       ev_requirement_penalty=7,\n",
    "                                       balance_penalty=10)\n",
    "\n",
    "obs, info = test_env.reset()\n",
    "\n",
    "# Set up the terminations and truncations\n",
    "terminations = truncations = {a: False for a in test_env.agents}\n",
    "terminations['__all__'] = False\n",
    "truncations['__all__'] = False\n",
    "\n",
    "# Set up the order of the agents\n",
    "sequence = test_env._agent_sequence\n",
    "current_idx = 0\n",
    "while not terminations['__all__'] and not truncations['__all__']:\n",
    "    \n",
    "    current_agent = test_env.agents[sequence[current_idx]]\n",
    "    \n",
    "    current_policy = 'generator' if sequence[current_idx].startswith('generator') else \\\n",
    "                     'storage' if sequence[current_idx].startswith('storage') else \\\n",
    "                     'ev' if sequence[current_idx].startswith('ev') else \\\n",
    "                     'aggregator'\n",
    "    \n",
    "    action_dict = {current_agent.name: algo.compute_single_action(observation=obs[current_agent.name],\n",
    "                                                                  policy_id=current_policy)}\n",
    "\n",
    "    obs, rewards, terminations, truncations, info = test_env.step(action_dict)\n",
    "    print('Observation: {}'.format(obs))\n",
    "    print('Reward: {}'.format(rewards))\n",
    "    print('Infos: {}\\n'.format(info))\n",
    "    \n",
    "    current_idx = (current_idx + 1) % len(sequence)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the storage state of charge\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(data.storage['p_charge_limit'].shape[0]):\n",
    "    print(i)\n",
    "    plt.plot(test_env.storages[i].value)\n",
    "    \n",
    "plt.legend(['storage_{:02d}'.format(i+1) for i in range(data.storage['p_charge_limit'].shape[0])])"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the generator power output\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(data.generator['p_forecast'].shape[0]):\n",
    "    plt.plot(test_env.generators[i].value)\n",
    "    \n",
    "plt.legend(['generator_{:02d}'.format(i+1) for i in range(data.generator['p_forecast'].shape[0])])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check imports and exports\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(test_env.aggregator.imports)\n",
    "plt.plot(test_env.aggregator.exports)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check EVs\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(data.vehicle['e_capacity_max'].shape[0]):\n",
    "    plt.plot(test_env.evs[i].value)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
