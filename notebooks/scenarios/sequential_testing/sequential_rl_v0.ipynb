{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T23:20:55.175947Z",
     "start_time": "2024-08-26T23:20:51.327048Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 00:20:54,903\tWARNING deprecation.py:50 -- DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import ray\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib import Policy\n",
    "\n",
    "import IPython.core.display_functions\n",
    "\n",
    "from src.parsers import HMParser, CotevParser\n",
    "from src.resources import Aggregator, Generator, Load, Storage\n",
    "from src.algorithms.rl import EnergyCommunitySequentialV8\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data parsing\n",
    "\n",
    "# EC data for non-renewable generators and batteries\n",
    "data_ec = HMParser(file_path='/Users/ecgomes/DataspellProjects/pyecom/data/EC_V4.xlsx', ec_id=1)\n",
    "data_ec.parse()\n",
    "\n",
    "# EV data from the EV4EU simulator\n",
    "data_ev = CotevParser(population_path=\n",
    "                      '/Users/ecgomes/DataspellProjects/pyecom/data/simulation_dataframes_2years/population_731.csv',\n",
    "                      driving_history_path=\n",
    "                      '/Users/ecgomes/DataspellProjects/pyecom/data/simulation_dataframes_2years/ev_driving_history_731.csv',\n",
    "                      assigned_segments_path='/Users/ecgomes/DataspellProjects/pyecom/data/simulation_dataframes_2years/assigned_segments_731.csv',\n",
    "                      parse_date_start='2019',\n",
    "                      parse_date_end='2020')\n",
    "data_ev.parse()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-26T23:20:57.223901Z",
     "start_time": "2024-08-26T23:20:55.789058Z"
    }
   },
   "id": "e43835ff69a5fd2a",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# UPAC Data load\n",
    "\n",
    "data_upacs = {}\n",
    "for i in glob.glob('/Users/ecgomes/Documents/PhD/UPAC data/upac*_pv.csv'):\n",
    "    temp = pd.read_csv(i, index_col=0, parse_dates=True)\n",
    "    temp = temp.resample('H').mean()\n",
    "    \n",
    "    # Need to divide by 1000 to convert from W to kW\n",
    "    temp['pv'] = temp['pv'] / 1000\n",
    "    temp['load'] = temp['load'] / 1000\n",
    "    \n",
    "    # Set any negative values to zero\n",
    "    temp.loc[temp['pv'] < 0, 'pv'] = 0\n",
    "    temp.loc[temp['load'] < 0, 'load'] = 0\n",
    "    \n",
    "    # We only want 2019 and 2020 data\n",
    "    temp = temp.loc['2019':'2020']\n",
    "    \n",
    "    # Fill potential NaN values with interpolation\n",
    "    # temp = temp.interpolate()\n",
    "    \n",
    "    # Fill NaN values with zeros\n",
    "    temp = temp.fillna(0)\n",
    "    \n",
    "    name = i.split('/')[-1].split('_')[0].split('upac')[1]\n",
    "    \n",
    "    data_upacs[name] = temp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-26T23:21:00.506961Z",
     "start_time": "2024-08-26T23:20:57.918659Z"
    }
   },
   "id": "d8097bd3d6272b3d",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train resource creation\n",
    "\n",
    "def create_resources(upacs, ec, ev):\n",
    "    \"\"\"\n",
    "    Create the resources for the training environment.\n",
    "    return a list of resources.\n",
    "    :param upacs: dict with the UPAC data\n",
    "    :param ec: dict with the EC data\n",
    "    :param ev: dict with the EV data\n",
    "    \"\"\"\n",
    "\n",
    "    resources = []\n",
    "    # Add generators (from pv column from the UPAC data)\n",
    "    for i in range(len(upacs)):\n",
    "        current_name = list(upacs.keys())[i]\n",
    "        resources.append(Generator(\n",
    "            name='ren_generator_' + current_name,\n",
    "            value=np.zeros(upacs[current_name]['pv'].shape),\n",
    "            lower_bound=np.zeros(upacs[current_name]['pv'].shape),\n",
    "            upper_bound=upacs[current_name]['pv'].values,\n",
    "            cost=ec.generator['cost_parameter_b'][0, 0] * np.ones(upacs[current_name].shape[0]),\n",
    "            cost_nde=np.tile(ec.generator['cost_nde'][0], (int(upacs[current_name].shape[0] / 24))),\n",
    "            is_renewable=True))\n",
    "\n",
    "    '''\n",
    "    resources.append(Generator(\n",
    "        name='generator_14',\n",
    "        value=np.zeros(upacs['02']['pv'].shape),\n",
    "        lower_bound=np.zeros(upacs['02']['pv'].shape),\n",
    "        upper_bound=np.ones(upacs['02']['pv'].shape) * 15,\n",
    "        cost=ec.generator['cost_parameter_b'][0, 0] * np.ones(upacs['02'].shape[0]),\n",
    "        cost_nde=ec.generator['cost_nde'][0],\n",
    "        is_renewable=False))\n",
    "    \n",
    "    resources.append(Generator(\n",
    "        name='generator_15',\n",
    "        value=np.zeros(upacs['02']['pv'].shape),\n",
    "        lower_bound=np.zeros(upacs['02']['pv'].shape),\n",
    "        upper_bound=np.ones(upacs['02']['pv'].shape) * 15,\n",
    "        cost=ec.generator['cost_parameter_b'][0, 0] * np.ones(upacs['02'].shape[0]),\n",
    "        cost_nde=ec.generator['cost_nde'][0],\n",
    "        is_renewable=False))\n",
    "    '''\n",
    "\n",
    "    # Add loads (from load column from the UPAC data)\n",
    "    for i in range(len(upacs)):\n",
    "        current_name = list(upacs.keys())[i]\n",
    "        resources.append(Load(\n",
    "            name='load_' + current_name,\n",
    "            value=upacs[current_name]['load'],\n",
    "            lower_bound=np.zeros(upacs[current_name].shape),\n",
    "            upper_bound=upacs[current_name]['load'].values,\n",
    "            cost=np.ones(upacs[current_name].shape[0]),\n",
    "            cost_cut=np.tile(ec.load['cost_cut'][0], (int(upacs[current_name].shape[0] / 24))),\n",
    "            cost_reduce=np.tile(ec.load['cost_reduce'][0], (int(upacs[current_name].shape[0] / 24))),\n",
    "            cost_ens=np.tile(ec.load['cost_ens'][0], (int(upacs[current_name].shape[0] / 24)))))\n",
    "\n",
    "    # Add storage (from the EC data)\n",
    "    for i in range(ec.storage['p_charge_limit'].shape[0]):\n",
    "        resources.append(Storage(\n",
    "            name='storage_{:02d}'.format(i+1),\n",
    "            value=ec.storage['initial_state'][i] * np.ones(upacs['02'].shape[0]),\n",
    "            lower_bound=np.ones(upacs['02'].shape[0]) * ec.storage['energy_min_percentage'][i],\n",
    "            upper_bound=(ec.storage['energy_capacity'][i] * np.ones(upacs['02'].shape[0])),\n",
    "            cost=np.ones(upacs['02'].shape[0]) * 0,\n",
    "            cost_discharge=np.tile(ec.storage['discharge_price'][i], (int(upacs['02'].shape[0] / 24))),\n",
    "            cost_charge=np.tile(ec.storage['charge_price'][i], (int(upacs['02'].shape[0] / 24))),\n",
    "            capacity_max=ec.storage['energy_capacity'][i],\n",
    "            capacity_min=ec.storage['energy_min_percentage'][i],\n",
    "            initial_charge=ec.storage['initial_state'][i],\n",
    "            discharge_efficiency=ec.storage['discharge_efficiency'][i],\n",
    "            discharge_max=np.tile(ec.storage['p_discharge_limit'][i], (int(upacs['02'].shape[0] / 24))),\n",
    "            charge_efficiency=ec.storage['charge_efficiency'][i],\n",
    "            charge_max=np.tile(ec.storage['p_charge_limit'][i], (int(upacs['02'].shape[0] / 24))),\n",
    "            capital_cost=np.array([0.05250, 0.10500, 0.01575])))\n",
    "\n",
    "    # Add vehicles (from the EV data)\n",
    "    for i in np.arange(len(ev)):\n",
    "        # Append to the list of resources\n",
    "        # ev[i].cost_charge *= 0\n",
    "        # ev[i].cost_discharge *= 0\n",
    "        resources.append(ev[i])\n",
    "\n",
    "    # Append Aggregator\n",
    "    resources.append(Aggregator(\n",
    "        name='aggregator',\n",
    "        value=np.zeros(upacs['02'].shape[0]),\n",
    "        lower_bound=np.zeros(upacs['02'].shape[0]),\n",
    "        upper_bound=np.tile(ec.peers['import_contracted_p_max'][0, 0], (upacs['02'].shape[0])),\n",
    "        cost=np.tile(ec.peers['buy_price'][0, 0], (upacs['02'].shape[0])),\n",
    "        imports=np.zeros(upacs['02'].shape[0]),\n",
    "        exports=np.zeros(upacs['02'].shape[0]),\n",
    "        import_cost=np.tile(ec.peers['buy_price'][0], (int(upacs['02'].shape[0] / 24))), # * 100,\n",
    "        export_cost=np.tile(ec.peers['sell_price'][0], (int(upacs['02'].shape[0] / 24))),\n",
    "        import_max=np.tile(ec.peers['import_contracted_p_max'][0, 0], (int(upacs['02'].shape[0]))),\n",
    "        export_max=np.tile(ec.peers['export_contracted_p_max'][0, 0], (int(upacs['02'].shape[0])))))\n",
    "\n",
    "    return resources"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-26T23:21:01.524271Z",
     "start_time": "2024-08-26T23:21:01.515185Z"
    }
   },
   "id": "bf9b045471522328",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create resources for the training environment\n",
    "\n",
    "def iterate_resources(u, c, e, mode='daily'):\n",
    "    \n",
    "    temp = {}\n",
    "    \n",
    "    # Save first key of upac data\n",
    "    first_key = list(u.keys())[0]\n",
    "    \n",
    "    if mode is 'daily':\n",
    "\n",
    "        # Loop to iterate over days in the datasets\n",
    "        for i in np.unique(u[first_key].index.date):\n",
    "            # Create the resources for the training environment\n",
    "            \n",
    "            date = i.strftime('%Y-%m-%d')\n",
    "            \n",
    "            temp_u = {k: v.loc[date] for k, v in u.items()}\n",
    "            temp_e = e.create_resources(e.population, e.trips_grid, e.assigned_segments, date)\n",
    "            \n",
    "            temp[date] = create_resources(upacs=temp_u,\n",
    "                                          ec=c,\n",
    "                                          ev=temp_e)\n",
    "            \n",
    "    elif mode is 'monthly':\n",
    "        \n",
    "        # Loop to iterate over months in the datasets\n",
    "        # Need to be careful with different years\n",
    "        unique_months = np.unique(data_upacs['02'].index.strftime('%Y-%m'))\n",
    "        \n",
    "        for i in unique_months:\n",
    "            # Create the resources for the training environment\n",
    "            date = i\n",
    "            \n",
    "            temp_u = {k: v.loc[date] for k, v in u.items()}\n",
    "            temp_e = e.create_resources(e.population, e.trips_grid, e.assigned_segments, date)\n",
    "            \n",
    "            temp[date] = create_resources(upacs=temp_u,\n",
    "                                          ec=c,\n",
    "                                          ev=temp_e)\n",
    "            \n",
    "    elif mode is 'yearly':\n",
    "        \n",
    "        # Loop to iterate over years in the datasets\n",
    "        unique_years = np.unique(data_upacs['02'].index.strftime('%Y'))\n",
    "        \n",
    "        for i in unique_years:\n",
    "            # Create the resources for the training environment\n",
    "            date = i\n",
    "            \n",
    "            temp_u = {k: v.loc[date] for k, v in u.items()}\n",
    "            temp_e = e.create_resources(e.population, e.trips_grid, e.assigned_segments, date)\n",
    "            \n",
    "            temp[date] = create_resources(upacs=temp_u,\n",
    "                                          ec=c,\n",
    "                                          ev=temp_e)\n",
    "        \n",
    "    return temp\n",
    "\n",
    "dataset_resources = iterate_resources(u=data_upacs, c=data_ec, e=data_ev, mode='monthly')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-26T23:21:02.386194Z",
     "start_time": "2024-08-26T23:21:02.301508Z"
    }
   },
   "id": "82526219bdef7d23",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['ren_generator_08',\n 'ren_generator_06',\n 'ren_generator_02',\n 'ren_generator_09',\n 'ren_generator_13',\n 'ev_01',\n 'ev_02',\n 'ev_03',\n 'ev_04',\n 'ev_05',\n 'storage_01',\n 'storage_02',\n 'storage_03',\n 'aggregator']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the execution order\n",
    "\n",
    "execution_order = [res.name for res in dataset_resources[list(dataset_resources.keys())[0]][:5]] + \\\n",
    "                  [res.name for res in dataset_resources[list(dataset_resources.keys())[0]][13:-1]] + \\\n",
    "                  [res.name for res in dataset_resources[list(dataset_resources.keys())[0]][10:13]] + \\\n",
    "                  [dataset_resources[list(dataset_resources.keys())[0]][-1].name]\n",
    "execution_order"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-26T23:21:02.840727Z",
     "start_time": "2024-08-26T23:21:02.836589Z"
    }
   },
   "id": "9905c07df9d0e24c",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated: True\n"
     ]
    }
   ],
   "source": [
    "# Create the environment and check if everything is ok\n",
    "\n",
    "temp_env = EnergyCommunitySequentialV8(ren_generators=dataset_resources[list(dataset_resources.keys())[0]][:5],\n",
    "                                       generators=[],#dataset_resources[list(dataset_resources.keys())[0]][5:7],\n",
    "                                       loads=dataset_resources[list(dataset_resources.keys())[0]][5:10],\n",
    "                                       storages=dataset_resources[list(dataset_resources.keys())[0]][10:13],\n",
    "                                       evs=dataset_resources[list(dataset_resources.keys())[0]][13:-1],\n",
    "                                       aggregator=dataset_resources[list(dataset_resources.keys())[0]][-1],\n",
    "                                       storage_penalty=1,\n",
    "                                       ev_penalty=1,\n",
    "                                       balance_penalty=1,\n",
    "                                       execution_order=execution_order)\n",
    "temp_env.reset()\n",
    "terminations = truncations = {a: False for a in temp_env.agents}\n",
    "terminations['__all__'] = False\n",
    "truncations['__all__'] = False\n",
    "while not terminations['__all__'] and not truncations['__all__']:\n",
    "\n",
    "    actions = temp_env.action_space_sample()\n",
    "    next_obs, rewards, terminations, truncations, infos = temp_env.step(actions)\n",
    "\n",
    "print('Terminated: {}'.format(terminations['__all__']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-26T23:21:03.910444Z",
     "start_time": "2024-08-26T23:21:03.394936Z"
    }
   },
   "id": "f732630cb55ab585",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create the policies dictionary\n",
    "\n",
    "def assign_group_policies(env):\n",
    "\n",
    "    policies = {'generator_renewable': (None,\n",
    "                              env.observation_space['ren_generator_08'],\n",
    "                              env.action_space['ren_generator_08'],\n",
    "                              {}),\n",
    "                'storage': (None,\n",
    "                            env.observation_space['storage_01'],\n",
    "                            env.action_space['storage_01'],\n",
    "                            {}),\n",
    "                'ev': (None,\n",
    "                       env.observation_space['ev_01'],\n",
    "                       env.action_space['ev_01'],\n",
    "                       {}),\n",
    "                #'generator_non_renewable': (None,\n",
    "                #              env.observation_space['generator_14'],\n",
    "                #              env.action_space['generator_14'],\n",
    "                #              {}),\n",
    "                }\n",
    "\n",
    "    return policies\n",
    "\n",
    "def assign_group_policies_v2(env):\n",
    "\n",
    "    policies = {'ren_08': (None,\n",
    "                           env.observation_space['ren_generator_08'],\n",
    "                           env.action_space['ren_generator_08'],\n",
    "                           {}),\n",
    "                'ren_09': (None,\n",
    "                            env.observation_space['ren_generator_09'],\n",
    "                            env.action_space['ren_generator_09'],\n",
    "                            {}),\n",
    "                'ren_02': (None,\n",
    "                            env.observation_space['ren_generator_02'],\n",
    "                            env.action_space['ren_generator_02'],\n",
    "                            {}),\n",
    "                'ren_06': (None,\n",
    "                            env.observation_space['ren_generator_06'],\n",
    "                            env.action_space['ren_generator_06'],\n",
    "                            {}),\n",
    "                'ren_13': (None,\n",
    "                            env.observation_space['ren_generator_13'],\n",
    "                            env.action_space['ren_generator_13'],\n",
    "                            {}),\n",
    "                'storage_01': (None,\n",
    "                               env.observation_space['storage_01'],\n",
    "                               env.action_space['storage_01'],\n",
    "                               {}),\n",
    "                'storage_02': (None,\n",
    "                               env.observation_space['storage_02'],\n",
    "                               env.action_space['storage_02'],\n",
    "                               {}),\n",
    "                'storage_03': (None,\n",
    "                               env.observation_space['storage_03'],\n",
    "                               env.action_space['storage_03'],\n",
    "                               {}),\n",
    "                'ev_01': (None,\n",
    "                          env.observation_space['ev_01'],\n",
    "                          env.action_space['ev_01'],\n",
    "                          {}),\n",
    "                'ev_02': (None,\n",
    "                          env.observation_space['ev_02'],\n",
    "                          env.action_space['ev_02'],\n",
    "                          {}),\n",
    "                'ev_03': (None,\n",
    "                          env.observation_space['ev_03'],\n",
    "                          env.action_space['ev_03'],\n",
    "                          {}),\n",
    "                'ev_04': (None,\n",
    "                          env.observation_space['ev_04'],\n",
    "                          env.action_space['ev_04'],\n",
    "                          {}),\n",
    "                'ev_05': (None,\n",
    "                          env.observation_space['ev_05'],\n",
    "                          env.action_space['ev_05'],\n",
    "                          {}),\n",
    "                }\n",
    "\n",
    "    return policies\n",
    "\n",
    "def assign_group_policies_v3(env):\n",
    "\n",
    "    policies = {'ren_08': (None,\n",
    "                           env.observation_space['ren_generator_08'],\n",
    "                           env.action_space['ren_generator_08'],\n",
    "                           {}),\n",
    "                'ren_09': (None,\n",
    "                           env.observation_space['ren_generator_09'],\n",
    "                           env.action_space['ren_generator_09'],\n",
    "                           {}),\n",
    "                'ren_02': (None,\n",
    "                           env.observation_space['ren_generator_02'],\n",
    "                           env.action_space['ren_generator_02'],\n",
    "                           {}),\n",
    "                'ren_06': (None,\n",
    "                           env.observation_space['ren_generator_06'],\n",
    "                           env.action_space['ren_generator_06'],\n",
    "                           {}),\n",
    "                'ren_13': (None,\n",
    "                           env.observation_space['ren_generator_13'],\n",
    "                           env.action_space['ren_generator_13'],\n",
    "                           {}),\n",
    "                'storage_01': (None,\n",
    "                               env.observation_space['storage_01'],\n",
    "                               env.action_space['storage_01'],\n",
    "                               {}),\n",
    "                'storage_02': (None,\n",
    "                               env.observation_space['storage_02'],\n",
    "                               env.action_space['storage_02'],\n",
    "                               {}),\n",
    "                'storage_03': (None,\n",
    "                               env.observation_space['storage_03'],\n",
    "                               env.action_space['storage_03'],\n",
    "                               {}),\n",
    "                }\n",
    "    \n",
    "    return policies\n",
    "\n",
    "def assign_group_policies_v4(env):\n",
    "\n",
    "    policies = {'generator_renewable': (None,\n",
    "                                        env.observation_space['ren_generator_08'],\n",
    "                                        env.action_space['ren_generator_08'],\n",
    "                                        {}),\n",
    "                'storage_01': (None,\n",
    "                               env.observation_space['storage_01'],\n",
    "                               env.action_space['storage_01'],\n",
    "                               {}),\n",
    "                'storage_02': (None,\n",
    "                               env.observation_space['storage_02'],\n",
    "                               env.action_space['storage_02'],\n",
    "                               {}),\n",
    "                'storage_03': (None,\n",
    "                               env.observation_space['storage_03'],\n",
    "                               env.action_space['storage_03'],\n",
    "                               {}),\n",
    "                }\n",
    "\n",
    "    return policies\n",
    "\n",
    "policies = assign_group_policies_v3(env=temp_env)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-26T23:21:04.556897Z",
     "start_time": "2024-08-26T23:21:04.550409Z"
    }
   },
   "id": "665c1352bde7814a",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datapoint 2019-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(RolloutWorker pid=54332)\u001B[0m 2024-08-27 00:21:17,223\tWARNING env_runner_v2.py:155 -- More than 10416 observations in 10416 env steps for episode 541056473734603130 are buffered in the sampler. If this is more than you expected, check that that you set a horizon on your environment correctly and that it terminates at some point. Note: In multi-agent environments, `rollout_fragment_length` sets the batch size based on (across-agents) environment steps, not the steps of individual agents, which can result in unexpectedly large batches.Also, you may be waiting for your Env to terminate (batch_mode=`complete_episodes`). Make sure it does at some point.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0; avg. reward=-164488.62550000084\n",
      "Iter: 1; avg. reward=-101400.2816500004\n",
      "Iter: 2; avg. reward=-72065.26570000034\n",
      "Iter: 3; avg. reward=-58764.1014250003\n",
      "Iter: 4; avg. reward=-49284.93386000029\n",
      "Iter: 5; avg. reward=-42044.93816666691\n",
      "Iter: 6; avg. reward=-37192.57304285738\n",
      "Iter: 7; avg. reward=-33407.678325000204\n",
      "Iter: 8; avg. reward=-30767.968044444704\n",
      "Iter: 9; avg. reward=-28407.78511000024\n",
      "Iter: 10; avg. reward=-26307.364436363863\n",
      "Iter: 11; avg. reward=-24607.572458333536\n",
      "Iter: 12; avg. reward=-22770.745630769423\n",
      "Iter: 13; avg. reward=-21120.043564285897\n",
      "Iter: 14; avg. reward=-19736.6437533335\n",
      "Iter: 15; avg. reward=-18469.52778125015\n",
      "Iter: 16; avg. reward=-17179.7129411766\n",
      "Iter: 17; avg. reward=-16115.608488889\n",
      "Iter: 18; avg. reward=-15204.76152631588\n",
      "Iter: 19; avg. reward=-14206.156460000091\n",
      "Iter: 20; avg. reward=-13188.168128571542\n",
      "Iter: 21; avg. reward=-12185.736286363774\n",
      "Iter: 22; avg. reward=-11271.038204347982\n",
      "Iter: 23; avg. reward=-10418.274779166844\n",
      "Iter: 24; avg. reward=-10667.958692000147\n",
      "Iter: 25; avg. reward=-9901.76628461556\n",
      "Iter: 26; avg. reward=-9528.209377777946\n",
      "Iter: 27; avg. reward=-8750.859607143053\n",
      "Iter: 28; avg. reward=-8012.408817241598\n",
      "Iter: 29; avg. reward=-7328.993666666907\n",
      "Iter: 30; avg. reward=-7535.08166774219\n",
      "Iter: 31; avg. reward=-7008.065746875271\n",
      "Iter: 32; avg. reward=-6410.441884848775\n",
      "Iter: 33; avg. reward=-5831.578617647368\n",
      "Iter: 34; avg. reward=-5486.294348571733\n",
      "Iter: 35; avg. reward=-4946.2792527780975\n",
      "Iter: 36; avg. reward=-5202.580591892219\n",
      "Iter: 37; avg. reward=-4704.28888421087\n",
      "Iter: 38; avg. reward=-4311.970641026001\n",
      "Iter: 39; avg. reward=-4961.333780000316\n",
      "Iter: 40; avg. reward=-4558.8172048783745\n",
      "Iter: 41; avg. reward=-4101.372516667009\n",
      "Iter: 42; avg. reward=-3920.7009046515045\n",
      "Iter: 43; avg. reward=-3455.4819000003536\n",
      "Iter: 44; avg. reward=-3603.0280577781405\n",
      "Iter: 45; avg. reward=-3230.725834782986\n",
      "Iter: 46; avg. reward=-3409.1549212769823\n",
      "Iter: 47; avg. reward=-3179.0086958337183\n",
      "Iter: 48; avg. reward=-3123.439089796301\n",
      "Iter: 49; avg. reward=-2844.666802000396\n",
      "Iter: 50; avg. reward=-2542.744760784722\n",
      "Iter: 51; avg. reward=-2919.451498077287\n",
      "Iter: 52; avg. reward=-2561.864258490942\n",
      "Iter: 53; avg. reward=-2271.80670555594\n",
      "Iter: 54; avg. reward=-1935.9625200003957\n",
      "Iter: 55; avg. reward=-1853.8944303575413\n",
      "Iter: 56; avg. reward=-1540.268410526725\n",
      "Iter: 57; avg. reward=-1531.1719017245443\n",
      "Iter: 58; avg. reward=-1233.924191525837\n",
      "Iter: 59; avg. reward=-2520.0116133338547\n",
      "Iter: 60; avg. reward=-2442.3499213119994\n",
      "Iter: 61; avg. reward=-2224.7898258069763\n",
      "Iter: 62; avg. reward=-1937.239939683067\n",
      "Iter: 63; avg. reward=-1913.706500000524\n",
      "Iter: 64; avg. reward=-1676.2030153851474\n",
      "Iter: 65; avg. reward=-1890.4579545459926\n",
      "Iter: 66; avg. reward=-1697.0203373139786\n",
      "Iter: 67; avg. reward=-1892.219189706435\n",
      "Iter: 68; avg. reward=-1735.4847043483855\n",
      "Iter: 69; avg. reward=-2061.2502757148113\n",
      "Iter: 70; avg. reward=-2231.8048478878577\n",
      "Iter: 71; avg. reward=-2031.819415278319\n",
      "Iter: 72; avg. reward=-1824.4783369868492\n",
      "Iter: 73; avg. reward=-1586.3449621627167\n",
      "Iter: 74; avg. reward=-1630.284712000557\n",
      "Iter: 75; avg. reward=-2072.1168236847366\n",
      "Iter: 76; avg. reward=-1862.378228571961\n",
      "Iter: 77; avg. reward=-1685.1765115390003\n",
      "Iter: 78; avg. reward=-1617.535575949905\n",
      "Iter: 79; avg. reward=-1561.4674125005313\n",
      "Iter: 80; avg. reward=-1510.172872840031\n",
      "Iter: 81; avg. reward=-1327.5556487810193\n",
      "Iter: 82; avg. reward=-1303.7635867475217\n",
      "Iter: 83; avg. reward=-1105.9115452386352\n",
      "Iter: 84; avg. reward=-995.0929682358394\n",
      "Iter: 85; avg. reward=-988.202415116821\n",
      "Iter: 86; avg. reward=-1006.9265149430656\n",
      "Iter: 87; avg. reward=-809.1335931823556\n",
      "Iter: 88; avg. reward=-640.0827235960483\n",
      "Iter: 89; avg. reward=-591.7507900005473\n",
      "Iter: 90; avg. reward=-431.952681319234\n",
      "Iter: 91; avg. reward=-491.5470326092511\n",
      "Iter: 92; avg. reward=-439.19211505431423\n",
      "Iter: 93; avg. reward=-365.92463297927867\n",
      "Iter: 94; avg. reward=-237.8988157900339\n",
      "Iter: 95; avg. reward=-143.5694552088968\n",
      "Iter: 96; avg. reward=-13.055780412939844\n",
      "Iter: 97; avg. reward=137.09809693820227\n",
      "Iter: 98; avg. reward=122.37775151458368\n",
      "Iter: 99; avg. reward=255.06248899942722\n",
      "Iter: 100; avg. reward=1772.1683859994255\n",
      "Iter: 101; avg. reward=2286.9512399994146\n",
      "Iter: 102; avg. reward=2497.8329209994063\n",
      "Iter: 103; avg. reward=2810.550474999398\n",
      "Iter: 104; avg. reward=2932.0858709993936\n",
      "Iter: 105; avg. reward=3031.4911529993906\n",
      "Iter: 106; avg. reward=3255.537235999384\n",
      "Iter: 107; avg. reward=3374.3664489993757\n",
      "Iter: 108; avg. reward=3607.8700749993714\n",
      "Iter: 109; avg. reward=3447.708367999397\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 192\u001B[0m\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatapoint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdatapoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m200\u001B[39m):\n\u001B[0;32m--> 192\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[43malgo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    193\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIter: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m; avg. reward=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepisode_reward_mean\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;66;03m# print(f\"Policy rewards: {results['policy_reward_mean']}\")\u001B[39;00m\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;66;03m# if results['episode_reward_mean'] > 500:\u001B[39;00m\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;66;03m#     break\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;66;03m#    break\u001B[39;00m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;66;03m# print(\"checkpoints saved at\", checkpoint)\u001B[39;00m\n",
      "File \u001B[0;32m~/DataspellProjects/pyecom/venv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py:397\u001B[0m, in \u001B[0;36mTrainable.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    395\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 397\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    399\u001B[0m     skipped \u001B[38;5;241m=\u001B[39m skip_exceptions(e)\n",
      "File \u001B[0;32m~/DataspellProjects/pyecom/venv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:853\u001B[0m, in \u001B[0;36mAlgorithm.step\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    845\u001B[0m     (\n\u001B[1;32m    846\u001B[0m         results,\n\u001B[1;32m    847\u001B[0m         train_iter_ctx,\n\u001B[1;32m    848\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001B[1;32m    849\u001B[0m \u001B[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001B[39;00m\n\u001B[1;32m    850\u001B[0m \u001B[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001B[39;00m\n\u001B[1;32m    851\u001B[0m \u001B[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001B[39;00m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 853\u001B[0m     results, train_iter_ctx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_one_training_iteration\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001B[39;00m\n\u001B[1;32m    856\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m evaluate_this_iter \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mevaluation_parallel_to_training:\n",
      "File \u001B[0;32m~/DataspellProjects/pyecom/venv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:2838\u001B[0m, in \u001B[0;36mAlgorithm._run_one_training_iteration\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2836\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timers[TRAINING_ITERATION_TIMER]:\n\u001B[1;32m   2837\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39m_disable_execution_plan_api:\n\u001B[0;32m-> 2838\u001B[0m         results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2839\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2840\u001B[0m         results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_exec_impl)\n",
      "File \u001B[0;32m~/DataspellProjects/pyecom/venv/lib/python3.11/site-packages/ray/rllib/algorithms/ppo/ppo.py:429\u001B[0m, in \u001B[0;36mPPO.training_step\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    424\u001B[0m         train_batch \u001B[38;5;241m=\u001B[39m synchronous_parallel_sample(\n\u001B[1;32m    425\u001B[0m             worker_set\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworkers,\n\u001B[1;32m    426\u001B[0m             max_agent_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mtrain_batch_size,\n\u001B[1;32m    427\u001B[0m         )\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 429\u001B[0m         train_batch \u001B[38;5;241m=\u001B[39m \u001B[43msynchronous_parallel_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m            \u001B[49m\u001B[43mworker_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_env_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_batch_size\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    433\u001B[0m train_batch \u001B[38;5;241m=\u001B[39m train_batch\u001B[38;5;241m.\u001B[39mas_multi_agent()\n\u001B[1;32m    434\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_counters[NUM_AGENT_STEPS_SAMPLED] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m train_batch\u001B[38;5;241m.\u001B[39magent_steps()\n",
      "File \u001B[0;32m~/DataspellProjects/pyecom/venv/lib/python3.11/site-packages/ray/rllib/execution/rollout_ops.py:85\u001B[0m, in \u001B[0;36msynchronous_parallel_sample\u001B[0;34m(worker_set, max_agent_steps, max_env_steps, concat)\u001B[0m\n\u001B[1;32m     82\u001B[0m     sample_batches \u001B[38;5;241m=\u001B[39m [worker_set\u001B[38;5;241m.\u001B[39mlocal_worker()\u001B[38;5;241m.\u001B[39msample()]\n\u001B[1;32m     83\u001B[0m \u001B[38;5;66;03m# Loop over remote workers' `sample()` method in parallel.\u001B[39;00m\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 85\u001B[0m     sample_batches \u001B[38;5;241m=\u001B[39m \u001B[43mworker_set\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforeach_worker\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_worker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhealthy_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     87\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m worker_set\u001B[38;5;241m.\u001B[39mnum_healthy_remote_workers() \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     89\u001B[0m         \u001B[38;5;66;03m# There is no point staying in this loop, since we will not be able to\u001B[39;00m\n\u001B[1;32m     90\u001B[0m         \u001B[38;5;66;03m# get any new samples if we don't have any healthy remote workers left.\u001B[39;00m\n\u001B[1;32m     91\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/DataspellProjects/pyecom/venv/lib/python3.11/site-packages/ray/rllib/evaluation/worker_set.py:671\u001B[0m, in \u001B[0;36mWorkerSet.foreach_worker\u001B[0;34m(self, func, local_worker, healthy_only, remote_worker_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001B[0m\n\u001B[1;32m    668\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m local_worker \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_worker() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    669\u001B[0m     local_result \u001B[38;5;241m=\u001B[39m [func(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_worker())]\n\u001B[0;32m--> 671\u001B[0m remote_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__worker_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforeach_actor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhealthy_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhealthy_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremote_actor_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremote_worker_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_seconds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_seconds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_obj_refs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_obj_refs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmark_healthy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmark_healthy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    680\u001B[0m handle_remote_call_result_errors(remote_results, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ignore_worker_failures)\n\u001B[1;32m    682\u001B[0m \u001B[38;5;66;03m# With application errors handled, return good results.\u001B[39;00m\n",
      "File \u001B[0;32m~/DataspellProjects/pyecom/venv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:592\u001B[0m, in \u001B[0;36mFaultTolerantActorManager.foreach_actor\u001B[0;34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001B[0m\n\u001B[1;32m    583\u001B[0m     func, remote_actor_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_filter_func_and_remote_actor_id_by_state(\n\u001B[1;32m    584\u001B[0m         func, remote_actor_ids\n\u001B[1;32m    585\u001B[0m     )\n\u001B[1;32m    587\u001B[0m remote_calls \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__call_actors(\n\u001B[1;32m    588\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[1;32m    589\u001B[0m     remote_actor_ids\u001B[38;5;241m=\u001B[39mremote_actor_ids,\n\u001B[1;32m    590\u001B[0m )\n\u001B[0;32m--> 592\u001B[0m _, remote_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__fetch_result\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    593\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremote_actor_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremote_actor_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    594\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremote_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremote_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mremote_calls\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    596\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_seconds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_seconds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    597\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_obj_refs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_obj_refs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    598\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmark_healthy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmark_healthy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    599\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    601\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m remote_results\n",
      "File \u001B[0;32m~/DataspellProjects/pyecom/venv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:460\u001B[0m, in \u001B[0;36mFaultTolerantActorManager.__fetch_result\u001B[0;34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001B[0m\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m remote_calls:\n\u001B[1;32m    458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [], RemoteCallResults()\n\u001B[0;32m--> 460\u001B[0m ready, _ \u001B[38;5;241m=\u001B[39m \u001B[43mray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremote_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    462\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_returns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mremote_calls\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    463\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    464\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Make sure remote results are fetched locally in parallel.\u001B[39;49;00m\n\u001B[1;32m    465\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfetch_local\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mreturn_obj_refs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    466\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    468\u001B[0m \u001B[38;5;66;03m# Remote data should already be fetched to local object store at this point.\u001B[39;00m\n\u001B[1;32m    469\u001B[0m remote_results \u001B[38;5;241m=\u001B[39m RemoteCallResults()\n",
      "File \u001B[0;32m~/DataspellProjects/pyecom/venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:24\u001B[0m, in \u001B[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(fn)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mauto_init_wrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     23\u001B[0m     auto_init_ray()\n\u001B[0;32m---> 24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/DataspellProjects/pyecom/venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001B[0m, in \u001B[0;36mclient_mode_hook.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minit\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m is_client_mode_enabled_by_default:\n\u001B[1;32m    102\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(ray, func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/DataspellProjects/pyecom/venv/lib/python3.11/site-packages/ray/_private/worker.py:2755\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_refs, num_returns, timeout, fetch_local)\u001B[0m\n\u001B[1;32m   2753\u001B[0m timeout \u001B[38;5;241m=\u001B[39m timeout \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m10\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m6\u001B[39m\n\u001B[1;32m   2754\u001B[0m timeout_milliseconds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(timeout \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n\u001B[0;32m-> 2755\u001B[0m ready_ids, remaining_ids \u001B[38;5;241m=\u001B[39m \u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcore_worker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2756\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobject_refs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2757\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_returns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2758\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_milliseconds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2759\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_task_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2760\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfetch_local\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2761\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2762\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ready_ids, remaining_ids\n",
      "File \u001B[0;32mpython/ray/_raylet.pyx:3333\u001B[0m, in \u001B[0;36mray._raylet.CoreWorker.wait\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpython/ray/_raylet.pyx:445\u001B[0m, in \u001B[0;36mray._raylet.check_status\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "# Create an RLlib Algorithm instance from a PPOConfig to learn how to\n",
    "# act in the above environment.\n",
    "\n",
    "from ray.tune import register_env\n",
    "from ray.train import Checkpoint\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "IMPORT_PENALTY = 1 #100\n",
    "EXPORT_PENALTY = 1 #10\n",
    "STORAGE_ACTION_PENALTY = 5 #100\n",
    "STORAGE_ACTION_REWARD = 5 #10\n",
    "EV_ACTION_PENALTY = 1 #1000\n",
    "EV_ACTION_REWARD = 5 #10\n",
    "EV_REQUIREMENT_PENALTY = 2000 #3000\n",
    "BALANCE_PENALTY = 5000 #20000\n",
    "\n",
    "checkpoint = None\n",
    "checkpoint_path = None\n",
    "algo = None\n",
    "current_best = None\n",
    "\n",
    "# Months per day:\n",
    "# January: 0:31 -> DONE\n",
    "# February: 31:59 -> DONE\n",
    "# March: 59:90 -> DONE\n",
    "# April: 90:120 -> DONE\n",
    "# May: 120:151 -> DONE\n",
    "# June: 151:181 -> DONE\n",
    "# July: 181:212 -> DONE\n",
    "# August: 212:243 -> DONE\n",
    "# September: 243:273 -> DONE\n",
    "# October: 273:304 -> DONE\n",
    "# November: 304:334 -> DONE\n",
    "# December: 334:365 -> DONE\n",
    "\n",
    "# Build a loop for using separate resources on a daily basis\n",
    "for datapoint in list(dataset_resources.keys())[:1]:\n",
    "    \n",
    "    temp_resources = dataset_resources[datapoint]\n",
    "    \n",
    "    env = EnergyCommunitySequentialV8(ren_generators=temp_resources[:5],\n",
    "                                      generators=[],#temp_resources[5:7],\n",
    "                                      loads=temp_resources[5:10],\n",
    "                                      storages=temp_resources[10:13],\n",
    "                                      evs=temp_resources[13:-1],\n",
    "                                      aggregator=temp_resources[-1],\n",
    "                                      storage_penalty=STORAGE_ACTION_PENALTY,\n",
    "                                      ev_penalty=EV_REQUIREMENT_PENALTY,\n",
    "                                      balance_penalty=BALANCE_PENALTY,\n",
    "                                      execution_order=execution_order)\n",
    "\n",
    "    register_env(\"EC_Multi\", lambda config: env)\n",
    "\n",
    "    # Define the PPOConfig\n",
    "    config = PPOConfig() \\\n",
    "        .environment(env=\"EC_Multi\", disable_env_checking=False)\\\n",
    "        .training(train_batch_size=128,\n",
    "                  lr=2e-4, #tune.grid_search([0.001, 0.0001]),\n",
    "                  gamma=0.99,\n",
    "                  use_gae=True,\n",
    "                  use_critic=True,\n",
    "                  #model={#'fcnet_activation': 'linear',\n",
    "                         #'post_fcnet_activation': 'linear',\n",
    "                         #'use_lstm': True,\n",
    "                         #'fcnet_hiddens': [64, 64],\n",
    "                         #'lstm_cell_size': 256,\n",
    "                         #'max_seq_len': 2,\n",
    "                         #'lstm_use_prev_action': True,\n",
    "                         #'lstm_use_prev_reward': True,\n",
    "                         #'vf_share_layers': True\n",
    "                  #      }\n",
    "                )\\\n",
    "        .framework('torch') \\\n",
    "        .rollouts(batch_mode='complete_episodes', #'complete_episodes',\n",
    "                  num_rollout_workers=1,\n",
    "                  rollout_fragment_length='auto')\\\n",
    "        .multi_agent(policies={\n",
    "                               'ren_08': (None,\n",
    "                                          env.observation_space['ren_generator_08'],\n",
    "                                          env.action_space['ren_generator_08'],\n",
    "                                          PPOConfig.overrides(gamma=0.0)),\n",
    "                               'ren_09': (None,\n",
    "                                          env.observation_space['ren_generator_09'],\n",
    "                                          env.action_space['ren_generator_09'],\n",
    "                                          PPOConfig.overrides(gamma=0.0)),\n",
    "                               'ren_02': (None,\n",
    "                                          env.observation_space['ren_generator_02'],\n",
    "                                          env.action_space['ren_generator_02'],\n",
    "                                          PPOConfig.overrides(gamma=0.0)),\n",
    "                               'ren_06': (None,\n",
    "                                          env.observation_space['ren_generator_06'],\n",
    "                                          env.action_space['ren_generator_06'],\n",
    "                                          PPOConfig.overrides(gamma=0.0)),\n",
    "                               'ren_13': (None,\n",
    "                                          env.observation_space['ren_generator_13'],\n",
    "                                          env.action_space['ren_generator_13'],\n",
    "                                          PPOConfig.overrides(gamma=0.0)),\n",
    "                               'ev_01': (None,\n",
    "                                         env.observation_space['ev_01'],\n",
    "                                         env.action_space['ev_01'],\n",
    "                                         PPOConfig.overrides(gamma=0.9)),\n",
    "                               'ev_02': (None,\n",
    "                                         env.observation_space['ev_02'],\n",
    "                                         env.action_space['ev_02'],\n",
    "                                         PPOConfig.overrides(gamma=0.9)),\n",
    "                               'ev_03': (None,\n",
    "                                         env.observation_space['ev_03'],\n",
    "                                         env.action_space['ev_03'],\n",
    "                                         PPOConfig.overrides(gamma=0.9)),\n",
    "                               'ev_04': (None,\n",
    "                                         env.observation_space['ev_04'],\n",
    "                                         env.action_space['ev_04'],\n",
    "                                         PPOConfig.overrides(gamma=0.9)),\n",
    "                               'ev_05': (None,\n",
    "                                         env.observation_space['ev_05'],\n",
    "                                         env.action_space['ev_05'],\n",
    "                                         PPOConfig.overrides(gamma=0.9)),\n",
    "                               'storage_01': (None,\n",
    "                                              env.observation_space['storage_01'],\n",
    "                                              env.action_space['storage_01'],\n",
    "                                              PPOConfig.overrides(gamma=0.9)),\n",
    "                               'storage_02': (None,\n",
    "                                              env.observation_space['storage_02'],\n",
    "                                              env.action_space['storage_02'],\n",
    "                                              PPOConfig.overrides(gamma=0.9)),\n",
    "                               'storage_03': (None,\n",
    "                                              env.observation_space['storage_03'],\n",
    "                                              env.action_space['storage_03'],\n",
    "                                              PPOConfig.overrides(gamma=0.9)),\n",
    "                               'aggregator': (None,\n",
    "                                              env.observation_space['aggregator'],\n",
    "                                              env.action_space['aggregator'],\n",
    "                                              PPOConfig.overrides(gamma=0.9))},\n",
    "                     policy_mapping_fn=(\n",
    "                         lambda agent_id, episode, worker, **kwargs:\n",
    "                                        #'generator_renewable' if agent_id.startswith('ren_generator') else\n",
    "                                        'ren_08' if agent_id.startswith('ren_generator_08') else\n",
    "                                        'ren_09' if agent_id.startswith('ren_generator_09') else\n",
    "                                        'ren_02' if agent_id.startswith('ren_generator_02') else\n",
    "                                        'ren_06' if agent_id.startswith('ren_generator_06') else\n",
    "                                        'ren_13' if agent_id.startswith('ren_generator_13') else\n",
    "                                        'storage_01' if agent_id.startswith('storage_01') else\n",
    "                                        'storage_02' if agent_id.startswith('storage_02') else\n",
    "                                        'storage_03' if agent_id.startswith('storage_03') else\n",
    "                                        'ev_01' if agent_id.startswith('ev_01') else\n",
    "                                        'ev_02' if agent_id.startswith('ev_02') else\n",
    "                                        'ev_03' if agent_id.startswith('ev_03') else\n",
    "                                        'ev_04' if agent_id.startswith('ev_04') else\n",
    "                                        'ev_05' if agent_id.startswith('ev_05') else\n",
    "                                        'aggregator'\n",
    "                                        ))\n",
    "    \n",
    "    # if agent_id.startswith('ev') else\n",
    "                                        #'generator_non_renewable'))\n",
    "\n",
    "    #results = tune.run(\n",
    "    #    \"PPO\",\n",
    "    #    stop={\"training_iteration\": 100},\n",
    "    #    config=config.to_dict(),\n",
    "    #    checkpoint_at_end=True,\n",
    "    #    verbose=0,\n",
    "    #)\n",
    "    algo = config.build()\n",
    "    \n",
    "    '''\n",
    "    # Load the checkpoint if it exists\n",
    "    if checkpoint is not None:\n",
    "        policy = Policy.from_checkpoint(checkpoint.checkpoint.path)\n",
    "    \n",
    "        for p in policies.keys():\n",
    "            if p in policy.keys():\n",
    "                algo.get_policy(p).set_weights(policy[p].get_weights())\n",
    "    elif checkpoint_path is not None:\n",
    "        checkpoint = Checkpoint.from_directory(checkpoint_path)\n",
    "        policy = Policy.from_checkpoint(checkpoint)\n",
    "    \n",
    "        for p in policies.keys():\n",
    "            if p in policy.keys():\n",
    "                algo.get_policy(p).set_weights(policy[p].get_weights())\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Clear the Jupyter cell output\n",
    "    IPython.core.display_functions.clear_output()\n",
    "    \n",
    "    # Train for n iterations and report results (mean episode rewards)\n",
    "    print(f\"Datapoint {datapoint}\\n\")\n",
    "    for i in range(200):\n",
    "        results = algo.train()\n",
    "        print(f\"Iter: {i}; avg. reward={results['episode_reward_mean']}\")\n",
    "        # print(f\"Policy rewards: {results['policy_reward_mean']}\")\n",
    "        # if results['episode_reward_mean'] > 500:\n",
    "        #     break\n",
    "        # if results['episode_reward_mean'] > current_best_results['episode_reward_mean']:\n",
    "        #     current_best = algo.save()\n",
    "        #     current_best_results = results\n",
    "\n",
    "\n",
    "\n",
    "# if results['episode_reward_mean'] < 500:\n",
    "        # Save the checkpoint to disk.\n",
    "        # checkpoint = algo.save()\n",
    "        # algo.save('/Users/ecgomes/DataspellProjects/pyecom/models/sequential_v6_nogen_fullpenalty_{}'.format(datapoint))\n",
    "        \n",
    "    # else:\n",
    "    #    break\n",
    "    # print(\"checkpoints saved at\", checkpoint)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "204b37883758a647",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/ecgomes/DataspellProjects/pyecom/models/no_costs/sequential_monthly_v8), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'__all__': {'num_agent_steps_trained': 1792.0, 'num_env_steps_trained': 744.0, 'total_loss': 27.994122813088552}, 'ren_08': {'total_loss': 27.994122813088552, 'policy_loss': 0.00021704208904079028, 'vf_loss': 1.25502470120458e-07, 'vf_loss_unclipped': 1.25502470120458e-07, 'vf_explained_var': -1.0, 'entropy': 0.0004476785152551851, 'mean_kl_loss': 1.9364568552480777e-08, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 1.5527149582651164e-27}, 'ren_06': {'total_loss': 0.00023418636194297244, 'policy_loss': 0.00023389345833233424, 'vf_loss': 2.940111169940402e-07, 'vf_loss_unclipped': 2.940111169940402e-07, 'vf_explained_var': -1.0, 'entropy': 7.642200428693156e-05, 'mean_kl_loss': 1.1741787005964511e-06, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 2.587858344022275e-28}, 'ren_02': {'total_loss': -0.0005774629595024245, 'policy_loss': -0.000577554324907916, 'vf_loss': 9.377969608489625e-08, 'vf_loss_unclipped': 9.377969608489625e-08, 'vf_explained_var': -1.0, 'entropy': 2.0085665528313257e-05, 'mean_kl_loss': 5.027752301335645e-10, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 2.587858344022275e-28}, 'ren_09': {'total_loss': -0.0007016428959156786, 'policy_loss': -0.0007017955609730312, 'vf_loss': 1.553067059794395e-07, 'vf_loss_unclipped': 1.553067059794395e-07, 'vf_explained_var': -1.0, 'entropy': 4.474321480042168e-05, 'mean_kl_loss': 5.224422266056765e-08, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 5.17571668804455e-28}, 'ren_13': {'total_loss': -0.010587803710784232, 'policy_loss': -0.010709748928036009, 'vf_loss': 0.00012194592152419708, 'vf_loss_unclipped': 0.00012194592152419708, 'vf_explained_var': -0.8270307111740113, 'entropy': 8.868734200534943e-05, 'mean_kl_loss': 0.00014664864868029287, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 4.192330406575114e-26}, 'ev_01': {'total_loss': 2.839424350368125, 'policy_loss': -0.04745778307318688, 'vf_loss': 2.8798061245679856, 'vf_loss_unclipped': 1460.0720765095098, 'vf_explained_var': 0.5762474407468523, 'entropy': 0.6490801428897041, 'mean_kl_loss': 0.004596398511125047, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 0.7697353363037109}, 'ev_02': {'total_loss': 3.23266069659165, 'policy_loss': -0.04758100133655327, 'vf_loss': 3.258089044796569, 'vf_loss_unclipped': 229.4119503678807, 'vf_explained_var': 0.6167894155638558, 'entropy': 0.7560293116420508, 'mean_kl_loss': 0.010244270014334476, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 2.1624391078948975}, 'ev_03': {'total_loss': 3.544369014788951, 'policy_loss': -0.06409303770001445, 'vf_loss': 3.588830201625824, 'vf_loss_unclipped': 211.4403643514429, 'vf_explained_var': 0.5592281171253749, 'entropy': 0.8107067184363093, 'mean_kl_loss': 0.010213402695868257, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 1.9221680164337158}, 'ev_04': {'total_loss': 7.765425699778966, 'policy_loss': -0.044434470842991555, 'vf_loss': 7.795732242039271, 'vf_loss_unclipped': 735252.0895767647, 'vf_explained_var': 0.08580745492662702, 'entropy': 0.877429563488279, 'mean_kl_loss': 0.00871111377753681, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 1.6218292713165283}, 'ev_05': {'total_loss': 4.77134602676944, 'policy_loss': -0.06335545356252363, 'vf_loss': 4.81386799454689, 'vf_loss_unclipped': 168.5637812250001, 'vf_explained_var': 0.4129223462513515, 'entropy': 0.768980801999569, 'mean_kl_loss': 0.014451412819480806, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 1.4416260719299316}, 'storage_01': {'total_loss': 1.4536811543575354, 'policy_loss': -0.0494577177534146, 'vf_loss': 1.49078920890178, 'vf_loss_unclipped': 1352.6002660892477, 'vf_explained_var': 0.44830717154911587, 'entropy': 2.154806874820164, 'mean_kl_loss': 0.010841950687180132, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 1.139062523841858}, 'storage_02': {'total_loss': 1.1625154363257544, 'policy_loss': -0.039796813928655216, 'vf_loss': 1.1908448391301292, 'vf_loss_unclipped': 281.68340050952776, 'vf_explained_var': 0.3883189344406128, 'entropy': 2.0945714698519025, 'mean_kl_loss': 0.01006742924950591, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 1.139062523841858}, 'storage_03': {'total_loss': 0.7973576283454895, 'policy_loss': -0.04249141529734646, 'vf_loss': 0.8309835934745414, 'vf_loss_unclipped': 283.1258218391559, 'vf_explained_var': 0.2095006660052708, 'entropy': 2.291024881090437, 'mean_kl_loss': 0.00583732557802751, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 1.5187500715255737}, 'aggregator': {'total_loss': 2.4387587604352405, 'policy_loss': -0.0005841954265322004, 'vf_loss': 2.4393429839611054, 'vf_loss_unclipped': 176458.9964784876, 'vf_explained_var': 0.13578247240611485, 'entropy': 0.0, 'mean_kl_loss': 0.0, 'default_optimizer_lr': 0.0002, 'curr_lr': 0.0002, 'curr_entropy_coeff': 0.0, 'curr_kl_coeff': 1.5407439784686627e-34}}, 'num_env_steps_sampled': 1145760, 'num_env_steps_trained': 0, 'num_agent_steps_sampled': 1145760, 'num_agent_steps_trained': 0}, 'sampler_results': {'episode_reward_max': 16548.93529999913, 'episode_reward_min': -78399.16950000693, 'episode_reward_mean': 3447.708367999397, 'episode_len_mean': 10416.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {'ren_08': 551.5999999999922, 'ren_06': 601.7999999999936, 'ren_02': 583.199999999996, 'ren_09': 637.3999999999926, 'ren_13': 598.5999999999968, 'ev_01': 245.6958999999995, 'ev_02': -41188.88960000001, 'ev_03': -1248.6247999999996, 'ev_04': -37116.57190000001, 'ev_05': -35379.6772, 'storage_01': -2302.408500000001, 'storage_02': -2733.7986999999985, 'storage_03': -2690.4881999999975, 'aggregator': -5370.553099999999}, 'policy_reward_max': {'ren_08': 669.5999999999907, 'ren_06': 669.5999999999907, 'ren_02': 669.5999999999907, 'ren_09': 669.5999999999907, 'ren_13': 669.5999999999907, 'ev_01': 3176.389900000001, 'ev_02': 3262.939, 'ev_03': 3103.975100000001, 'ev_04': 2747.609699999999, 'ev_05': 3055.237999999999, 'storage_01': 3.204500000000007, 'storage_02': 59.65120000000009, 'storage_03': 21.948700000000013, 'aggregator': -365.0730000000001}, 'policy_reward_mean': {'ren_08': 667.5229999999907, 'ren_06': 668.1999999999907, 'ren_02': 667.8809999999908, 'ren_09': 668.6289999999906, 'ren_13': 666.6069999999908, 'ev_01': 2528.4423999999995, 'ev_02': 1537.9222509999997, 'ev_03': 2152.506228, 'ev_04': -4183.047329000003, 'ev_05': -64.90745800000029, 'storage_01': -382.87190599999985, 'storage_02': -605.6833070000001, 'storage_03': -409.0748310000001, 'aggregator': -464.41768}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-5303.157700000094, -5909.860699999926, -728.8237000000539, 339.0832999999537, -369.04640000001365, 537.2118000001175, 3457.324500000216, 1974.1672000002006, 1190.4838000002906, 4767.339799999888, 7171.598499999413, 8865.33239999936, 8852.319599999397, 9195.283999999398, -16660.3725999994, 9253.043899999124, 184.27020000000908, 12237.584199999117, 12664.213299999132, 12490.045699999122, -13717.721700000659, 9329.427799999123, 12713.52169999908, 13270.909199999074, 6253.370799999862, 13954.249099999131, -14429.42880000058, 13732.504299999042, 10596.122599999017, -30286.496199998604, 11541.845799999306, 14653.859699998959, 3667.5067999997186, 16548.93529999913, -10095.059000000758, 13522.874199998952, -11616.892900000792, 7637.863899999671, -456.09800000027263, 10815.175299998957, 12553.357299998972, -22131.495099998097, 16032.672199998991, 13101.243599999189, 16199.623499998987, 2659.850499999441, 16022.788699999004, -1012.6709000002562, 16006.4429999992, -78399.16950000693, 2217.3515999993215, 11046.37599999944, 15890.85299999932, -431.0998000003767, 13524.019999998962, -15817.02900000093, 11069.862399998934, -14970.54230000101, 8922.460299998978, -24539.074699998204, -14170.624900001096, 12167.146299998965, 13104.079299998974, 15797.39139999896, -4881.826200000741, -35209.52519999822, 14077.75499999898, 11959.355699998965, 3658.4573999995314, 2867.9174999999723, 2593.3902999999827, 13464.439499998934, 647.1854999992817, 15315.807899998952, 8313.667499999006, -402.5054000002586, -2617.1991000000944, 16398.850599999394, 14236.393799999003, 3709.7912999990376, 13949.877099998968, -5914.6330000008065, 4377.460299999879, 6447.951199999029, 11796.527999998974, 8817.719799999124, 12516.25699999893, 14702.024199998988, -1320.2161000000401, 13390.851499998938, -12778.035800000951, 13166.347599998935, 7692.934299998986, 12411.146799998962, 785.275999999389, 4095.568499999716, 14326.225999999073, 4969.505999999147, 13700.07679999893, -23182.309399997604], 'episode_lengths': [10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416], 'policy_ren_08_reward': [645.9999999999925, 651.8999999999922, 651.5999999999922, 658.3999999999915, 663.3999999999912, 665.8999999999909, 666.6999999999911, 668.0999999999908, 669.0999999999907, 668.4999999999908, 668.9999999999908, 669.2999999999907, 669.5999999999907, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 668.8999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.3999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 551.5999999999922, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 668.1999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_ren_06_reward': [649.599999999992, 649.799999999992, 659.4999999999916, 661.3999999999916, 665.5999999999912, 664.9999999999911, 666.8999999999908, 668.4999999999908, 669.4999999999907, 668.8999999999908, 669.5999999999907, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.3999999999908, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 601.7999999999936, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.1999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_ren_02_reward': [645.8999999999926, 650.9999999999924, 657.7999999999919, 661.5999999999912, 662.499999999991, 663.6999999999912, 666.299999999991, 666.6999999999908, 668.0999999999908, 668.5999999999908, 669.3999999999907, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 668.7999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.2999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 583.199999999996, 669.5999999999907, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_ren_09_reward': [651.5999999999924, 658.6999999999916, 657.4999999999915, 660.1999999999912, 663.2999999999911, 666.399999999991, 667.7999999999909, 669.4999999999907, 669.1999999999908, 669.2999999999907, 669.5999999999907, 669.5999999999907, 669.4999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 668.7999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 668.8999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 637.3999999999926, 668.8999999999908, 669.5999999999907, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_ren_13_reward': [646.0999999999924, 648.599999999992, 653.6999999999917, 661.5999999999913, 662.899999999991, 665.899999999991, 665.299999999991, 667.5999999999909, 669.0999999999907, 667.8999999999909, 669.2999999999907, 669.0999999999907, 669.2999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.4999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 599.6999999999957, 669.5999999999907, 669.5999999999907, 669.3999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 600.4999999999931, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 598.5999999999968, 669.5999999999907, 669.5999999999907, 669.2999999999907], 'policy_ev_01_reward': [699.1656000000005, 245.6958999999995, 903.8563000000005, 1158.525699999999, 1032.8712999999984, 1518.5068, 1590.7815999999991, 2009.4535999999985, 2211.326099999998, 1594.0236999999988, 2423.0019999999995, 2583.1674000000003, 2313.9160999999995, 2786.4874, 2730.0119000000004, 2799.727500000001, 2150.4656999999975, 2952.6475999999984, 2425.2911999999997, 2830.1267000000007, 2815.8460000000014, 2594.9676999999992, 2987.5361999999986, 3094.0963999999994, 2796.7045000000003, 3161.2403, 2100.9391000000005, 3170.2379, 2934.944800000001, 1825.3326999999986, 3098.7161000000006, 3074.3509999999997, 2950.172599999999, 3088.147999999999, 3132.736599999999, 399.1892000000005, 3067.7204999999985, 3122.836000000002, 3089.7482999999993, 3092.409, 1277.4345000000003, 2835.8899, 2266.0258999999996, 2998.5636, 3093.879499999999, 2859.8978999999995, 3124.3412999999996, 3150.2078000000006, 3109.785200000001, 1751.1297999999997, 2071.5145999999995, 3072.090099999999, 3176.389900000001, 2161.1045999999988, 1870.9322000000006, 2699.183400000001, 3046.8905, 986.4009000000009, 2846.3053000000004, 3049.2962999999995, 2125.5964000000004, 3103.9377000000018, 3102.7259, 2920.7520000000004, 2742.7482999999984, 3001.6875999999997, 2755.2174999999993, 2459.8644999999983, 3021.769699999998, 3005.350099999999, 3048.598899999998, 3047.9435999999987, 2113.2146000000007, 3073.4585999999986, 2484.7039000000004, 3051.1737999999996, 3139.8718000000003, 3112.322399999999, 3094.5683000000004, 2924.345, 2090.821000000001, 2910.8902000000003, 2872.160999999999, 1633.7073999999986, 2669.1625, 3042.4796, 3122.0149, 3113.916899999999, 1536.9917999999989, 2742.6263, 1651.0089999999998, 2271.2118999999993, 3038.0170000000016, 3078.3670000000006, 1241.1864, 2627.2770999999975, 1840.9532000000004, 2715.3241, 2753.122, 2558.9638999999997], 'policy_ev_02_reward': [-1302.841999999999, -1098.6251000000004, -855.2160999999996, -1581.3457999999996, -162.2698999999996, -55.745399999999705, -230.78989999999993, -61.50480000000023, 750.0449999999998, 195.1066999999999, 1031.4803000000009, 889.7886000000003, 985.0457000000002, 1221.3556000000005, 1356.7926000000004, 2099.8859, 1959.5440000000006, 2044.8153000000002, 2231.075999999999, 1550.4273000000007, 2110.0438999999997, 2063.3490000000006, 2527.0117, 2494.4728, 2743.0034, 2824.611600000001, 2245.7308999999996, 2682.615199999999, 2689.350199999999, 3004.2776000000003, 1903.2408000000003, 3071.256199999999, 3044.586499999999, 3246.7814, 3226.4697, 3048.7755, 3262.939, 3051.8086000000008, 3199.813800000001, 1546.1541000000007, 2752.180499999997, 2658.4098, 3163.3158000000003, 2281.3062000000014, 2944.4518, 3106.4460000000013, 2734.122999999998, 1113.6376999999986, 2685.4324999999994, -41188.88960000001, 978.4269999999993, 2025.0245999999997, 3061.860500000001, 2735.813399999998, 2024.0749999999998, 2956.971199999999, 795.7789999999989, 2166.5069999999996, 1594.1989000000008, 2313.424600000001, 2535.108400000001, 2845.5441999999994, 2852.312899999999, 2883.7809000000016, 1924.162199999999, 2522.8817000000004, 2744.0251999999978, 1903.5134000000016, 1132.8666999999987, 2956.3782, 2149.5863000000013, 1391.8589000000004, 1864.7818000000007, 2250.6525999999967, 2849.8861999999986, 2633.989399999999, 1860.4430999999968, 2542.6534000000015, 2171.6408999999985, 2729.9118000000008, 2597.4360000000006, 2244.0642999999986, 1864.2123000000004, 2222.206599999998, 2481.271399999998, 1938.4501999999993, 720.7508000000009, 2482.3437, 581.6466000000008, 721.3365999999991, 1988.277200000001, 2664.986800000003, 2083.464799999999, 2543.4359999999997, 2063.2076999999977, 2727.866099999999, 2121.733599999999, 1290.787100000001, 1228.9034000000004, 2624.054899999997], 'policy_ev_03_reward': [-1093.5049, -332.05419999999987, 457.98929999999973, 842.5354000000005, -352.0812000000003, 644.6067000000002, 1142.9304000000009, 1360.1256999999998, -1248.6247999999996, 1698.3441999999986, 1781.0802999999994, 2106.1310999999982, 1815.5242000000005, 657.1084999999997, 2210.7565999999997, 2529.029700000002, -1245.4040999999997, 2542.6008999999995, 2339.3947, 2758.8435999999997, 2827.845199999999, 2937.8645, 3103.975100000001, 2595.3655000000003, 1797.9831999999997, 2869.5071000000003, 2927.7415999999994, 3019.702000000001, 2617.1254999999987, 1795.6904000000004, 3082.698799999999, 1682.1572, 3048.6778999999997, 3081.9122000000025, 3027.4922999999985, 2426.0758, 2925.083999999998, 2995.6067000000003, 2627.6794999999997, 3009.145400000002, 1956.7415999999996, 2779.9818000000023, 2909.3418000000006, 2773.2615, 2877.5683000000013, 1906.745499999999, 2639.9158000000007, 2615.3508000000006, 2795.2786000000037, 2883.7223999999987, 2889.000400000001, 2867.147400000001, 2853.8992000000007, -89.1487, 1838.5097, 843.0386999999993, 1943.3364000000013, 2878.9229000000005, 2913.194900000001, 2249.995399999998, 2909.8128000000006, 2790.8092, 2727.9907999999978, 2624.4759000000004, 2742.6776999999984, 2798.198400000002, 2773.4648000000007, 1985.6715000000004, 1180.381599999999, 1586.912799999997, 2672.593699999999, 1876.0697999999993, 2664.618599999998, 2260.7283999999986, 2650.484699999997, 2307.3385000000003, 2700.473099999996, 2703.618999999998, 2652.640299999999, 2549.7393999999967, 2545.9007, 2773.492099999999, 2726.5037999999986, 556.3306999999992, 1474.6024000000002, 1792.8452999999986, 2285.604400000003, 2600.176200000005, -29.24549999999961, 2754.022400000001, 813.9085999999991, 2793.7006000000006, 2108.381399999999, 2701.4419, 2638.9644999999996, 2670.006900000001, 2731.7557000000006, 2645.2220000000016, 2594.8945999999983, 2572.9466999999986], 'policy_ev_04_reward': [-764.1521999999999, -197.57630000000023, 104.95120000000003, 549.2211999999993, 25.51390000000015, 824.5797000000005, 206.72959999999998, 1132.7265999999997, -376.06530000000004, 1595.1847999999977, 1340.9035999999983, 938.093299999999, 1885.0315999999968, 2209.338599999997, -25596.3292, 1724.384199999998, -6606.463199999995, 1775.5396999999982, 2081.2444999999984, 1519.0905999999977, -24756.9445, -2931.7353999999973, 2285.343999999997, 2212.2036999999973, -4897.901399999999, 2374.268199999996, -24585.2146, -42.28540000000112, 2441.596999999997, -30451.5725, -568.4373000000012, 2460.712699999997, 2253.636699999999, 2389.2846999999992, -19268.7019, 2597.1833999999994, -18785.27150000002, -6349.512499999993, 1918.0832999999989, 1995.2663999999984, 2231.615799999997, -18505.658700000004, 2412.4804999999974, -374.8421000000007, 2552.5051999999987, -9973.888000000004, 2519.1367000000005, -12860.401400000008, 2544.5265, -20890.810899999986, -4631.578700000001, -1597.4541000000017, 2600.4574999999986, -10662.861200000005, 2747.609699999999, -26819.0985, 2618.440799999999, -25161.581700000024, 2708.7431999999976, -37116.57190000001, -26701.351500000004, -1833.9987000000024, 2451.137699999997, 2564.894499999998, -16570.525800000007, -10947.855700000018, 2527.12, 2087.9961999999978, 225.4133000000006, -9728.817800000019, 2717.557499999997, 2066.7529999999997, -11106.734100000007, 2597.720399999999, -3950.0344999999998, -12629.35850000002, 2431.0427, 2342.7267999999967, 2025.232699999997, 2400.0424999999987, 2449.739499999998, -19034.67869999999, -7702.8961000000045, 1852.564199999998, 2340.8703, 2440.681299999999, 1695.340899999998, 1986.3261999999984, 2421.9029999999984, 2620.0822000000003, -21714.012199999986, 2566.6011999999982, -3226.2005999999997, 1223.2024999999978, -10198.991800000003, -9070.522000000012, 2692.491099999999, -5741.823999999998, 2691.6386, -30568.72790000002], 'policy_ev_05_reward': [456.09209999999973, -3161.677, 632.7269000000001, 580.0523000000002, -1466.4127000000008, 154.80070000000012, 783.8278999999998, 1040.1369000000002, -727.2383000000005, 1319.2453000000007, 113.87900000000057, 1216.8513000000007, 1680.9662999999987, 2007.2464999999993, 2334.4862, 1194.3531999999993, 2426.1337000000003, 2189.9811999999997, 2059.4516999999996, 2655.3309000000004, 2043.3629999999991, 2255.2308999999996, -1.4298999999997342, 1446.4143999999994, 2267.4686000000006, 2458.5279999999993, 313.8545000000003, 2647.943799999999, -1166.0679999999993, -8575.162900000003, 1957.0877000000005, 2042.0596999999996, -10326.937700000008, 2790.4551000000015, -1955.0544999999995, 2906.829699999999, -4299.0, 2778.2999000000013, -12140.412300000002, -1469.0177999999994, 2720.2336000000005, -14518.030000000002, 2485.4039000000007, 2745.921199999999, 2671.261599999998, 2675.0368999999996, 2694.8802000000014, 2248.9746, 2775.2981999999984, -22841.878699999997, -1450.3346000000022, 2816.7084999999997, 2864.3666000000007, 2729.1888000000004, 2299.300999999998, 2429.480399999998, -40.05249999999999, 2814.8983000000007, -3509.872999999999, 2842.128500000001, 2600.642999999997, 2682.025800000003, -588.7412000000002, 2852.6615999999985, 2872.510499999999, -35379.6772, 2891.7272, 1925.285699999999, -3670.502200000001, 2907.9903000000004, -9576.759999999997, 2709.6042, 2906.531299999999, 2933.2763999999984, 2881.293099999999, 2953.7411999999995, -15366.353799999997, 3055.237999999999, 3005.0116999999987, -7923.630900000001, 2884.4376, 2778.1963, 2445.0280999999995, -1639.440200000001, 455.8857999999996, -2382.7150000000024, 2683.9939000000018, 2517.173399999998, -7531.631600000001, 2746.4795, 2873.5242000000003, 2463.3749999999995, 875.8964999999989, 670.9986999999995, 2649.1043999999983, 2562.5959, 2775.262900000001, 1845.8193999999992, 1619.5349, 2626.2599999999993], 'policy_storage_01_reward': [-1615.490099999999, -1324.2137999999986, -921.3989999999992, -740.9713999999996, -933.5197999999995, -1399.273, -1371.2844000000007, -2302.408500000001, -659.0850000000002, -846.3896999999988, -672.7795000000003, -416.7499999999998, -759.3210999999991, -348.83769999999964, -1048.192099999998, -897.1374999999998, -207.88140000000018, -377.6895, -208.88970000000023, -124.41300000000003, -536.8908999999999, -106.96940000000001, -714.0477999999986, -59.92250000000002, -82.37880000000008, -105.79530000000008, -143.88670000000022, -48.90950000000003, -860.4919999999985, -233.09910000000002, -262.0453, -49.991000000000035, -61.05920000000003, -465.71210000000013, -86.95199999999996, -74.65080000000013, -438.3952999999999, -232.96769999999978, -627.6734999999993, -37.06910000000003, -49.331699999999934, -40.93840000000002, -102.46190000000021, -34.65499999999999, -223.80810000000002, -631.4348000000003, -225.32450000000003, -230.03189999999992, -439.7925999999999, -225.13209999999992, -29.0383, -229.49009999999998, -41.21860000000004, -44.2677, -12.184499999999998, -23.21929999999998, -23.369599999999995, -221.30209999999994, -407.93379999999985, -432.0400000000001, -412.6986999999997, -210.15279999999998, -220.1312, -224.0108999999997, -410.21239999999966, -15.859, -823.0189999999999, -427.47759999999994, -421.3278999999998, -415.619, -214.96019999999982, -423.0375999999999, -212.61409999999998, -12.0879, -211.58509999999984, -621.585999999999, -207.11789999999982, -15.962000000000002, -1015.5652999999998, -203.78309999999996, -1015.7608999999997, -208.20209999999992, -612.2839999999994, -11.901599999999998, -216.36909999999983, -212.03029999999987, -211.36759999999984, -214.15189999999976, -413.3483, -1.8079999999999896, -3.2551000000000014, -797.4070000000003, -1.010199999999997, 3.204500000000007, -199.9117999999999, -196.9294000000001, -397.0407999999998, 0.4954999999999936, -193.3718999999998, -594.1236999999999], 'policy_storage_02_reward': [-1785.2102999999966, -1468.9633000000013, -2127.562699999999, -1273.7696999999987, -785.8167999999997, -2587.5195000000003, -1163.3885999999993, -1349.823399999999, -859.5561999999991, -2718.7911999999997, -1068.293200000001, -771.7657000000008, -643.644800000001, -1807.2906999999987, -1420.0076000000001, -2733.7986999999985, -596.7906000000008, -1479.9757999999997, -284.01329999999984, -1253.5378000000007, -1068.7990999999997, -301.7511999999999, -360.1347000000005, -783.7888000000011, -606.6644000000003, -2137.161800000003, -185.8796999999996, -568.8567000000005, -753.7038000000005, -360.92429999999973, -580.7289000000005, -339.3874000000001, -151.88449999999978, -104.89459999999984, -703.1072000000006, -96.37939999999983, -87.07209999999999, -653.1208000000003, -1462.7212000000009, -59.12149999999992, -657.5408000000002, -246.5669, -48.83340000000003, -244.19869999999997, -228.02190000000002, -46.70680000000001, -13.629200000000003, -1.3024000000000155, -222.90029999999985, -636.0298000000009, -190.83949999999987, -786.2448999999995, -992.4885999999999, -216.09869999999995, -209.5699, -234.4748, -224.9168999999999, -604.6621999999996, 7.017099999999995, -406.57520000000005, 9.25699999999999, 21.34999999999996, 13.063599999999955, -184.21789999999967, -1167.2514999999999, -157.10609999999974, -774.4283000000001, -356.99810000000025, -775.0763000000005, -160.72409999999996, -1160.5200000000002, 44.974800000000094, -551.854500000001, -767.7180000000005, -357.18000000000006, -393.45820000000003, -167.6958999999999, 59.65120000000009, -154.11559999999997, -346.8281000000004, 45.14360000000007, -353.07270000000005, -186.18019999999996, -555.5171, -396.5101, -361.6615999999999, -172.37310000000014, 20.817500000000045, -759.2201000000008, -969.4539999999998, -986.7628999999998, -1375.8201000000006, 34.20110000000001, -383.38300000000004, -192.9118, -193.58149999999995, -358.22830000000033, -170.87809999999985, 18.71569999999998, -194.59220000000016], 'policy_storage_03_reward': [-2593.5677000000005, -1280.3026000000002, -1674.603100000001, -1968.1275999999987, -524.7941000000001, -1367.6618999999998, -308.5073999999998, -2690.4881999999975, -748.2820000000011, -919.4512000000004, -643.1785, -541.8950999999997, -1294.2801000000002, -403.5421000000006, -103.38839999999989, -351.40810000000033, -588.0286000000003, -292.87850000000003, -864.8334000000017, -338.74690000000044, -45.7693, -71.60479999999994, -19.828999999999965, -637.5659999999995, -670.5420000000001, -410.16620000000034, -25.275399999999895, -38.285999999999945, -225.29629999999995, -212.4286, -3.086900000000003, -205.2188999999999, 0.2222999999999961, -400.3537999999999, -404.72200000000066, -614.2251000000002, -197.90749999999986, -17.453699999999998, -5.305900000000002, -204.8642, -629.2949000000004, -44.65339999999994, 6.545499999999989, 4.653100000000001, -430.7367999999998, -185.7618, -409.13639999999975, -15.100699999999982, -203.12519999999995, -214.44469999999978, -387.6622000000007, -0.21989999999999738, -594.7949999999998, -2.995700000000002, -6.446800000000007, -598.4458999999999, 3.690499999999985, -786.9510999999998, -186.30979999999983, 2.6476999999999955, -197.56339999999958, -192.18119999999996, -196.65389999999968, -605.9368999999995, 13.667499999999986, 6.3834, -982.4640999999999, -588.0517000000003, 3.1899000000000055, -181.58879999999988, 1.6760999999999902, -216.2278, 0.5919999999999803, 21.634599999999995, -997.5567000000001, -602.2649, 9.210800000000003, -381.4995, -384.7298, -1390.3723000000014, -609.4814000000001, 7.472499999999998, -0.09750000000000815, -586.9381999999996, 16.933599999999995, -408.5662999999997, -578.6245, -776.1422000000006, -18.780200000000008, -191.67079999999999, -382.0399, -393.5141999999998, -196.0999999999996, -405.3851999999999, -190.27550000000002, -2.973400000000005, 13.202299999999997, -595.2879, 21.948700000000013, -184.238], 'policy_aggregator_reward': [-542.8482, -552.1443, -529.6665, -530.2368000000002, -520.2371000000006, -521.9822999999996, -525.9747000000001, -504.4506999999999, -497.0357000000003, -493.1328, -481.39550000000037, -485.1885000000002, -478.51829999999984, -474.48210000000034, -472.5025999999995, -459.99230000000006, -455.20529999999985, -465.1567, -462.4084000000001, -455.07569999999964, -453.7159999999997, -457.9234999999999, -442.9039000000001, -437.5662999999998, -442.30230000000034, -428.7828000000005, -425.43849999999946, -437.6569999999998, -429.33480000000037, -426.60949999999974, -433.5991999999999, -430.0798000000001, -437.90779999999984, -424.6855999999998, -411.01999999999936, -417.92409999999984, -412.19, -404.9326000000002, -403.31000000000034, -405.7270000000001, -396.6813000000003, -397.92920000000004, -407.14590000000027, -396.76619999999957, -405.4760999999995, -398.48439999999954, -389.51820000000015, -382.00540000000024, -386.0599, -384.8358999999998, -380.13710000000054, -398.9855999999998, -385.6184999999998, -389.8345999999995, -376.0063999999998, -386.26420000000013, -397.23579999999987, -390.7743000000002, -390.78249999999986, -389.38009999999974, -387.42890000000006, -388.1879000000006, -385.62530000000015, -383.00779999999986, -377.6027, -386.1782999999999, -381.8883, -378.4481999999996, -386.2573999999998, -380.8641999999998, -392.2820000000004, -381.49940000000015, -379.3501000000002, -389.8572000000001, -384.34409999999997, -382.28069999999997, -365.0730000000001, -367.8986999999998, -388.2894, -377.6330000000003, -386.3590000000002, -380.79490000000015, -376.9871000000002, -371.06060000000014, -377.3187999999999, -378.36339999999996, -376.8826999999996, -376.4356000000001, -370.13180000000017, -378.76270000000045, -366.4847000000002, -374.78659999999996, -371.7157000000001, -368.73560000000055, -372.69609999999966, -376.1711999999999, -370.9036999999997, -368.15210000000036, -383.3091999999999, -5370.553099999999]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1370391283986539, 'mean_inference_ms': 0.3633769520597312, 'mean_action_processing_ms': 0.03580106444683358, 'mean_env_wait_ms': 0.028322516700498478, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.009131567818777902, 'StateBufferConnector_ms': 0.0010931151253836496, 'ViewRequirementAgentConnector_ms': 0.0689772197178432}}, 'episode_reward_max': 16548.93529999913, 'episode_reward_min': -78399.16950000693, 'episode_reward_mean': 3447.708367999397, 'episode_len_mean': 10416.0, 'episodes_this_iter': 1, 'policy_reward_min': {'ren_08': 551.5999999999922, 'ren_06': 601.7999999999936, 'ren_02': 583.199999999996, 'ren_09': 637.3999999999926, 'ren_13': 598.5999999999968, 'ev_01': 245.6958999999995, 'ev_02': -41188.88960000001, 'ev_03': -1248.6247999999996, 'ev_04': -37116.57190000001, 'ev_05': -35379.6772, 'storage_01': -2302.408500000001, 'storage_02': -2733.7986999999985, 'storage_03': -2690.4881999999975, 'aggregator': -5370.553099999999}, 'policy_reward_max': {'ren_08': 669.5999999999907, 'ren_06': 669.5999999999907, 'ren_02': 669.5999999999907, 'ren_09': 669.5999999999907, 'ren_13': 669.5999999999907, 'ev_01': 3176.389900000001, 'ev_02': 3262.939, 'ev_03': 3103.975100000001, 'ev_04': 2747.609699999999, 'ev_05': 3055.237999999999, 'storage_01': 3.204500000000007, 'storage_02': 59.65120000000009, 'storage_03': 21.948700000000013, 'aggregator': -365.0730000000001}, 'policy_reward_mean': {'ren_08': 667.5229999999907, 'ren_06': 668.1999999999907, 'ren_02': 667.8809999999908, 'ren_09': 668.6289999999906, 'ren_13': 666.6069999999908, 'ev_01': 2528.4423999999995, 'ev_02': 1537.9222509999997, 'ev_03': 2152.506228, 'ev_04': -4183.047329000003, 'ev_05': -64.90745800000029, 'storage_01': -382.87190599999985, 'storage_02': -605.6833070000001, 'storage_03': -409.0748310000001, 'aggregator': -464.41768}, 'hist_stats': {'episode_reward': [-5303.157700000094, -5909.860699999926, -728.8237000000539, 339.0832999999537, -369.04640000001365, 537.2118000001175, 3457.324500000216, 1974.1672000002006, 1190.4838000002906, 4767.339799999888, 7171.598499999413, 8865.33239999936, 8852.319599999397, 9195.283999999398, -16660.3725999994, 9253.043899999124, 184.27020000000908, 12237.584199999117, 12664.213299999132, 12490.045699999122, -13717.721700000659, 9329.427799999123, 12713.52169999908, 13270.909199999074, 6253.370799999862, 13954.249099999131, -14429.42880000058, 13732.504299999042, 10596.122599999017, -30286.496199998604, 11541.845799999306, 14653.859699998959, 3667.5067999997186, 16548.93529999913, -10095.059000000758, 13522.874199998952, -11616.892900000792, 7637.863899999671, -456.09800000027263, 10815.175299998957, 12553.357299998972, -22131.495099998097, 16032.672199998991, 13101.243599999189, 16199.623499998987, 2659.850499999441, 16022.788699999004, -1012.6709000002562, 16006.4429999992, -78399.16950000693, 2217.3515999993215, 11046.37599999944, 15890.85299999932, -431.0998000003767, 13524.019999998962, -15817.02900000093, 11069.862399998934, -14970.54230000101, 8922.460299998978, -24539.074699998204, -14170.624900001096, 12167.146299998965, 13104.079299998974, 15797.39139999896, -4881.826200000741, -35209.52519999822, 14077.75499999898, 11959.355699998965, 3658.4573999995314, 2867.9174999999723, 2593.3902999999827, 13464.439499998934, 647.1854999992817, 15315.807899998952, 8313.667499999006, -402.5054000002586, -2617.1991000000944, 16398.850599999394, 14236.393799999003, 3709.7912999990376, 13949.877099998968, -5914.6330000008065, 4377.460299999879, 6447.951199999029, 11796.527999998974, 8817.719799999124, 12516.25699999893, 14702.024199998988, -1320.2161000000401, 13390.851499998938, -12778.035800000951, 13166.347599998935, 7692.934299998986, 12411.146799998962, 785.275999999389, 4095.568499999716, 14326.225999999073, 4969.505999999147, 13700.07679999893, -23182.309399997604], 'episode_lengths': [10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416, 10416], 'policy_ren_08_reward': [645.9999999999925, 651.8999999999922, 651.5999999999922, 658.3999999999915, 663.3999999999912, 665.8999999999909, 666.6999999999911, 668.0999999999908, 669.0999999999907, 668.4999999999908, 668.9999999999908, 669.2999999999907, 669.5999999999907, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 668.8999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.3999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 551.5999999999922, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 668.1999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_ren_06_reward': [649.599999999992, 649.799999999992, 659.4999999999916, 661.3999999999916, 665.5999999999912, 664.9999999999911, 666.8999999999908, 668.4999999999908, 669.4999999999907, 668.8999999999908, 669.5999999999907, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.3999999999908, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 601.7999999999936, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.1999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_ren_02_reward': [645.8999999999926, 650.9999999999924, 657.7999999999919, 661.5999999999912, 662.499999999991, 663.6999999999912, 666.299999999991, 666.6999999999908, 668.0999999999908, 668.5999999999908, 669.3999999999907, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 668.7999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.2999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 583.199999999996, 669.5999999999907, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_ren_09_reward': [651.5999999999924, 658.6999999999916, 657.4999999999915, 660.1999999999912, 663.2999999999911, 666.399999999991, 667.7999999999909, 669.4999999999907, 669.1999999999908, 669.2999999999907, 669.5999999999907, 669.5999999999907, 669.4999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 668.7999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 668.8999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 637.3999999999926, 668.8999999999908, 669.5999999999907, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907], 'policy_ren_13_reward': [646.0999999999924, 648.599999999992, 653.6999999999917, 661.5999999999913, 662.899999999991, 665.899999999991, 665.299999999991, 667.5999999999909, 669.0999999999907, 667.8999999999909, 669.2999999999907, 669.0999999999907, 669.2999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.4999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 599.6999999999957, 669.5999999999907, 669.5999999999907, 669.3999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 600.4999999999931, 669.4999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.3999999999908, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 669.5999999999907, 598.5999999999968, 669.5999999999907, 669.5999999999907, 669.2999999999907], 'policy_ev_01_reward': [699.1656000000005, 245.6958999999995, 903.8563000000005, 1158.525699999999, 1032.8712999999984, 1518.5068, 1590.7815999999991, 2009.4535999999985, 2211.326099999998, 1594.0236999999988, 2423.0019999999995, 2583.1674000000003, 2313.9160999999995, 2786.4874, 2730.0119000000004, 2799.727500000001, 2150.4656999999975, 2952.6475999999984, 2425.2911999999997, 2830.1267000000007, 2815.8460000000014, 2594.9676999999992, 2987.5361999999986, 3094.0963999999994, 2796.7045000000003, 3161.2403, 2100.9391000000005, 3170.2379, 2934.944800000001, 1825.3326999999986, 3098.7161000000006, 3074.3509999999997, 2950.172599999999, 3088.147999999999, 3132.736599999999, 399.1892000000005, 3067.7204999999985, 3122.836000000002, 3089.7482999999993, 3092.409, 1277.4345000000003, 2835.8899, 2266.0258999999996, 2998.5636, 3093.879499999999, 2859.8978999999995, 3124.3412999999996, 3150.2078000000006, 3109.785200000001, 1751.1297999999997, 2071.5145999999995, 3072.090099999999, 3176.389900000001, 2161.1045999999988, 1870.9322000000006, 2699.183400000001, 3046.8905, 986.4009000000009, 2846.3053000000004, 3049.2962999999995, 2125.5964000000004, 3103.9377000000018, 3102.7259, 2920.7520000000004, 2742.7482999999984, 3001.6875999999997, 2755.2174999999993, 2459.8644999999983, 3021.769699999998, 3005.350099999999, 3048.598899999998, 3047.9435999999987, 2113.2146000000007, 3073.4585999999986, 2484.7039000000004, 3051.1737999999996, 3139.8718000000003, 3112.322399999999, 3094.5683000000004, 2924.345, 2090.821000000001, 2910.8902000000003, 2872.160999999999, 1633.7073999999986, 2669.1625, 3042.4796, 3122.0149, 3113.916899999999, 1536.9917999999989, 2742.6263, 1651.0089999999998, 2271.2118999999993, 3038.0170000000016, 3078.3670000000006, 1241.1864, 2627.2770999999975, 1840.9532000000004, 2715.3241, 2753.122, 2558.9638999999997], 'policy_ev_02_reward': [-1302.841999999999, -1098.6251000000004, -855.2160999999996, -1581.3457999999996, -162.2698999999996, -55.745399999999705, -230.78989999999993, -61.50480000000023, 750.0449999999998, 195.1066999999999, 1031.4803000000009, 889.7886000000003, 985.0457000000002, 1221.3556000000005, 1356.7926000000004, 2099.8859, 1959.5440000000006, 2044.8153000000002, 2231.075999999999, 1550.4273000000007, 2110.0438999999997, 2063.3490000000006, 2527.0117, 2494.4728, 2743.0034, 2824.611600000001, 2245.7308999999996, 2682.615199999999, 2689.350199999999, 3004.2776000000003, 1903.2408000000003, 3071.256199999999, 3044.586499999999, 3246.7814, 3226.4697, 3048.7755, 3262.939, 3051.8086000000008, 3199.813800000001, 1546.1541000000007, 2752.180499999997, 2658.4098, 3163.3158000000003, 2281.3062000000014, 2944.4518, 3106.4460000000013, 2734.122999999998, 1113.6376999999986, 2685.4324999999994, -41188.88960000001, 978.4269999999993, 2025.0245999999997, 3061.860500000001, 2735.813399999998, 2024.0749999999998, 2956.971199999999, 795.7789999999989, 2166.5069999999996, 1594.1989000000008, 2313.424600000001, 2535.108400000001, 2845.5441999999994, 2852.312899999999, 2883.7809000000016, 1924.162199999999, 2522.8817000000004, 2744.0251999999978, 1903.5134000000016, 1132.8666999999987, 2956.3782, 2149.5863000000013, 1391.8589000000004, 1864.7818000000007, 2250.6525999999967, 2849.8861999999986, 2633.989399999999, 1860.4430999999968, 2542.6534000000015, 2171.6408999999985, 2729.9118000000008, 2597.4360000000006, 2244.0642999999986, 1864.2123000000004, 2222.206599999998, 2481.271399999998, 1938.4501999999993, 720.7508000000009, 2482.3437, 581.6466000000008, 721.3365999999991, 1988.277200000001, 2664.986800000003, 2083.464799999999, 2543.4359999999997, 2063.2076999999977, 2727.866099999999, 2121.733599999999, 1290.787100000001, 1228.9034000000004, 2624.054899999997], 'policy_ev_03_reward': [-1093.5049, -332.05419999999987, 457.98929999999973, 842.5354000000005, -352.0812000000003, 644.6067000000002, 1142.9304000000009, 1360.1256999999998, -1248.6247999999996, 1698.3441999999986, 1781.0802999999994, 2106.1310999999982, 1815.5242000000005, 657.1084999999997, 2210.7565999999997, 2529.029700000002, -1245.4040999999997, 2542.6008999999995, 2339.3947, 2758.8435999999997, 2827.845199999999, 2937.8645, 3103.975100000001, 2595.3655000000003, 1797.9831999999997, 2869.5071000000003, 2927.7415999999994, 3019.702000000001, 2617.1254999999987, 1795.6904000000004, 3082.698799999999, 1682.1572, 3048.6778999999997, 3081.9122000000025, 3027.4922999999985, 2426.0758, 2925.083999999998, 2995.6067000000003, 2627.6794999999997, 3009.145400000002, 1956.7415999999996, 2779.9818000000023, 2909.3418000000006, 2773.2615, 2877.5683000000013, 1906.745499999999, 2639.9158000000007, 2615.3508000000006, 2795.2786000000037, 2883.7223999999987, 2889.000400000001, 2867.147400000001, 2853.8992000000007, -89.1487, 1838.5097, 843.0386999999993, 1943.3364000000013, 2878.9229000000005, 2913.194900000001, 2249.995399999998, 2909.8128000000006, 2790.8092, 2727.9907999999978, 2624.4759000000004, 2742.6776999999984, 2798.198400000002, 2773.4648000000007, 1985.6715000000004, 1180.381599999999, 1586.912799999997, 2672.593699999999, 1876.0697999999993, 2664.618599999998, 2260.7283999999986, 2650.484699999997, 2307.3385000000003, 2700.473099999996, 2703.618999999998, 2652.640299999999, 2549.7393999999967, 2545.9007, 2773.492099999999, 2726.5037999999986, 556.3306999999992, 1474.6024000000002, 1792.8452999999986, 2285.604400000003, 2600.176200000005, -29.24549999999961, 2754.022400000001, 813.9085999999991, 2793.7006000000006, 2108.381399999999, 2701.4419, 2638.9644999999996, 2670.006900000001, 2731.7557000000006, 2645.2220000000016, 2594.8945999999983, 2572.9466999999986], 'policy_ev_04_reward': [-764.1521999999999, -197.57630000000023, 104.95120000000003, 549.2211999999993, 25.51390000000015, 824.5797000000005, 206.72959999999998, 1132.7265999999997, -376.06530000000004, 1595.1847999999977, 1340.9035999999983, 938.093299999999, 1885.0315999999968, 2209.338599999997, -25596.3292, 1724.384199999998, -6606.463199999995, 1775.5396999999982, 2081.2444999999984, 1519.0905999999977, -24756.9445, -2931.7353999999973, 2285.343999999997, 2212.2036999999973, -4897.901399999999, 2374.268199999996, -24585.2146, -42.28540000000112, 2441.596999999997, -30451.5725, -568.4373000000012, 2460.712699999997, 2253.636699999999, 2389.2846999999992, -19268.7019, 2597.1833999999994, -18785.27150000002, -6349.512499999993, 1918.0832999999989, 1995.2663999999984, 2231.615799999997, -18505.658700000004, 2412.4804999999974, -374.8421000000007, 2552.5051999999987, -9973.888000000004, 2519.1367000000005, -12860.401400000008, 2544.5265, -20890.810899999986, -4631.578700000001, -1597.4541000000017, 2600.4574999999986, -10662.861200000005, 2747.609699999999, -26819.0985, 2618.440799999999, -25161.581700000024, 2708.7431999999976, -37116.57190000001, -26701.351500000004, -1833.9987000000024, 2451.137699999997, 2564.894499999998, -16570.525800000007, -10947.855700000018, 2527.12, 2087.9961999999978, 225.4133000000006, -9728.817800000019, 2717.557499999997, 2066.7529999999997, -11106.734100000007, 2597.720399999999, -3950.0344999999998, -12629.35850000002, 2431.0427, 2342.7267999999967, 2025.232699999997, 2400.0424999999987, 2449.739499999998, -19034.67869999999, -7702.8961000000045, 1852.564199999998, 2340.8703, 2440.681299999999, 1695.340899999998, 1986.3261999999984, 2421.9029999999984, 2620.0822000000003, -21714.012199999986, 2566.6011999999982, -3226.2005999999997, 1223.2024999999978, -10198.991800000003, -9070.522000000012, 2692.491099999999, -5741.823999999998, 2691.6386, -30568.72790000002], 'policy_ev_05_reward': [456.09209999999973, -3161.677, 632.7269000000001, 580.0523000000002, -1466.4127000000008, 154.80070000000012, 783.8278999999998, 1040.1369000000002, -727.2383000000005, 1319.2453000000007, 113.87900000000057, 1216.8513000000007, 1680.9662999999987, 2007.2464999999993, 2334.4862, 1194.3531999999993, 2426.1337000000003, 2189.9811999999997, 2059.4516999999996, 2655.3309000000004, 2043.3629999999991, 2255.2308999999996, -1.4298999999997342, 1446.4143999999994, 2267.4686000000006, 2458.5279999999993, 313.8545000000003, 2647.943799999999, -1166.0679999999993, -8575.162900000003, 1957.0877000000005, 2042.0596999999996, -10326.937700000008, 2790.4551000000015, -1955.0544999999995, 2906.829699999999, -4299.0, 2778.2999000000013, -12140.412300000002, -1469.0177999999994, 2720.2336000000005, -14518.030000000002, 2485.4039000000007, 2745.921199999999, 2671.261599999998, 2675.0368999999996, 2694.8802000000014, 2248.9746, 2775.2981999999984, -22841.878699999997, -1450.3346000000022, 2816.7084999999997, 2864.3666000000007, 2729.1888000000004, 2299.300999999998, 2429.480399999998, -40.05249999999999, 2814.8983000000007, -3509.872999999999, 2842.128500000001, 2600.642999999997, 2682.025800000003, -588.7412000000002, 2852.6615999999985, 2872.510499999999, -35379.6772, 2891.7272, 1925.285699999999, -3670.502200000001, 2907.9903000000004, -9576.759999999997, 2709.6042, 2906.531299999999, 2933.2763999999984, 2881.293099999999, 2953.7411999999995, -15366.353799999997, 3055.237999999999, 3005.0116999999987, -7923.630900000001, 2884.4376, 2778.1963, 2445.0280999999995, -1639.440200000001, 455.8857999999996, -2382.7150000000024, 2683.9939000000018, 2517.173399999998, -7531.631600000001, 2746.4795, 2873.5242000000003, 2463.3749999999995, 875.8964999999989, 670.9986999999995, 2649.1043999999983, 2562.5959, 2775.262900000001, 1845.8193999999992, 1619.5349, 2626.2599999999993], 'policy_storage_01_reward': [-1615.490099999999, -1324.2137999999986, -921.3989999999992, -740.9713999999996, -933.5197999999995, -1399.273, -1371.2844000000007, -2302.408500000001, -659.0850000000002, -846.3896999999988, -672.7795000000003, -416.7499999999998, -759.3210999999991, -348.83769999999964, -1048.192099999998, -897.1374999999998, -207.88140000000018, -377.6895, -208.88970000000023, -124.41300000000003, -536.8908999999999, -106.96940000000001, -714.0477999999986, -59.92250000000002, -82.37880000000008, -105.79530000000008, -143.88670000000022, -48.90950000000003, -860.4919999999985, -233.09910000000002, -262.0453, -49.991000000000035, -61.05920000000003, -465.71210000000013, -86.95199999999996, -74.65080000000013, -438.3952999999999, -232.96769999999978, -627.6734999999993, -37.06910000000003, -49.331699999999934, -40.93840000000002, -102.46190000000021, -34.65499999999999, -223.80810000000002, -631.4348000000003, -225.32450000000003, -230.03189999999992, -439.7925999999999, -225.13209999999992, -29.0383, -229.49009999999998, -41.21860000000004, -44.2677, -12.184499999999998, -23.21929999999998, -23.369599999999995, -221.30209999999994, -407.93379999999985, -432.0400000000001, -412.6986999999997, -210.15279999999998, -220.1312, -224.0108999999997, -410.21239999999966, -15.859, -823.0189999999999, -427.47759999999994, -421.3278999999998, -415.619, -214.96019999999982, -423.0375999999999, -212.61409999999998, -12.0879, -211.58509999999984, -621.585999999999, -207.11789999999982, -15.962000000000002, -1015.5652999999998, -203.78309999999996, -1015.7608999999997, -208.20209999999992, -612.2839999999994, -11.901599999999998, -216.36909999999983, -212.03029999999987, -211.36759999999984, -214.15189999999976, -413.3483, -1.8079999999999896, -3.2551000000000014, -797.4070000000003, -1.010199999999997, 3.204500000000007, -199.9117999999999, -196.9294000000001, -397.0407999999998, 0.4954999999999936, -193.3718999999998, -594.1236999999999], 'policy_storage_02_reward': [-1785.2102999999966, -1468.9633000000013, -2127.562699999999, -1273.7696999999987, -785.8167999999997, -2587.5195000000003, -1163.3885999999993, -1349.823399999999, -859.5561999999991, -2718.7911999999997, -1068.293200000001, -771.7657000000008, -643.644800000001, -1807.2906999999987, -1420.0076000000001, -2733.7986999999985, -596.7906000000008, -1479.9757999999997, -284.01329999999984, -1253.5378000000007, -1068.7990999999997, -301.7511999999999, -360.1347000000005, -783.7888000000011, -606.6644000000003, -2137.161800000003, -185.8796999999996, -568.8567000000005, -753.7038000000005, -360.92429999999973, -580.7289000000005, -339.3874000000001, -151.88449999999978, -104.89459999999984, -703.1072000000006, -96.37939999999983, -87.07209999999999, -653.1208000000003, -1462.7212000000009, -59.12149999999992, -657.5408000000002, -246.5669, -48.83340000000003, -244.19869999999997, -228.02190000000002, -46.70680000000001, -13.629200000000003, -1.3024000000000155, -222.90029999999985, -636.0298000000009, -190.83949999999987, -786.2448999999995, -992.4885999999999, -216.09869999999995, -209.5699, -234.4748, -224.9168999999999, -604.6621999999996, 7.017099999999995, -406.57520000000005, 9.25699999999999, 21.34999999999996, 13.063599999999955, -184.21789999999967, -1167.2514999999999, -157.10609999999974, -774.4283000000001, -356.99810000000025, -775.0763000000005, -160.72409999999996, -1160.5200000000002, 44.974800000000094, -551.854500000001, -767.7180000000005, -357.18000000000006, -393.45820000000003, -167.6958999999999, 59.65120000000009, -154.11559999999997, -346.8281000000004, 45.14360000000007, -353.07270000000005, -186.18019999999996, -555.5171, -396.5101, -361.6615999999999, -172.37310000000014, 20.817500000000045, -759.2201000000008, -969.4539999999998, -986.7628999999998, -1375.8201000000006, 34.20110000000001, -383.38300000000004, -192.9118, -193.58149999999995, -358.22830000000033, -170.87809999999985, 18.71569999999998, -194.59220000000016], 'policy_storage_03_reward': [-2593.5677000000005, -1280.3026000000002, -1674.603100000001, -1968.1275999999987, -524.7941000000001, -1367.6618999999998, -308.5073999999998, -2690.4881999999975, -748.2820000000011, -919.4512000000004, -643.1785, -541.8950999999997, -1294.2801000000002, -403.5421000000006, -103.38839999999989, -351.40810000000033, -588.0286000000003, -292.87850000000003, -864.8334000000017, -338.74690000000044, -45.7693, -71.60479999999994, -19.828999999999965, -637.5659999999995, -670.5420000000001, -410.16620000000034, -25.275399999999895, -38.285999999999945, -225.29629999999995, -212.4286, -3.086900000000003, -205.2188999999999, 0.2222999999999961, -400.3537999999999, -404.72200000000066, -614.2251000000002, -197.90749999999986, -17.453699999999998, -5.305900000000002, -204.8642, -629.2949000000004, -44.65339999999994, 6.545499999999989, 4.653100000000001, -430.7367999999998, -185.7618, -409.13639999999975, -15.100699999999982, -203.12519999999995, -214.44469999999978, -387.6622000000007, -0.21989999999999738, -594.7949999999998, -2.995700000000002, -6.446800000000007, -598.4458999999999, 3.690499999999985, -786.9510999999998, -186.30979999999983, 2.6476999999999955, -197.56339999999958, -192.18119999999996, -196.65389999999968, -605.9368999999995, 13.667499999999986, 6.3834, -982.4640999999999, -588.0517000000003, 3.1899000000000055, -181.58879999999988, 1.6760999999999902, -216.2278, 0.5919999999999803, 21.634599999999995, -997.5567000000001, -602.2649, 9.210800000000003, -381.4995, -384.7298, -1390.3723000000014, -609.4814000000001, 7.472499999999998, -0.09750000000000815, -586.9381999999996, 16.933599999999995, -408.5662999999997, -578.6245, -776.1422000000006, -18.780200000000008, -191.67079999999999, -382.0399, -393.5141999999998, -196.0999999999996, -405.3851999999999, -190.27550000000002, -2.973400000000005, 13.202299999999997, -595.2879, 21.948700000000013, -184.238], 'policy_aggregator_reward': [-542.8482, -552.1443, -529.6665, -530.2368000000002, -520.2371000000006, -521.9822999999996, -525.9747000000001, -504.4506999999999, -497.0357000000003, -493.1328, -481.39550000000037, -485.1885000000002, -478.51829999999984, -474.48210000000034, -472.5025999999995, -459.99230000000006, -455.20529999999985, -465.1567, -462.4084000000001, -455.07569999999964, -453.7159999999997, -457.9234999999999, -442.9039000000001, -437.5662999999998, -442.30230000000034, -428.7828000000005, -425.43849999999946, -437.6569999999998, -429.33480000000037, -426.60949999999974, -433.5991999999999, -430.0798000000001, -437.90779999999984, -424.6855999999998, -411.01999999999936, -417.92409999999984, -412.19, -404.9326000000002, -403.31000000000034, -405.7270000000001, -396.6813000000003, -397.92920000000004, -407.14590000000027, -396.76619999999957, -405.4760999999995, -398.48439999999954, -389.51820000000015, -382.00540000000024, -386.0599, -384.8358999999998, -380.13710000000054, -398.9855999999998, -385.6184999999998, -389.8345999999995, -376.0063999999998, -386.26420000000013, -397.23579999999987, -390.7743000000002, -390.78249999999986, -389.38009999999974, -387.42890000000006, -388.1879000000006, -385.62530000000015, -383.00779999999986, -377.6027, -386.1782999999999, -381.8883, -378.4481999999996, -386.2573999999998, -380.8641999999998, -392.2820000000004, -381.49940000000015, -379.3501000000002, -389.8572000000001, -384.34409999999997, -382.28069999999997, -365.0730000000001, -367.8986999999998, -388.2894, -377.6330000000003, -386.3590000000002, -380.79490000000015, -376.9871000000002, -371.06060000000014, -377.3187999999999, -378.36339999999996, -376.8826999999996, -376.4356000000001, -370.13180000000017, -378.76270000000045, -366.4847000000002, -374.78659999999996, -371.7157000000001, -368.73560000000055, -372.69609999999966, -376.1711999999999, -370.9036999999997, -368.15210000000036, -383.3091999999999, -5370.553099999999]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1370391283986539, 'mean_inference_ms': 0.3633769520597312, 'mean_action_processing_ms': 0.03580106444683358, 'mean_env_wait_ms': 0.028322516700498478, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.009131567818777902, 'StateBufferConnector_ms': 0.0010931151253836496, 'ViewRequirementAgentConnector_ms': 0.0689772197178432}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 1145760, 'num_agent_steps_trained': 0, 'num_env_steps_sampled': 1145760, 'num_env_steps_trained': 0, 'num_env_steps_sampled_this_iter': 10416, 'num_env_steps_trained_this_iter': 0, 'num_env_steps_sampled_throughput_per_sec': 901.1461050573056, 'num_env_steps_trained_throughput_per_sec': 0.0, 'timesteps_total': 1145760, 'num_steps_trained_this_iter': 0, 'agent_timesteps_total': 1145760, 'timers': {'training_iteration_time_ms': 11577.887, 'sample_time_ms': 5982.092, 'synch_weights_time_ms': 8.084}, 'counters': {'num_env_steps_sampled': 1145760, 'num_env_steps_trained': 0, 'num_agent_steps_sampled': 1145760, 'num_agent_steps_trained': 0}, 'done': False, 'episodes_total': 110, 'training_iteration': 110, 'trial_id': 'default', 'date': '2024-08-27_00-42-19', 'timestamp': 1724715739, 'time_this_iter_s': 11.561012029647827, 'time_total_s': 1263.2289953231812, 'pid': 54233, 'hostname': 'Eduardos-MBP.Home', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'env': 'EC_Multi', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0002, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 128, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x2f0fa6200>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None), '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'ren_08': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'expected_production': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('production': Discrete(10)), {'gamma': 0.0}), 'ren_09': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'expected_production': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('production': Discrete(10)), {'gamma': 0.0}), 'ren_02': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'expected_production': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('production': Discrete(10)), {'gamma': 0.0}), 'ren_06': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'expected_production': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('production': Discrete(10)), {'gamma': 0.0}), 'ren_13': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'expected_production': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('production': Discrete(10)), {'gamma': 0.0}), 'ev_01': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'available_ev_energy': Box(0.0, 99999.0, (1,), float32), 'available_renewable_energy': Box(0.0, 99999.0, (1,), float32), 'available_storage_energy': Box(0.0, 99999.0, (1,), float32), 'current_time': Box(0, 9999, (1,), int32), 'export_price': Box(0.0, 1.0, (1,), float32), 'grid_connection': Discrete(2), 'import_price': Box(0.0, 1.0, (1,), float32), 'maximum_charge': Box(0.0, 99999.0, (1,), float32), 'maximum_discharge': Box(0.0, 99999.0, (1,), float32), 'next_departure_energy_requirement': Box(0.0, 1.0, (1,), float32), 'next_departure_time': Box(0, 9999, (1,), int32), 'soc': Box(0.0, 1.0, (1,), float32), 'time_until_next_departure': Box(0, 9999, (1,), int32)), Dict('ctl': Discrete(20)), {'gamma': 0.9}), 'ev_02': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'available_ev_energy': Box(0.0, 99999.0, (1,), float32), 'available_renewable_energy': Box(0.0, 99999.0, (1,), float32), 'available_storage_energy': Box(0.0, 99999.0, (1,), float32), 'current_time': Box(0, 9999, (1,), int32), 'export_price': Box(0.0, 1.0, (1,), float32), 'grid_connection': Discrete(2), 'import_price': Box(0.0, 1.0, (1,), float32), 'maximum_charge': Box(0.0, 99999.0, (1,), float32), 'maximum_discharge': Box(0.0, 99999.0, (1,), float32), 'next_departure_energy_requirement': Box(0.0, 1.0, (1,), float32), 'next_departure_time': Box(0, 9999, (1,), int32), 'soc': Box(0.0, 1.0, (1,), float32), 'time_until_next_departure': Box(0, 9999, (1,), int32)), Dict('ctl': Discrete(20)), {'gamma': 0.9}), 'ev_03': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'available_ev_energy': Box(0.0, 99999.0, (1,), float32), 'available_renewable_energy': Box(0.0, 99999.0, (1,), float32), 'available_storage_energy': Box(0.0, 99999.0, (1,), float32), 'current_time': Box(0, 9999, (1,), int32), 'export_price': Box(0.0, 1.0, (1,), float32), 'grid_connection': Discrete(2), 'import_price': Box(0.0, 1.0, (1,), float32), 'maximum_charge': Box(0.0, 99999.0, (1,), float32), 'maximum_discharge': Box(0.0, 99999.0, (1,), float32), 'next_departure_energy_requirement': Box(0.0, 1.0, (1,), float32), 'next_departure_time': Box(0, 9999, (1,), int32), 'soc': Box(0.0, 1.0, (1,), float32), 'time_until_next_departure': Box(0, 9999, (1,), int32)), Dict('ctl': Discrete(20)), {'gamma': 0.9}), 'ev_04': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'available_ev_energy': Box(0.0, 99999.0, (1,), float32), 'available_renewable_energy': Box(0.0, 99999.0, (1,), float32), 'available_storage_energy': Box(0.0, 99999.0, (1,), float32), 'current_time': Box(0, 9999, (1,), int32), 'export_price': Box(0.0, 1.0, (1,), float32), 'grid_connection': Discrete(2), 'import_price': Box(0.0, 1.0, (1,), float32), 'maximum_charge': Box(0.0, 99999.0, (1,), float32), 'maximum_discharge': Box(0.0, 99999.0, (1,), float32), 'next_departure_energy_requirement': Box(0.0, 1.0, (1,), float32), 'next_departure_time': Box(0, 9999, (1,), int32), 'soc': Box(0.0, 1.0, (1,), float32), 'time_until_next_departure': Box(0, 9999, (1,), int32)), Dict('ctl': Discrete(20)), {'gamma': 0.9}), 'ev_05': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'available_ev_energy': Box(0.0, 99999.0, (1,), float32), 'available_renewable_energy': Box(0.0, 99999.0, (1,), float32), 'available_storage_energy': Box(0.0, 99999.0, (1,), float32), 'current_time': Box(0, 9999, (1,), int32), 'export_price': Box(0.0, 1.0, (1,), float32), 'grid_connection': Discrete(2), 'import_price': Box(0.0, 1.0, (1,), float32), 'maximum_charge': Box(0.0, 99999.0, (1,), float32), 'maximum_discharge': Box(0.0, 99999.0, (1,), float32), 'next_departure_energy_requirement': Box(0.0, 1.0, (1,), float32), 'next_departure_time': Box(0, 9999, (1,), int32), 'soc': Box(0.0, 1.0, (1,), float32), 'time_until_next_departure': Box(0, 9999, (1,), int32)), Dict('ctl': Discrete(20)), {'gamma': 0.9}), 'storage_01': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'available_ev_energy': Box(0.0, 99999.0, (1,), float32), 'available_renewable_energy': Box(0.0, 99999.0, (1,), float32), 'available_storage_energy': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'maximum_charge': Box(0.0, 99999.0, (1,), float32), 'maximum_discharge': Box(0.0, 99999.0, (1,), float32), 'soc': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('ctl': Discrete(20)), {'gamma': 0.9}), 'storage_02': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'available_ev_energy': Box(0.0, 99999.0, (1,), float32), 'available_renewable_energy': Box(0.0, 99999.0, (1,), float32), 'available_storage_energy': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'maximum_charge': Box(0.0, 99999.0, (1,), float32), 'maximum_discharge': Box(0.0, 99999.0, (1,), float32), 'soc': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('ctl': Discrete(20)), {'gamma': 0.9}), 'storage_03': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'available_ev_energy': Box(0.0, 99999.0, (1,), float32), 'available_renewable_energy': Box(0.0, 99999.0, (1,), float32), 'available_storage_energy': Box(0.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32), 'maximum_charge': Box(0.0, 99999.0, (1,), float32), 'maximum_discharge': Box(0.0, 99999.0, (1,), float32), 'soc': Box(0.0, 1.0, (1,), float32), 'time_of_day': Box(0, 23, (1,), int32)), Dict('ctl': Discrete(20)), {'gamma': 0.9}), 'aggregator': (None, Dict('available_energy': Box(-99999.0, 99999.0, (1,), float32), 'export_price': Box(0.0, 1.0, (1,), float32), 'import_price': Box(0.0, 1.0, (1,), float32)), Dict('placeholder': Discrete(1)), {'gamma': 0.9})}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 1}, 'time_since_restore': 1263.2289953231812, 'iterations_since_restore': 110, 'perf': {'cpu_util_percent': 16.5375, 'ram_util_percent': 69.8125}})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.save('/Users/ecgomes/DataspellProjects/pyecom/models/no_costs/sequential_monthly_v8')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-26T23:42:26.595452Z",
     "start_time": "2024-08-26T23:42:26.450863Z"
    }
   },
   "id": "e87b4cd68c23375b",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.9"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_resources[list(dataset_resources.keys())[0]][-2].discharge_efficiency #*\\\n",
    "# dataset_resources[list(dataset_resources.keys())[0]][-2].schedule_requirement_soc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T05:48:22.152717Z",
     "start_time": "2024-08-24T05:48:22.150185Z"
    }
   },
   "id": "bf15eff88ee54a3f",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check the results\n",
    "# Create a new env\n",
    "\n",
    "test_resources = dataset_resources[list(dataset_resources.keys())[0]]\n",
    "\n",
    "test_env = EnergyCommunitySequentialV0(ren_generators=test_resources[:5],\n",
    "                                       generators=test_resources[5:7],\n",
    "                                       loads=test_resources[7:12],\n",
    "                                       storages=test_resources[12:15],\n",
    "                                       evs=test_resources[15:-1],\n",
    "                                       aggregator=test_resources[-1],\n",
    "                                       ev_penalty=1,\n",
    "                                       balance_penalty=BALANCE_PENALTY,\n",
    "                                       execution_order=execution_order)\n",
    "\n",
    "obs, info = test_env.reset()\n",
    "\n",
    "# Set up the terminations and truncations\n",
    "terminations = truncations = {a: False for a in test_env.agents}\n",
    "terminations['__all__'] = False\n",
    "truncations['__all__'] = False\n",
    "\n",
    "while not terminations['__all__'] and not truncations['__all__']:\n",
    "\n",
    "    current_agent = test_env.execution_order[test_env._current_agent_idx]\n",
    "\n",
    "    current_policy = 'generator_renewable' if current_agent.startswith('ren_gen') else \\\n",
    "        'storage' if current_agent.startswith('storage') else \\\n",
    "            'ev' if current_agent.startswith('ev') else \\\n",
    "                'generator_non_renewable'\n",
    "\n",
    "    action_dict = {current_agent: algo.compute_single_action(observation=obs[current_agent],\n",
    "                                                             policy_id=current_policy)}\n",
    "\n",
    "    obs, rewards, terminations, truncations, info = test_env.step(action_dict)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad683417379e3b8d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the generator power output\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(5):\n",
    "    plt.plot(test_env.ren_generators[i].value)\n",
    "\n",
    "plt.legend(['generator_{:02d}'.format(i+1) for i in range(data_ec.generator['p_forecast'].shape[0])])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c3feab2574a47b6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create subplots with the generator values and the forecast\n",
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(10, 10))\n",
    "\n",
    "for i in np.arange(5):\n",
    "    axs[i].plot(test_env.ren_generators[i].value, label='rl_{:02d}'.format(i+1))\n",
    "    axs[i].plot(data_upacs[list(data_upacs.keys())[i]]['pv'].loc['2019-01-01'].values, label='forecast_{:02d}'.format(i+1),\n",
    "                linestyle='--')\n",
    "    \n",
    "    axs[i].legend()\n",
    "    \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd2094b014b68100",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the storage state of charge\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(data_ec.storage['p_charge_limit'].shape[0]):\n",
    "    plt.plot(test_env.storages[i].value * test_env.storages[i].capacity_max)\n",
    "    \n",
    "plt.yticks(np.arange(0, 120, 10))\n",
    "\n",
    "plt.legend(['storage_{:02d}'.format(i+1) for i in range(data_ec.storage['p_charge_limit'].shape[0])])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dff30e2397d292e6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the load values\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(5):\n",
    "    plt.plot(test_env.loads[i].value)\n",
    "    \n",
    "plt.legend(['load_{:02d}'.format(i+1) for i in range(5)])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5410febfe280c103",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check imports and exports\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(test_env.aggregator.imports, label='imports')\n",
    "plt.plot(test_env.aggregator.exports, label='exports')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5ae9575aeeaf40c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check EVs\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for ev in test_env.evs:\n",
    "    plt.plot(ev.value * ev.capacity_max, label=ev.name)\n",
    "\n",
    "plt.yticks(np.arange(0, 80, 5))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74c6a4ca8fa3f912",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for ev in test_env.evs:\n",
    "    print(ev.name)\n",
    "    print(ev.charge)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f60d9ebd62fbe091",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i in range(len(test_env.evs)):\n",
    "    plt.plot(test_env.evs[i].schedule_requirement_soc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d58254a0e27239b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check the sum of values\n",
    "\n",
    "test_prod = pd.DataFrame({'ren_gen': np.sum([test_env.ren_generators[i].value for i in range(5)], axis=0),\n",
    "                          'sdischarge': np.sum([test_env.storages[i].discharge for i in range(3)], axis=0),\n",
    "                          'evdischarge': np.sum([test_env.evs[i].discharge for i in range(5)], axis=0),\n",
    "                          'non_ren_gen': np.sum([test_env.generators[i].value for i in range(2)], axis=0),\n",
    "                          'imports': test_env.aggregator.imports})\n",
    "\n",
    "test_cons = pd.DataFrame({'loads': np.sum([test_env.loads[i].value for i in range(5)], axis=0),\n",
    "                          'scharge': np.sum([test_env.storages[i].charge / test_env.storages[i].charge_efficiency \n",
    "                                             for i in range(3)], axis=0),\n",
    "                          'evcharge': np.sum([test_env.evs[i].charge / test_env.evs[i].charge_efficiency \n",
    "                                              for i in range(5)], axis=0),\n",
    "                          'exports': test_env.aggregator.exports})\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10))\n",
    "\n",
    "test_prod.plot(kind='area', ax=axs[0])\n",
    "test_cons.plot(kind='area', ax=axs[1])\n",
    "\n",
    "axs[2].plot(test_prod.sum(axis=1)[0:], label='prod')\n",
    "axs[2].plot(test_cons.sum(axis=1)[0:], label='cons')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "116e0f9e09d53659",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_prod"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78f7d845fda12af0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_cons"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6867593193aead80",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_env.aggregator.imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56349d9b222d4cf8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "32178670952f7c66"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
